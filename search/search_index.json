{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"mesa-frames CI/CD Package Meta Chat"},{"location":"#scale-mesa-beyond-its-limits","title":"Scale Mesa beyond its limits","text":"<p>Classic Mesa stores each agent as a Python object, which quickly becomes a bottleneck at scale. mesa-frames reimagines agent storage using Polars DataFrames, so agents live in a columnar store rather than the Python heap.</p> <p>You keep the Mesa-style <code>Model</code> / <code>AgentSet</code> structure, but updates are vectorized and memory-efficient.</p>"},{"location":"#why-it-matters","title":"Why it matters","text":"<ul> <li>\u26a1 10\u00d7 faster bulk updates on 10k+ agents (see Benchmarks)</li> <li>\ud83d\udcca Columnar execution via Polars: SIMD ops, multi-core support</li> <li>\ud83d\udd04 Declarative logic: agent rules as transformations, not Python loops</li> <li>\ud83d\ude80 Roadmap: Lazy queries and GPU support for even faster models</li> </ul>"},{"location":"#who-is-it-for","title":"Who is it for?","text":"<ul> <li>Researchers needing to scale to tens or hundreds of thousands of agents</li> <li>Users whose agent logic can be written as vectorized, set-based operations</li> </ul> <p>\u274c Not a good fit if: your model depends on strict per-agent sequencing, complex non-vectorizable methods, or fine-grained identity tracking.</p>"},{"location":"#why-dataframes","title":"Why DataFrames?","text":"<p>DataFrames enable SIMD and columnar operations that are far more efficient than Python loops. mesa-frames currently uses Polars as its backend.</p> Feature mesa (classic) mesa-frames Storage Python objects Polars DataFrame Updates Loops Vectorized ops Memory overhead High Low Max agents (practical) ~10^3 ~10^6+"},{"location":"#benchmarks","title":"Benchmarks","text":"<p>mesa-frames consistently outperforms classic Mesa across both toy and canonical ABMs.</p> <p>In the Boltzmann model, it maintains near-constant runtimes even as agent count rises, achieving up to 10\u00d7 faster execution at scale.</p> <p>In the more computation-intensive Sugarscape model, mesa-frames roughly halves total runtime.</p> <p>We still have room to optimize performance further (see Roadmap).</p> <p> </p> <p> </p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Install</li> </ol> <pre><code>   pip install mesa-frames\n</code></pre> <p>Or for development:</p> <pre><code>git clone https://github.com/mesa/mesa-frames.git\ncd mesa-frames\nuv sync --all-extras\n</code></pre> <ol> <li>Create a model</li> </ol> <pre><code>from mesa_frames import AgentSet, Model\nimport polars as pl\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def give_money(self):\n        self.select(self.wealth &gt; 0)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n        self[new_wealth, \"wealth\"] += new_wealth[\"len\"]\n\n    def step(self):\n        self.do(\"give_money\")\n\nclass MoneyModelDF(Model):\n    def __init__(self, N: int):\n        super().__init__()\n        self.sets += MoneyAgents(N, self)\n\n    def step(self):\n        self.sets.do(\"step\")\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<p>Community contributions welcome \u2014 see the full roadmap</p> <ul> <li>Transition to LazyFrames for optimization and GPU support</li> <li>Auto-vectorize existing Mesa models via decorator</li> <li>Increase possible Spaces (Network, Continuous...)</li> <li>Refine the API to align to Mesa</li> </ul>"},{"location":"#license","title":"License","text":"<p>Copyright \u00a9 2025 Adam Amer, Mesa team and contributors</p> <p>Licensed under the Apache License, Version 2.0.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#version-010-alpha-2024-08-28","title":"Version 0.1.0-alpha \u2014 2024-08-28","text":""},{"location":"changelog/#whats-changed","title":"What's Changed","text":"<ul> <li>Refactoring mesa.Agent, mesa.AgentSet, mesa.Model -&gt; AgentSetDF, AgentsDF, ModelDF by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/8</li> <li>setup: Migrate from setup.py to pyproject.toml by @rht in https://github.com/adamamer20/mesa-frames/pull/13</li> <li>ci: Add pre-commit configuration by @rht in https://github.com/adamamer20/mesa-frames/pull/14</li> <li>Merge requirements.txt into pyproject.toml by @rht in https://github.com/adamamer20/mesa-frames/pull/15</li> <li>ci: Add GA for tests by @rht in https://github.com/adamamer20/mesa-frames/pull/17</li> <li>Changes to AgentSetDF and AgentsDF before time.py -&gt; CopyMixin by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/16</li> <li>benchmark: Split Polars agent into native and concise by @rht in https://github.com/adamamer20/mesa-frames/pull/23</li> <li>benchmark: Split pandas agent into native and concise by @rht in https://github.com/adamamer20/mesa-frames/pull/24</li> <li>speed up mesa readme_plot script by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/26</li> <li>Adding DataFrameMixin for improved reusability/encapsulation by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/27</li> <li>Abstract SpaceDF by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/29</li> <li>Adding Abstract DiscreteSpaceDF by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/30</li> <li>Adding abstract GridDF by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/32</li> <li>Additional methods and fixes to DataFrameMixin by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/43</li> <li>Concrete GridPandas by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/44</li> <li>[pre-commit.ci] pre-commit autoupdate by @pre-commit-ci in https://github.com/adamamer20/mesa-frames/pull/55</li> <li>Fixes and Tests for PolarsMixin by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/56</li> <li>Adding Comparison and Indexing methods to DataFrameMixin by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/58</li> <li>Concrete GridPolars by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/60</li> <li>Sugarscape Instantaneous Growback (Pandas-with-loop implementation) by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/63</li> <li>Adding pydoclint and properly format docstring by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/69</li> <li>Docs with material-from-mkdocs by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/70</li> <li>Enforce correct numpy docstring formatting with ruff.pydocstyle by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/74</li> <li>API Documentation with Sphinx by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/75</li> <li>Move images from docs to docs/general to make it available for mkdocs by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/79</li> <li>Adding user guide by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/81</li> <li>Adding SugarScape IG (polars with loops) by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/71</li> <li>Automatic publishing on PyPI on new release by @adamamer20 in https://github.com/adamamer20/mesa-frames/pull/77</li> </ul>"},{"location":"changelog/#new-contributors","title":"New Contributors","text":"<ul> <li>@adamamer20 made their first contribution in https://github.com/adamamer20/mesa-frames/pull/8</li> <li>@rht made their first contribution in https://github.com/adamamer20/mesa-frames/pull/13</li> <li>@pre-commit-ci made their first contribution in https://github.com/adamamer20/mesa-frames/pull/55</li> </ul> <p>Full Changelog: https://github.com/adamamer20/mesa-frames/commits/v0.1.0-alpha</p>"},{"location":"contributing/","title":"Contributing to mesa-frames \ud83d\ude80","text":"<p>Thank you for taking the time to contribute to mesa-frames! Since the project is still in its early stages, we warmly welcome contributions that will help shape its development. \ud83c\udf89</p> <p>For a more general and comprehensive guide, please refer to mesa's main contribution guidelines. \ud83d\udcdc</p>"},{"location":"contributing/#project-roadmap","title":"Project Roadmap \ud83d\uddfa\ufe0f","text":"<p>Before contributing, we recommend reviewing our roadmap file to understand the project's current priorities, upcoming features, and long-term vision. This will help ensure your contributions align with the project's direction.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute \ud83d\udca1","text":""},{"location":"contributing/#1-prerequisite-installations","title":"1. Prerequisite Installations \u2699\ufe0f","text":"<p>Before you begin contributing, ensure that you have the necessary tools installed:</p> <ul> <li>Install Python (at least the version specified in <code>requires-python</code> of <code>pyproject.toml</code>). \ud83d\udc0d</li> </ul> <p>-- We recommend using a virtual environment manager like:</p> <pre><code>- [Astral's UV](https://docs.astral.sh/uv/#installation) \ud83c\udf1f\n- [Hatch](https://hatch.pypa.io/latest/install/) \ud83c\udfd7\ufe0f\n</code></pre> <ul> <li> <p>Install pre-commit to enforce code quality standards before pushing changes:</p> </li> <li> <p>Pre-commit installation guide \u2705</p> </li> <li>More about pre-commit hooks</li> </ul> <p>-- If using VS Code, consider installing these extensions to automatically enforce formatting:</p> <pre><code>- [Ruff](https://marketplace.visualstudio.com/items?itemName=charliermarsh.ruff) \u2013 Python linting &amp; formatting \ud83d\udc3e\n- [Markdownlint](https://marketplace.visualstudio.com/items?itemName=DavidAnson.vscode-markdownlint) \u2013 Markdown linting (for documentation) \u270d\ufe0f\n- [Git Hooks](https://marketplace.visualstudio.com/items?itemName=lakshmikanthayyadevara.githooks) \u2013 Automatically runs &amp; visualizes pre-commit hooks \ud83d\udd17\n</code></pre>"},{"location":"contributing/#2-contribution-process","title":"2. Contribution Process \ud83d\udee0\ufe0f","text":""},{"location":"contributing/#step-1-choose-an-issue","title":"Step 1: Choose an Issue \ud83d\udccc","text":"<ul> <li>Pick an existing issue or create a new one if necessary.</li> <li>Ensure that your contribution aligns with the project's goals.</li> </ul>"},{"location":"contributing/#step-2-set-up-your-local-repository","title":"Step 2: Set Up Your Local Repository \ud83d\udcbb","text":"<ol> <li>Fork the repository on GitHub.</li> <li>Clone your fork to your local machine:</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/mesa-frames.git\n</code></pre> <ol> <li>Create a new branch with a descriptive name:</li> </ol> <pre><code>git checkout -b feature-name\n</code></pre> <ol> <li>Prevent merge commit clutter by setting rebase mode:</li> </ol> <pre><code>git config pull.rebase true\n</code></pre>"},{"location":"contributing/#step-3-install-dependencies","title":"Step 3: Install Dependencies \ud83d\udce6","text":"<p>We manage the development environment with uv:</p> <pre><code>uv sync --all-extras\n</code></pre> <p>This creates <code>.venv/</code> and installs mesa-frames with the development extras.</p>"},{"location":"contributing/#step-4-make-and-commit-changes","title":"Step 4: Make and Commit Changes \u2728","text":"<ol> <li>Make necessary edits and save the code.</li> <li>Add and commit your changes with meaningful commit messages:</li> </ol> <pre><code>git add FILE_NAME\ngit commit -m \"Fix issue X: Brief description of the fix\"\n</code></pre> <ul> <li>Keep commits small and focused on a single logical change.</li> <li>Follow Tim Pope\u2019s commit message guidelines. \ud83d\udcdd</li> </ul>"},{"location":"contributing/#step-5-code-quality-and-testing","title":"Step 5: Code Quality and Testing \u2705","text":"<ul> <li>Run pre-commit hooks to enforce code quality standards:</li> </ul> <pre><code>uv run pre-commit run -a\n</code></pre> <ul> <li>Run tests to ensure your contribution does not break functionality:</li> </ul> <pre><code>uv run pytest -q --cov=mesa_frames --cov-report=term-missing\n</code></pre> <p>-- Optional: Runtime Type Checking (beartype) \ud83d\udd0d</p> <p>You can enable stricter runtime validation of function arguments/returns with <code>beartype</code> during local development:</p> <pre><code>MESA_FRAMES_RUNTIME_TYPECHECKING=1 uv run pytest -q --cov=mesa_frames --cov-report=term-missing\n</code></pre> <p>Quick facts:</p> <ul> <li>Automatically enabled in: Hatch dev env (<code>hatch shell dev</code>), VS Code debugger, and VS Code test runs.</li> <li>Enable manually by exporting <code>MESA_FRAMES_RUNTIME_TYPECHECKING=1</code> (any of 1/true/yes).</li> <li>Use only for development/debugging; adds overhead\u2014disable for performance measurements or large simulations.</li> <li>Unset with your shell (e.g. <code>unset</code>/<code>Remove-Item Env:</code> depending on shell) to turn it off.</li> </ul> <p>Example for a one-off test run:</p> <pre><code>MESA_FRAMES_RUNTIME_TYPECHECKING=1 uv run pytest -q\n</code></pre>"},{"location":"contributing/#step-6-documentation-updates-if-needed","title":"Step 6: Documentation Updates (If Needed) \ud83d\udcd6","text":"<ul> <li>If you add a new feature, update the documentation accordingly.</li> <li>We use MKDocs for documentation:</li> <li>Modify or create markdown files in the <code>docs/</code> folder.</li> <li> <p>Preview your changes by running:</p> <pre><code>uv run mkdocs serve\n</code></pre> </li> <li> <p>Open <code>http://127.0.0.1:8000</code> in your browser to verify documentation updates.</p> </li> </ul>"},{"location":"contributing/#step-7-push-changes-and-open-a-pull-request-pr","title":"Step 7: Push Changes and Open a Pull Request (PR) \ud83d\ude80","text":"<ol> <li>Push your changes to your fork:</li> </ol> <pre><code>git push origin feature-name\n</code></pre> <ol> <li>Open a pull request (PR):</li> <li>Follow GitHub\u2019s PR guide.</li> <li>Link the issue you are solving in the PR description.</li> </ol> <p>Thank you again for your contribution! \ud83c\udf89</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>This document outlines the near-term roadmap for mesa-frames as of October 2025.</p>"},{"location":"roadmap/#1-lazyframes-for-polars-gpu","title":"1) LazyFrames for Polars + GPU","text":"<p>Switch Polars usage from eager to <code>LazyFrame</code> to enable better query optimization and GPU acceleration.</p> <p>Related issues:</p> <ul> <li> <p>#52: Use of LazyFrames for Polars implementation</p> </li> <li> <p>#144: Switch to LazyFrame for Polars implementation (PR)</p> </li> <li> <p>#89: Investigate Ibis or Narwhals for backend flexibility</p> </li> <li> <p>#122: Deprecate DataFrameMixin (remove during LazyFrames refactor)</p> </li> </ul> <p>Progress and next steps:</p> <ul> <li> <p>Land #144 and convert remaining eager paths to lazy.</p> </li> <li> <p>Validate GPU execution paths and benchmark improvements.</p> </li> <li> <p>Revisit Ibis/Narwhals after LazyFrame stabilization.</p> </li> <li> <p>Fold DataFrameMixin removal into the LazyFrames transition (#122).</p> </li> </ul>"},{"location":"roadmap/#2-agentset-enhancements","title":"2) AgentSet Enhancements","text":"<p>Expose movement methods from <code>AgentContainer</code> and provide optimized utilities for \"move to optimal\" workflows.</p> <p>Related issues:</p> <ul> <li> <p>#108: Adding abstraction of optimal agent movement</p> </li> <li> <p>#118: Adds move_to_optimal in DiscreteSpaceDF (PR)</p> </li> <li> <p>#82: Add movement methods to AgentContainer</p> </li> </ul> <p>Next steps:</p> <ul> <li> <p>Consolidate movement APIs under <code>AgentContainer</code>.</p> </li> <li> <p>Keep conflict resolution simple, vectorized, and well-documented.</p> </li> </ul>"},{"location":"roadmap/#3-research-publication","title":"3) Research &amp; Publication","text":"<p>JOSS paper preparation and submission.</p> <p>Related items:</p> <ul> <li> <p>#90: JOSS paper for the package</p> </li> <li> <p>#107: paper - Adding Statement of Need (PR)</p> </li> </ul> <p>See our contribution guide and browse all open items at https://github.com/mesa/mesa-frames/issues</p>"},{"location":"development/","title":"Development Guidelines","text":""},{"location":"development/#runtime-type-checking","title":"Runtime Type Checking \ud83d\udd0d","text":"<p>mesa-frames includes optional runtime type checking using beartype for development and debugging purposes. This feature helps catch type-related errors early during development and testing.</p> <p>Automatically Enabled</p> <p>Runtime type checking is automatically enabled in the following scenarios:</p> <ul> <li>Hatch development environment (<code>hatch shell dev</code>) \u2014 via <code>pyproject.toml</code> configuration</li> <li>VS Code debugging \u2014 when using the debugger (<code>F5</code> or \"Python Debugger: Current File\")</li> <li>VS Code testing \u2014 when running tests through VS Code's testing interface</li> </ul> <p>No manual setup required in these environments!</p>"},{"location":"development/#development-environment-setup","title":"Development Environment Setup","text":""},{"location":"development/#option-1-hatch-development-environment-recommended","title":"Option 1: Hatch Development Environment (Recommended)","text":"<p>The easiest way to enable runtime type checking is to use Hatch's development environment:</p> <pre><code># Enter the development environment (auto-enables runtime type checking)\nhatch shell dev\n\n# Verify it's enabled\npython -c \"import os; print('Runtime type checking:', os.getenv('MESA_FRAMES_RUNTIME_TYPECHECKING'))\"\n# \u2192 Runtime type checking: true\n</code></pre>"},{"location":"development/#option-2-manual-environment-variable","title":"Option 2: Manual Environment Variable","text":"<p>For other development setups, you can manually enable runtime type checking:</p> <p>Runtime type checking can be enabled by setting the <code>MESA_FRAMES_RUNTIME_TYPECHECKING</code> environment variable:</p> <pre><code>export MESA_FRAMES_RUNTIME_TYPECHECKING=1\n# or\nexport MESA_FRAMES_RUNTIME_TYPECHECKING=true\n# or\nexport MESA_FRAMES_RUNTIME_TYPECHECKING=yes\n</code></pre>"},{"location":"development/#usage-examples","title":"Usage Examples","text":"<p>Automatic Activation</p> <p>If you're using Hatch dev environment, VS Code debugging, or VS Code testing, runtime type checking is already enabled automatically. The examples below are for manual activation in other scenarios.</p>"},{"location":"development/#for-development-and-testing","title":"For Development and Testing","text":"<pre><code># Enable runtime type checking for testing\nMESA_FRAMES_RUNTIME_TYPECHECKING=1 uv run pytest\n\n# Enable runtime type checking for running scripts\nMESA_FRAMES_RUNTIME_TYPECHECKING=1 uv run python your_script.py\n</code></pre>"},{"location":"development/#in-your-ide-or-development-environment","title":"In Your IDE or Development Environment","text":"<p>VS Code (Already Configured):</p> <ul> <li>Debugging: Runtime type checking is automatically enabled when using VS Code's debugger</li> <li>Testing: Automatically enabled when running tests through VS Code's testing interface</li> <li> <p>Manual override: You can also add it manually in <code>.vscode/settings.json</code>:</p> <pre><code>{\n    \"python.env\": {\n        \"MESA_FRAMES_RUNTIME_TYPECHECKING\": \"1\"\n    }\n}\n</code></pre> </li> </ul> <p>PyCharm: In your run configuration, add the environment variable:</p> <pre><code>MESA_FRAMES_RUNTIME_TYPECHECKING=1\n</code></pre>"},{"location":"development/#how-it-works","title":"How It Works","text":"<p>When enabled, the runtime type checking system:</p> <ol> <li>Automatically instruments all mesa-frames packages with beartype decorators</li> <li>Validates function arguments and return values at runtime</li> <li>Provides detailed error messages when type mismatches occur</li> <li>Helps catch type-related bugs during development</li> </ol>"},{"location":"development/#requirements","title":"Requirements","text":"<p>Runtime type checking requires the optional <code>beartype</code> dependency:</p> <pre><code># Install beartype for runtime type checking\nuv add beartype\n# or\npip install beartype\n</code></pre> <p>Optional Dependency</p> <p>If <code>beartype</code> is not installed and runtime type checking is enabled, mesa-frames will issue a warning and continue without type checking.</p>"},{"location":"development/#performance-considerations","title":"Performance Considerations","text":"<p>Development Only</p> <p>Runtime type checking adds significant overhead and should only be used during development and testing. Do not enable it in production environments.</p> <p>The overhead includes:</p> <ul> <li>Function call interception and validation</li> <li>Type checking computations at runtime</li> <li>Memory usage for type checking infrastructure</li> </ul>"},{"location":"development/#when-to-use-runtime-type-checking","title":"When to Use Runtime Type Checking","text":"<p>\u2705 Automatically enabled (recommended):</p> <ul> <li>Hatch development environment (<code>hatch shell dev</code>)</li> <li>VS Code debugging sessions</li> <li>VS Code test execution</li> <li>Contributing to mesa-frames development</li> </ul> <p>\u2705 Manual activation (when needed):</p> <ul> <li>Development and debugging in other IDEs</li> <li>Writing new features outside VS Code</li> <li>Running unit tests from command line</li> <li>Troubleshooting type-related issues</li> </ul> <p>\u274c Not recommended for:</p> <ul> <li>Production deployments</li> <li>Performance benchmarking</li> <li>Large-scale simulations</li> <li>Final model runs</li> </ul>"},{"location":"development/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues with runtime type checking:</p> <ol> <li>Check beartype installation:</li> </ol> <pre><code>uv run python -c \"import beartype; print(beartype.__version__)\"\n</code></pre> <ol> <li>Verify environment variable:</li> </ol> <pre><code>echo $MESA_FRAMES_RUNTIME_TYPECHECKING\n</code></pre> <ol> <li>For automatic configurations:</li> <li>Hatch dev: Ensure you're in the dev environment (<code>hatch shell dev</code>)</li> <li>VS Code debugging: Check that the debugger configuration in <code>.vscode/launch.json</code> includes the environment variable</li> <li> <p>VS Code testing: Verify that <code>.env.test</code> file exists and contains <code>MESA_FRAMES_RUNTIME_TYPECHECKING=true</code></p> </li> <li> <p>Check for warnings in your application logs</p> </li> <li> <p>Disable temporarily if needed:</p> </li> </ol> <pre><code>unset MESA_FRAMES_RUNTIME_TYPECHECKING\n</code></pre> <p>Pro Tip</p> <p>Runtime type checking is particularly useful when developing custom AgentSet implementations or working with complex DataFrame operations where type safety is crucial.</p>"},{"location":"tutorials/2_introductory_tutorial/","title":"Introductory Tutorial","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[2]: Copied! <pre>#!pip install git+https://github.com/projectmesa/mesa-frames mesa\n</pre> #!pip install git+https://github.com/projectmesa/mesa-frames mesa In\u00a0[3]: Copied! <pre>from mesa_frames import Model, AgentSet, DataCollector\n\n\nclass MoneyModel(Model):\n    def __init__(self, N: int, agents_cls):\n        super().__init__()\n        self.n_agents = N\n        self.sets += agents_cls(N, self)\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum()\n            },\n            agent_reporters={\"wealth\": \"wealth\"},\n            storage=\"csv\",\n            storage_uri=\"./data\",\n            trigger=lambda m: m.steps % 2 == 0,\n        )\n\n    def step(self):\n        # Executes the step method for every agentset in self.sets\n        self.sets.do(\"step\")\n\n    def run_model(self, n):\n        for _ in range(n):\n            self.step()\n            self.datacollector.conditional_collect\n        self.datacollector.flush()\n</pre> from mesa_frames import Model, AgentSet, DataCollector   class MoneyModel(Model):     def __init__(self, N: int, agents_cls):         super().__init__()         self.n_agents = N         self.sets += agents_cls(N, self)         self.datacollector = DataCollector(             model=self,             model_reporters={                 \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum()             },             agent_reporters={\"wealth\": \"wealth\"},             storage=\"csv\",             storage_uri=\"./data\",             trigger=lambda m: m.steps % 2 == 0,         )      def step(self):         # Executes the step method for every agentset in self.sets         self.sets.do(\"step\")      def run_model(self, n):         for _ in range(n):             self.step()             self.datacollector.conditional_collect         self.datacollector.flush() In\u00a0[4]: Copied! <pre>import polars as pl\n\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.do(\"give_money\")\n\n    def give_money(self):\n        self.select(self.wealth &gt; 0)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n        self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"len\"]\n</pre> import polars as pl   class MoneyAgents(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.do(\"give_money\")      def give_money(self):         self.select(self.wealth &gt; 0)         other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)         self[\"active\", \"wealth\"] -= 1         new_wealth = other_agents.group_by(\"unique_id\").len()         self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"len\"] In\u00a0[5]: Copied! <pre># Create and run the model\nmodel = MoneyModel(1000, MoneyAgents)\nmodel.run_model(100)\n\nwealth_dist = list(model.sets.df.values())[0]\n\n# Print the final wealth distribution\nprint(wealth_dist.select(pl.col(\"wealth\")).describe())\n</pre> # Create and run the model model = MoneyModel(1000, MoneyAgents) model.run_model(100)  wealth_dist = list(model.sets.df.values())[0]  # Print the final wealth distribution print(wealth_dist.select(pl.col(\"wealth\")).describe()) <pre>shape: (9, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 statistic  \u2506 wealth \u2502\n\u2502 ---        \u2506 ---    \u2502\n\u2502 str        \u2506 f64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 count      \u2506 1000.0 \u2502\n\u2502 null_count \u2506 0.0    \u2502\n\u2502 mean       \u2506 1.0    \u2502\n\u2502 std        \u2506 1.1425 \u2502\n\u2502 min        \u2506 0.0    \u2502\n\u2502 25%        \u2506 0.0    \u2502\n\u2502 50%        \u2506 1.0    \u2502\n\u2502 75%        \u2506 2.0    \u2502\n\u2502 max        \u2506 11.0   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>This output shows the statistical summary of the wealth distribution after 100 steps of the simulation with 1000 agents.</p> In\u00a0[6]: Copied! <pre>class MoneyAgentsConcise(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        ## Adding the agents to the agent set\n        # 1. Changing the df attribute directly (not recommended, if other agents were added before, they will be lost)\n        \"\"\"self.df = pl.DataFrame(\n            {\"wealth\": pl.ones(n, eager=True)}\n        )\"\"\"\n        # 2. Adding the dataframe with add\n        \"\"\"self.add(\n            pl.DataFrame(\n                {\n                    \"wealth\": pl.ones(n, eager=True),\n                }\n            )\n        )\"\"\"\n        # 3. Adding the dataframe with __iadd__\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        # The give_money method is called\n        # self.give_money()\n        self.do(\"give_money\")\n\n    def give_money(self):\n        ## Active agents are changed to wealthy agents\n        # 1. Using the __getitem__ method\n        # self.select(self[\"wealth\"] &gt; 0)\n        # 2. Using the fallback __getattr__ method\n        self.select(self.wealth &gt; 0)\n\n        # Receiving agents are sampled (only native expressions currently supported)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n\n        # Wealth of wealthy is decreased by 1\n        # 1. Using the __setitem__ method with self.active_agents mask\n        # self[self.active_agents, \"wealth\"] -= 1\n        # 2. Using the __setitem__ method with \"active\" mask\n        self[\"active\", \"wealth\"] -= 1\n\n        # Compute the income of the other agents (only native expressions currently supported)\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        # 1. Using the set method\n        \"\"\"self.set(\n            attr_names=\"wealth\",\n            values=pl.col(\"wealth\") + new_wealth[\"len\"],\n            mask=new_wealth,\n        )\"\"\"\n\n        # 2. Using the __setitem__ method\n        self[new_wealth, \"wealth\"] += new_wealth[\"len\"]\n\n\nclass MoneyAgentsNative(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.do(\"give_money\")\n\n    def give_money(self):\n        ## Active agents are changed to wealthy agents\n        self.select(pl.col(\"wealth\") &gt; 0)\n\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n\n        # Wealth of wealthy is decreased by 1\n        self.df = self.df.with_columns(\n            wealth=pl.when(\n                pl.col(\"unique_id\").is_in(self.active_agents[\"unique_id\"].implode())\n            )\n            .then(pl.col(\"wealth\") - 1)\n            .otherwise(pl.col(\"wealth\"))\n        )\n\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        self.df = (\n            self.df.join(new_wealth, on=\"unique_id\", how=\"left\")\n            .fill_null(0)\n            .with_columns(wealth=pl.col(\"wealth\") + pl.col(\"len\"))\n            .drop(\"len\")\n        )\n</pre> class MoneyAgentsConcise(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         ## Adding the agents to the agent set         # 1. Changing the df attribute directly (not recommended, if other agents were added before, they will be lost)         \"\"\"self.df = pl.DataFrame(             {\"wealth\": pl.ones(n, eager=True)}         )\"\"\"         # 2. Adding the dataframe with add         \"\"\"self.add(             pl.DataFrame(                 {                     \"wealth\": pl.ones(n, eager=True),                 }             )         )\"\"\"         # 3. Adding the dataframe with __iadd__         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         # The give_money method is called         # self.give_money()         self.do(\"give_money\")      def give_money(self):         ## Active agents are changed to wealthy agents         # 1. Using the __getitem__ method         # self.select(self[\"wealth\"] &gt; 0)         # 2. Using the fallback __getattr__ method         self.select(self.wealth &gt; 0)          # Receiving agents are sampled (only native expressions currently supported)         other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)          # Wealth of wealthy is decreased by 1         # 1. Using the __setitem__ method with self.active_agents mask         # self[self.active_agents, \"wealth\"] -= 1         # 2. Using the __setitem__ method with \"active\" mask         self[\"active\", \"wealth\"] -= 1          # Compute the income of the other agents (only native expressions currently supported)         new_wealth = other_agents.group_by(\"unique_id\").len()          # Add the income to the other agents         # 1. Using the set method         \"\"\"self.set(             attr_names=\"wealth\",             values=pl.col(\"wealth\") + new_wealth[\"len\"],             mask=new_wealth,         )\"\"\"          # 2. Using the __setitem__ method         self[new_wealth, \"wealth\"] += new_wealth[\"len\"]   class MoneyAgentsNative(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.do(\"give_money\")      def give_money(self):         ## Active agents are changed to wealthy agents         self.select(pl.col(\"wealth\") &gt; 0)          other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)          # Wealth of wealthy is decreased by 1         self.df = self.df.with_columns(             wealth=pl.when(                 pl.col(\"unique_id\").is_in(self.active_agents[\"unique_id\"].implode())             )             .then(pl.col(\"wealth\") - 1)             .otherwise(pl.col(\"wealth\"))         )          new_wealth = other_agents.group_by(\"unique_id\").len()          # Add the income to the other agents         self.df = (             self.df.join(new_wealth, on=\"unique_id\", how=\"left\")             .fill_null(0)             .with_columns(wealth=pl.col(\"wealth\") + pl.col(\"len\"))             .drop(\"len\")         ) <p>Add Mesa implementation of MoneyAgent and MoneyModel classes to test Mesa performance</p> In\u00a0[7]: Copied! <pre>import mesa\n\n\nclass MesaMoneyAgent(mesa.Agent):\n    \"\"\"An agent with fixed initial wealth.\"\"\"\n\n    def __init__(self, model):\n        # Pass the parameters to the parent class.\n        super().__init__(model)\n\n        # Create the agent's variable and set the initial values.\n        self.wealth = 1\n\n    def step(self):\n        # Verify agent has some wealth\n        if self.wealth &gt; 0:\n            other_agent: MesaMoneyAgent = self.model.random.choice(self.model.agents)\n            if other_agent is not None:\n                other_agent.wealth += 1\n                self.wealth -= 1\n\n\nclass MesaMoneyModel(mesa.Model):\n    \"\"\"A model with some number of agents.\"\"\"\n\n    def __init__(self, N: int):\n        super().__init__()\n        self.num_agents = N\n        for _ in range(N):\n            self.agents.add(MesaMoneyAgent(self))\n\n    def step(self):\n        \"\"\"Advance the model by one step.\"\"\"\n        self.agents.shuffle_do(\"step\")\n\n    def run_model(self, n_steps) -&gt; None:\n        for _ in range(n_steps):\n            self.step()\n</pre> import mesa   class MesaMoneyAgent(mesa.Agent):     \"\"\"An agent with fixed initial wealth.\"\"\"      def __init__(self, model):         # Pass the parameters to the parent class.         super().__init__(model)          # Create the agent's variable and set the initial values.         self.wealth = 1      def step(self):         # Verify agent has some wealth         if self.wealth &gt; 0:             other_agent: MesaMoneyAgent = self.model.random.choice(self.model.agents)             if other_agent is not None:                 other_agent.wealth += 1                 self.wealth -= 1   class MesaMoneyModel(mesa.Model):     \"\"\"A model with some number of agents.\"\"\"      def __init__(self, N: int):         super().__init__()         self.num_agents = N         for _ in range(N):             self.agents.add(MesaMoneyAgent(self))      def step(self):         \"\"\"Advance the model by one step.\"\"\"         self.agents.shuffle_do(\"step\")      def run_model(self, n_steps) -&gt; None:         for _ in range(n_steps):             self.step() <pre>/home/runner/work/mesa-frames/mesa-frames/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[8]: Copied! <pre>import time\n\n\ndef run_simulation(model: MesaMoneyModel | MoneyModel, n_steps: int):\n    start_time = time.time()\n    model.run_model(n_steps)\n    end_time = time.time()\n    return end_time - start_time\n\n\n# Compare mesa and mesa-frames implementations\nn_agents_list = [10**2, 10**3 + 1, 2 * 10**3]\nn_steps = 100\nprint(\"Execution times:\")\nfor implementation in [\n    \"mesa\",\n    \"mesa-frames (pl concise)\",\n    \"mesa-frames (pl native)\",\n]:\n    print(f\"---------------\\n{implementation}:\")\n    for n_agents in n_agents_list:\n        if implementation == \"mesa\":\n            ntime = run_simulation(MesaMoneyModel(n_agents), n_steps)\n        elif implementation == \"mesa-frames (pl concise)\":\n            ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsConcise), n_steps)\n        elif implementation == \"mesa-frames (pl native)\":\n            ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsNative), n_steps)\n\n        print(f\"  Number of agents: {n_agents}, Time: {ntime:.2f} seconds\")\n    print(\"---------------\")\n</pre> import time   def run_simulation(model: MesaMoneyModel | MoneyModel, n_steps: int):     start_time = time.time()     model.run_model(n_steps)     end_time = time.time()     return end_time - start_time   # Compare mesa and mesa-frames implementations n_agents_list = [10**2, 10**3 + 1, 2 * 10**3] n_steps = 100 print(\"Execution times:\") for implementation in [     \"mesa\",     \"mesa-frames (pl concise)\",     \"mesa-frames (pl native)\", ]:     print(f\"---------------\\n{implementation}:\")     for n_agents in n_agents_list:         if implementation == \"mesa\":             ntime = run_simulation(MesaMoneyModel(n_agents), n_steps)         elif implementation == \"mesa-frames (pl concise)\":             ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsConcise), n_steps)         elif implementation == \"mesa-frames (pl native)\":             ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsNative), n_steps)          print(f\"  Number of agents: {n_agents}, Time: {ntime:.2f} seconds\")     print(\"---------------\") <pre>Execution times:\n---------------\nmesa:\n  Number of agents: 100, Time: 0.06 seconds\n</pre> <pre>  Number of agents: 1001, Time: 3.63 seconds\n</pre> <pre>  Number of agents: 2000, Time: 14.05 seconds\n---------------\n---------------\nmesa-frames (pl concise):\n</pre> <pre>  Number of agents: 100, Time: 0.32 seconds\n</pre> <pre>  Number of agents: 1001, Time: 0.36 seconds\n</pre> <pre>  Number of agents: 2000, Time: 0.44 seconds\n---------------\n---------------\nmesa-frames (pl native):\n  Number of agents: 100, Time: 0.15 seconds\n</pre> <pre>  Number of agents: 1001, Time: 0.18 seconds\n  Number of agents: 2000, Time: 0.18 seconds\n---------------\n</pre>"},{"location":"tutorials/2_introductory_tutorial/#installation-if-running-in-colab","title":"Installation (if running in Colab)\u00b6","text":"<p>Run the following cell to install <code>mesa-frames</code> if you are using Google Colab.</p>"},{"location":"tutorials/2_introductory_tutorial/#introductory-tutorial-boltzmann-wealth-model-with-mesa-frames","title":"Introductory Tutorial: Boltzmann Wealth Model with mesa-frames \ud83d\udcb0\ud83d\ude80\u00b6","text":"<p>In this tutorial, we'll implement the Boltzmann Wealth Model using mesa-frames. This model simulates the distribution of wealth among agents, where agents randomly give money to each other.</p>"},{"location":"tutorials/2_introductory_tutorial/#setting-up-the-model","title":"Setting Up the Model \ud83c\udfd7\ufe0f\u00b6","text":"<p>First, let's import the necessary modules and set up our model class:</p>"},{"location":"tutorials/2_introductory_tutorial/#implementing-the-agentset","title":"Implementing the AgentSet \ud83d\udc65\u00b6","text":"<p>Now, let's implement our <code>MoneyAgents</code> using polars backends.</p>"},{"location":"tutorials/2_introductory_tutorial/#running-the-model","title":"Running the Model \u25b6\ufe0f\u00b6","text":"<p>Now that we have our model and agent set defined, let's run a simulation:</p>"},{"location":"tutorials/2_introductory_tutorial/#performance-comparison","title":"Performance Comparison \ud83c\udfce\ufe0f\ud83d\udca8\u00b6","text":"<p>One of the key advantages of mesa-frames is its performance with large numbers of agents. Let's compare the performance of mesa and polars:</p>"},{"location":"tutorials/2_introductory_tutorial/#conclusion","title":"Conclusion \ud83c\udf89\u00b6","text":"<ul> <li>All mesa-frames implementations significantly outperform the original mesa implementation. \ud83c\udfc6</li> <li>The native implementation for Polars shows better performance than their concise counterparts. \ud83d\udcaa</li> <li>The Polars native implementation shows the most impressive speed-up, ranging from 10.86x to 17.60x faster than mesa! \ud83d\ude80\ud83d\ude80\ud83d\ude80</li> <li>The performance advantage of mesa-frames becomes more pronounced as the number of agents increases. \ud83d\udcc8</li> </ul>"},{"location":"tutorials/3_advanced_tutorial/","title":"Advanced Tutorial \u2014 Rebuilding Sugarscape with mesa-frames","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations <p>First, let's install and import the necessary packages.</p> <p>If you're running this tutorial on Google Colab or another fresh environment, uncomment the cell below to install the required dependencies.</p> In\u00a0[2]: Copied! <pre>#!pip install git+https://github.com/projectmesa/mesa-frames polars numba numpy\n</pre> #!pip install git+https://github.com/projectmesa/mesa-frames polars numba numpy In\u00a0[3]: Copied! <pre>from time import perf_counter\n\nimport numpy as np\nimport polars as pl\nfrom numba import njit\n\nfrom mesa_frames import AgentSet, DataCollector, Grid, Model\n\n\n# Simple display helper to render HTML in notebooks while keeping stdout\n# output for scripts/CI runs.\ndef _in_ipython() -&gt; bool:\n    \"\"\"Return True when running inside an IPython/Jupyter session.\"\"\"\n    try:\n        from IPython import get_ipython\n    except Exception:\n        return False\n    return get_ipython() is not None\n\n\ndef show_output(\n    obj: object,\n    *,\n    title: str | None = None,\n    max_rows: int = 12,\n    collapsible: bool = False,\n    open_by_default: bool = False,\n) -&gt; None:\n    \"\"\"Display rich HTML when available, otherwise fall back to prints.\"\"\"\n    rich_env = _in_ipython()\n\n    if isinstance(obj, pl.DataFrame):\n        df = obj.head(max_rows) if max_rows else obj\n        if rich_env:\n            from IPython.display import HTML, display\n\n            if collapsible:\n                open_attr = \" open\" if open_by_default else \"\"\n                summary = title or \"Table\"\n                html = df.to_pandas().to_html(index=False)\n                display(\n                    HTML(\n                        f\"\"\"\n&lt;details{open_attr} style=\"margin: 0.75em 0;\"&gt;\n  &lt;summary style=\"cursor:pointer; font-weight:600;\"&gt;{summary}&lt;/summary&gt;\n  &lt;div style=\"margin-top:0.5em;\"&gt;{html}&lt;/div&gt;\n&lt;/details&gt;\n\"\"\"\n                    )\n                )\n            else:\n                if title:\n                    display(HTML(f\"&lt;h4 style='margin: 0.6em 0 0.2em'&gt;{title}&lt;/h4&gt;\"))\n                display(df.to_pandas())\n        else:\n            if title:\n                print(f\"\\n=== {title} ===\")\n            print(df)\n        return\n\n    if title:\n        if rich_env:\n            from IPython.display import HTML, display\n\n            display(HTML(f\"&lt;h4 style='margin: 0.6em 0 0.2em'&gt;{title}&lt;/h4&gt;\"))\n        else:\n            print(f\"\\n=== {title} ===\")\n\n    if rich_env:\n        from IPython.display import display\n\n        display(obj)\n    else:\n        print(obj)\n</pre> from time import perf_counter  import numpy as np import polars as pl from numba import njit  from mesa_frames import AgentSet, DataCollector, Grid, Model   # Simple display helper to render HTML in notebooks while keeping stdout # output for scripts/CI runs. def _in_ipython() -&gt; bool:     \"\"\"Return True when running inside an IPython/Jupyter session.\"\"\"     try:         from IPython import get_ipython     except Exception:         return False     return get_ipython() is not None   def show_output(     obj: object,     *,     title: str | None = None,     max_rows: int = 12,     collapsible: bool = False,     open_by_default: bool = False, ) -&gt; None:     \"\"\"Display rich HTML when available, otherwise fall back to prints.\"\"\"     rich_env = _in_ipython()      if isinstance(obj, pl.DataFrame):         df = obj.head(max_rows) if max_rows else obj         if rich_env:             from IPython.display import HTML, display              if collapsible:                 open_attr = \" open\" if open_by_default else \"\"                 summary = title or \"Table\"                 html = df.to_pandas().to_html(index=False)                 display(                     HTML(                         f\"\"\"  {summary} {html}  \"\"\"                     )                 )             else:                 if title:                     display(HTML(f\"{title}\"))                 display(df.to_pandas())         else:             if title:                 print(f\"\\n=== {title} ===\")             print(df)         return      if title:         if rich_env:             from IPython.display import HTML, display              display(HTML(f\"{title}\"))         else:             print(f\"\\n=== {title} ===\")      if rich_env:         from IPython.display import display          display(obj)     else:         print(obj) In\u00a0[4]: Copied! <pre># Model-level reporters\n\n\ndef gini(model: Model) -&gt; float:\n    \"\"\"Compute the Gini coefficient of agent sugar holdings.\n\n    The function reads the primary agent set from ``model.sets[0]`` and\n    computes the population Gini coefficient on the ``sugar`` column. The\n    implementation is robust to empty sets and zero-total sugar.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and to expose a Polars DataFrame\n        under ``.df`` with a ``sugar`` column.\n\n    Returns\n    -------\n    float\n        Gini coefficient in the range [0, 1] if defined, ``0.0`` when the\n        total sugar is zero, and ``nan`` when the agent set is empty or too\n        small to measure.\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    sugar = primary_set.df[\"sugar\"].to_numpy().astype(np.float64)\n\n    if sugar.size == 0:\n        return float(\"nan\")\n    sorted_vals = np.sort(sugar.astype(np.float64))\n    n = sorted_vals.size\n    cumulative = np.cumsum(sorted_vals)\n    total = cumulative[-1]\n    if total == 0:\n        return 0.0\n    index = np.arange(1, n + 1, dtype=np.float64)\n    return float((2.0 * np.dot(index, sorted_vals) / (n * total)) - (n + 1) / n)\n\n\ndef corr_sugar_metabolism(model: Model) -&gt; float:\n    \"\"\"Pearson correlation between agent sugar and metabolism.\n\n    This reporter extracts the ``sugar`` and ``metabolism`` columns from the\n    primary agent set and returns their Pearson correlation coefficient. When\n    the agent set is empty or contains insufficient variation the function\n    returns ``nan``.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and provide a Polars DataFrame\n        with ``sugar`` and ``metabolism`` columns.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient between sugar and metabolism, or\n        ``nan`` when the correlation is undefined (empty set or constant\n        values).\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    agent_df = primary_set.df\n    sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)\n    metabolism = agent_df[\"metabolism\"].to_numpy().astype(np.float64)\n    return _safe_corr(sugar, metabolism)\n\n\ndef corr_sugar_vision(model: Model) -&gt; float:\n    \"\"\"Pearson correlation between agent sugar and vision.\n\n    Extracts the ``sugar`` and ``vision`` columns from the primary agent set\n    and returns their Pearson correlation coefficient. If the reporter cannot\n    compute a meaningful correlation (for example, when the agent set is\n    empty or values are constant) it returns ``nan``.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and provide a Polars DataFrame\n        with ``sugar`` and ``vision`` columns.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient between sugar and vision, or ``nan``\n        when the correlation is undefined.\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    agent_df = primary_set.df\n    sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)\n    vision = agent_df[\"vision\"].to_numpy().astype(np.float64)\n    return _safe_corr(sugar, vision)\n\n\ndef _safe_corr(x: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Safely compute Pearson correlation between two 1-D arrays.\n\n    This helper guards against degenerate inputs (too few observations or\n    constant arrays) which would make the Pearson correlation undefined or\n    numerically unstable. When a valid correlation can be computed the\n    function returns a Python float.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        One-dimensional numeric array containing the first variable to\n        correlate.\n    y : np.ndarray\n        One-dimensional numeric array containing the second variable to\n        correlate.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient as a Python float, or ``nan`` if the\n        correlation is undefined (fewer than 2 observations or constant\n        inputs).\n    \"\"\"\n    if x.size &lt; 2 or y.size &lt; 2:\n        return float(\"nan\")\n    if np.allclose(x, x[0]) or np.allclose(y, y[0]):\n        return float(\"nan\")\n    return float(np.corrcoef(x, y)[0, 1])\n\n\nclass Sugarscape(Model):\n    \"\"\"Minimal Sugarscape model used throughout the tutorial.\n\n    This class wires together a grid that stores ``sugar`` per cell, an\n    agent set implementation (passed in as ``agent_type``), and a\n    data collector that records model- and agent-level statistics.\n\n    The model's responsibilities are to:\n    - create the sugar landscape (cells with current and maximum sugar)\n    - create and place agents on the grid\n    - advance the sugar regrowth rule each step\n    - run the model for a fixed number of steps and collect data\n\n    Parameters\n    ----------\n    agent_type : type[AntsBase]\n        The :class:`AgentSet` subclass implementing the movement rules\n        (sequential, numba-accelerated, or parallel).\n    n_agents : int\n        Number of agents to create and place on the grid.\n    width : int\n        Grid width (number of columns).\n    height : int\n        Grid height (number of rows).\n    max_sugar : int, optional\n        Upper bound for the randomly initialised sugar values on the grid,\n        by default 4.\n    seed : int | None, optional\n        RNG seed to make runs reproducible across variants, by default None.\n\n    Notes\n    -----\n    The grid uses a von Neumann neighbourhood and capacity 1 (at most one\n    agent per cell). Both the sugar landscape and initial agent traits are\n    drawn from ``self.random`` so different movement variants can be\n    instantiated with identical initial conditions by passing the same seed.\n    \"\"\"\n\n    def __init__(\n        self,\n        agent_type: type[AntsBase],\n        n_agents: int,\n        *,\n        width: int,\n        height: int,\n        max_sugar: int = 4,\n        seed: int | None = None,\n    ) -&gt; None:\n        if n_agents &gt; width * height:\n            raise ValueError(\n                \"Cannot place more agents than grid cells when capacity is 1.\"\n            )\n        super().__init__(seed)\n\n        # 1. Let's create the sugar grid and set up the space\n\n        sugar_grid_df = self._generate_sugar_grid(width, height, max_sugar)\n        self.space = Grid(\n            self, [width, height], neighborhood_type=\"von_neumann\", capacity=1\n        )\n        self.space.set_cells(sugar_grid_df)\n        self._max_sugar = sugar_grid_df.select([\"dim_0\", \"dim_1\", \"max_sugar\"])\n\n        # 2. Now we create the agents and place them on the grid\n\n        agent_frame = self._generate_agent_frame(n_agents)\n        main_set = agent_type(self, agent_frame)\n        self.sets += main_set\n        self.space.place_to_empty(self.sets)\n\n        # 3. Finally we set up the data collector\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"mean_sugar\": lambda m: 0.0\n                if len(m.sets[0]) == 0\n                else float(m.sets[0].df[\"sugar\"].mean()),\n                \"total_sugar\": lambda m: float(m.sets[0].df[\"sugar\"].sum())\n                if len(m.sets[0])\n                else 0.0,\n                \"agents_alive\": lambda m: float(len(m.sets[0])) if len(m.sets) else 0.0,\n                \"gini\": gini,\n                \"corr_sugar_metabolism\": corr_sugar_metabolism,\n                \"corr_sugar_vision\": corr_sugar_vision,\n            },\n            agent_reporters={\n                \"sugar\": \"sugar\",\n                \"metabolism\": \"metabolism\",\n                \"vision\": \"vision\",\n            },\n        )\n        self.datacollector.collect()\n\n    def _generate_sugar_grid(\n        self, width: int, height: int, max_sugar: int\n    ) -&gt; pl.DataFrame:\n        \"\"\"Generate a random sugar grid.\n\n        Parameters\n        ----------\n        width : int\n            Grid width (number of columns).\n        height : int\n            Grid height (number of rows).\n        max_sugar : int\n            Maximum sugar value (inclusive) for each cell.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``dim_0``, ``dim_1``, ``sugar`` (current\n            amount) and ``max_sugar`` (regrowth target).\n        \"\"\"\n        sugar_vals = self.random.integers(\n            0, max_sugar + 1, size=(width, height), dtype=np.int64\n        )\n        dim_0 = pl.Series(\"dim_0\", pl.arange(width, eager=True)).to_frame()\n        dim_1 = pl.Series(\"dim_1\", pl.arange(height, eager=True)).to_frame()\n        return dim_0.join(dim_1, how=\"cross\").with_columns(\n            sugar=sugar_vals.flatten(), max_sugar=sugar_vals.flatten()\n        )\n\n    def _generate_agent_frame(self, n_agents: int) -&gt; pl.DataFrame:\n        \"\"\"Create the initial agent frame populated with agent traits.\n\n        Parameters\n        ----------\n        n_agents : int\n            Number of agents to create.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``sugar``, ``metabolism`` and ``vision``\n            (integer values) for each agent.\n        \"\"\"\n        rng = self.random\n        return pl.DataFrame(\n            {\n                \"sugar\": rng.integers(6, 25, size=n_agents, dtype=np.int64),\n                \"metabolism\": rng.integers(2, 5, size=n_agents, dtype=np.int64),\n                \"vision\": rng.integers(1, 6, size=n_agents, dtype=np.int64),\n            }\n        )\n\n    def step(self) -&gt; None:\n        \"\"\"Advance the model by one step.\n\n        Notes\n        -----\n        The per-step ordering is important and this tutorial implements the\n        classic Sugarscape \"instant growback\": agents move and eat first,\n        and then empty cells are refilled immediately (move -&gt; eat -&gt; regrow\n        -&gt; collect).\n        \"\"\"\n        if len(self.sets[0]) == 0:\n            self.running = False\n            return\n        self.sets[0].step()\n        self._advance_sugar_field()\n        self.datacollector.collect()\n\n    def run(self, steps: int) -&gt; None:\n        \"\"\"Run the model for a fixed number of steps.\n\n        Parameters\n        ----------\n        steps : int\n            Maximum number of steps to run. The model may terminate earlier if\n            ``self.running`` is set to ``False`` (for example, when all agents\n            have died).\n        \"\"\"\n        for _ in range(steps):\n            if not self.running:\n                break\n            self.step()\n\n    def _advance_sugar_field(self) -&gt; None:\n        \"\"\"Apply the instant-growback sugar regrowth rule.\n\n        Empty cells (no agent present) are refilled to their ``max_sugar``\n        value. Occupied cells have already been harvested in\n        :meth:`AntsBase.eat`, so we only need to refresh empty cells here.\n        The method uses vectorised DataFrame joins and writes to keep the\n        operation efficient.\n        \"\"\"\n        empty_cells = self.space.empty_cells\n        if not empty_cells.is_empty():\n            # Look up the maximum sugar for each empty cell and restore it.\n            refresh = empty_cells.join(\n                self._max_sugar, on=[\"dim_0\", \"dim_1\"], how=\"left\"\n            )\n            self.space.set_cells(empty_cells, {\"sugar\": refresh[\"max_sugar\"]})\n</pre>  # Model-level reporters   def gini(model: Model) -&gt; float:     \"\"\"Compute the Gini coefficient of agent sugar holdings.      The function reads the primary agent set from ``model.sets[0]`` and     computes the population Gini coefficient on the ``sugar`` column. The     implementation is robust to empty sets and zero-total sugar.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and to expose a Polars DataFrame         under ``.df`` with a ``sugar`` column.      Returns     -------     float         Gini coefficient in the range [0, 1] if defined, ``0.0`` when the         total sugar is zero, and ``nan`` when the agent set is empty or too         small to measure.     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      sugar = primary_set.df[\"sugar\"].to_numpy().astype(np.float64)      if sugar.size == 0:         return float(\"nan\")     sorted_vals = np.sort(sugar.astype(np.float64))     n = sorted_vals.size     cumulative = np.cumsum(sorted_vals)     total = cumulative[-1]     if total == 0:         return 0.0     index = np.arange(1, n + 1, dtype=np.float64)     return float((2.0 * np.dot(index, sorted_vals) / (n * total)) - (n + 1) / n)   def corr_sugar_metabolism(model: Model) -&gt; float:     \"\"\"Pearson correlation between agent sugar and metabolism.      This reporter extracts the ``sugar`` and ``metabolism`` columns from the     primary agent set and returns their Pearson correlation coefficient. When     the agent set is empty or contains insufficient variation the function     returns ``nan``.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and provide a Polars DataFrame         with ``sugar`` and ``metabolism`` columns.      Returns     -------     float         Pearson correlation coefficient between sugar and metabolism, or         ``nan`` when the correlation is undefined (empty set or constant         values).     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      agent_df = primary_set.df     sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)     metabolism = agent_df[\"metabolism\"].to_numpy().astype(np.float64)     return _safe_corr(sugar, metabolism)   def corr_sugar_vision(model: Model) -&gt; float:     \"\"\"Pearson correlation between agent sugar and vision.      Extracts the ``sugar`` and ``vision`` columns from the primary agent set     and returns their Pearson correlation coefficient. If the reporter cannot     compute a meaningful correlation (for example, when the agent set is     empty or values are constant) it returns ``nan``.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and provide a Polars DataFrame         with ``sugar`` and ``vision`` columns.      Returns     -------     float         Pearson correlation coefficient between sugar and vision, or ``nan``         when the correlation is undefined.     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      agent_df = primary_set.df     sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)     vision = agent_df[\"vision\"].to_numpy().astype(np.float64)     return _safe_corr(sugar, vision)   def _safe_corr(x: np.ndarray, y: np.ndarray) -&gt; float:     \"\"\"Safely compute Pearson correlation between two 1-D arrays.      This helper guards against degenerate inputs (too few observations or     constant arrays) which would make the Pearson correlation undefined or     numerically unstable. When a valid correlation can be computed the     function returns a Python float.      Parameters     ----------     x : np.ndarray         One-dimensional numeric array containing the first variable to         correlate.     y : np.ndarray         One-dimensional numeric array containing the second variable to         correlate.      Returns     -------     float         Pearson correlation coefficient as a Python float, or ``nan`` if the         correlation is undefined (fewer than 2 observations or constant         inputs).     \"\"\"     if x.size &lt; 2 or y.size &lt; 2:         return float(\"nan\")     if np.allclose(x, x[0]) or np.allclose(y, y[0]):         return float(\"nan\")     return float(np.corrcoef(x, y)[0, 1])   class Sugarscape(Model):     \"\"\"Minimal Sugarscape model used throughout the tutorial.      This class wires together a grid that stores ``sugar`` per cell, an     agent set implementation (passed in as ``agent_type``), and a     data collector that records model- and agent-level statistics.      The model's responsibilities are to:     - create the sugar landscape (cells with current and maximum sugar)     - create and place agents on the grid     - advance the sugar regrowth rule each step     - run the model for a fixed number of steps and collect data      Parameters     ----------     agent_type : type[AntsBase]         The :class:`AgentSet` subclass implementing the movement rules         (sequential, numba-accelerated, or parallel).     n_agents : int         Number of agents to create and place on the grid.     width : int         Grid width (number of columns).     height : int         Grid height (number of rows).     max_sugar : int, optional         Upper bound for the randomly initialised sugar values on the grid,         by default 4.     seed : int | None, optional         RNG seed to make runs reproducible across variants, by default None.      Notes     -----     The grid uses a von Neumann neighbourhood and capacity 1 (at most one     agent per cell). Both the sugar landscape and initial agent traits are     drawn from ``self.random`` so different movement variants can be     instantiated with identical initial conditions by passing the same seed.     \"\"\"      def __init__(         self,         agent_type: type[AntsBase],         n_agents: int,         *,         width: int,         height: int,         max_sugar: int = 4,         seed: int | None = None,     ) -&gt; None:         if n_agents &gt; width * height:             raise ValueError(                 \"Cannot place more agents than grid cells when capacity is 1.\"             )         super().__init__(seed)          # 1. Let's create the sugar grid and set up the space          sugar_grid_df = self._generate_sugar_grid(width, height, max_sugar)         self.space = Grid(             self, [width, height], neighborhood_type=\"von_neumann\", capacity=1         )         self.space.set_cells(sugar_grid_df)         self._max_sugar = sugar_grid_df.select([\"dim_0\", \"dim_1\", \"max_sugar\"])          # 2. Now we create the agents and place them on the grid          agent_frame = self._generate_agent_frame(n_agents)         main_set = agent_type(self, agent_frame)         self.sets += main_set         self.space.place_to_empty(self.sets)          # 3. Finally we set up the data collector         self.datacollector = DataCollector(             model=self,             model_reporters={                 \"mean_sugar\": lambda m: 0.0                 if len(m.sets[0]) == 0                 else float(m.sets[0].df[\"sugar\"].mean()),                 \"total_sugar\": lambda m: float(m.sets[0].df[\"sugar\"].sum())                 if len(m.sets[0])                 else 0.0,                 \"agents_alive\": lambda m: float(len(m.sets[0])) if len(m.sets) else 0.0,                 \"gini\": gini,                 \"corr_sugar_metabolism\": corr_sugar_metabolism,                 \"corr_sugar_vision\": corr_sugar_vision,             },             agent_reporters={                 \"sugar\": \"sugar\",                 \"metabolism\": \"metabolism\",                 \"vision\": \"vision\",             },         )         self.datacollector.collect()      def _generate_sugar_grid(         self, width: int, height: int, max_sugar: int     ) -&gt; pl.DataFrame:         \"\"\"Generate a random sugar grid.          Parameters         ----------         width : int             Grid width (number of columns).         height : int             Grid height (number of rows).         max_sugar : int             Maximum sugar value (inclusive) for each cell.          Returns         -------         pl.DataFrame             DataFrame with columns ``dim_0``, ``dim_1``, ``sugar`` (current             amount) and ``max_sugar`` (regrowth target).         \"\"\"         sugar_vals = self.random.integers(             0, max_sugar + 1, size=(width, height), dtype=np.int64         )         dim_0 = pl.Series(\"dim_0\", pl.arange(width, eager=True)).to_frame()         dim_1 = pl.Series(\"dim_1\", pl.arange(height, eager=True)).to_frame()         return dim_0.join(dim_1, how=\"cross\").with_columns(             sugar=sugar_vals.flatten(), max_sugar=sugar_vals.flatten()         )      def _generate_agent_frame(self, n_agents: int) -&gt; pl.DataFrame:         \"\"\"Create the initial agent frame populated with agent traits.          Parameters         ----------         n_agents : int             Number of agents to create.          Returns         -------         pl.DataFrame             DataFrame with columns ``sugar``, ``metabolism`` and ``vision``             (integer values) for each agent.         \"\"\"         rng = self.random         return pl.DataFrame(             {                 \"sugar\": rng.integers(6, 25, size=n_agents, dtype=np.int64),                 \"metabolism\": rng.integers(2, 5, size=n_agents, dtype=np.int64),                 \"vision\": rng.integers(1, 6, size=n_agents, dtype=np.int64),             }         )      def step(self) -&gt; None:         \"\"\"Advance the model by one step.          Notes         -----         The per-step ordering is important and this tutorial implements the         classic Sugarscape \"instant growback\": agents move and eat first,         and then empty cells are refilled immediately (move -&gt; eat -&gt; regrow         -&gt; collect).         \"\"\"         if len(self.sets[0]) == 0:             self.running = False             return         self.sets[0].step()         self._advance_sugar_field()         self.datacollector.collect()      def run(self, steps: int) -&gt; None:         \"\"\"Run the model for a fixed number of steps.          Parameters         ----------         steps : int             Maximum number of steps to run. The model may terminate earlier if             ``self.running`` is set to ``False`` (for example, when all agents             have died).         \"\"\"         for _ in range(steps):             if not self.running:                 break             self.step()      def _advance_sugar_field(self) -&gt; None:         \"\"\"Apply the instant-growback sugar regrowth rule.          Empty cells (no agent present) are refilled to their ``max_sugar``         value. Occupied cells have already been harvested in         :meth:`AntsBase.eat`, so we only need to refresh empty cells here.         The method uses vectorised DataFrame joins and writes to keep the         operation efficient.         \"\"\"         empty_cells = self.space.empty_cells         if not empty_cells.is_empty():             # Look up the maximum sugar for each empty cell and restore it.             refresh = empty_cells.join(                 self._max_sugar, on=[\"dim_0\", \"dim_1\"], how=\"left\"             )             self.space.set_cells(empty_cells, {\"sugar\": refresh[\"max_sugar\"]}) In\u00a0[5]: Copied! <pre>class AntsBase(AgentSet):\n    \"\"\"Base agent set for the Sugarscape tutorial.\n\n    This class implements the common behaviour shared by all agent\n    movement variants (sequential, numba-accelerated and parallel).\n\n    Notes\n    -----\n    - Agents are expected to have integer traits: ``sugar``, ``metabolism``\n      and ``vision``. These are validated in :meth:`__init__`.\n    - Subclasses must implement :meth:`move` which changes agent positions\n      on the grid (via :meth:`mesa_frames.Grid` helpers).\n    \"\"\"\n\n    def __init__(self, model: Model, agent_frame: pl.DataFrame) -&gt; None:\n        \"\"\"Initialise the agent set and validate required trait columns.\n\n        Parameters\n        ----------\n        model : Model\n            The parent model which provides RNG and space.\n        agent_frame : pl.DataFrame\n            A Polars DataFrame with at least the columns ``sugar``,\n            ``metabolism`` and ``vision`` for each agent.\n\n        Raises\n        ------\n        ValueError\n            If required trait columns are missing from ``agent_frame``.\n        \"\"\"\n        super().__init__(model)\n        required = {\"sugar\", \"metabolism\", \"vision\"}\n        missing = required.difference(agent_frame.columns)\n        if missing:\n            raise ValueError(\n                f\"Initial agent frame must include columns {sorted(required)}; missing {sorted(missing)}.\"\n            )\n        self.add(agent_frame.clone())\n\n    def step(self) -&gt; None:\n        \"\"\"Advance the agent set by one time step.\n\n        The update order is important: agents are first shuffled to randomise\n        move order (this is important only for sequential variants), then they move, harvest sugar\n        from their occupied cells, and finally any agents whose sugar falls\n        to zero or below are removed.\n        \"\"\"\n        # Randomise ordering for movement decisions when required by the\n        # implementation (e.g. sequential update uses this shuffle).\n        self.shuffle(inplace=True)\n        # Movement policy implemented by subclasses.\n        self.move()\n        # Agents harvest sugar on their occupied cells.\n        self.eat()\n        # Remove agents that starved after eating.\n        self._remove_starved()\n\n    def move(self) -&gt; None:  # pragma: no cover\n        \"\"\"Abstract movement method.\n\n        Subclasses must override this method to update agent positions on the\n        grid. Implementations should use :meth:`mesa_frames.Grid.move_agents`\n        or similar helpers provided by the space API.\n        \"\"\"\n        raise NotImplementedError\n\n    def eat(self) -&gt; None:\n        \"\"\"Agents harvest sugar from the cells they currently occupy.\n\n        Behaviour:\n        - Look up the set of occupied cells (cells that reference an agent\n          id).\n        - For each occupied cell, add the cell sugar to the agent's sugar\n          stock and subtract the agent's metabolism cost.\n        - After agents harvest, set the sugar on those cells to zero (they\n          were consumed).\n        \"\"\"\n        # Map of currently occupied agent ids on the grid.\n        occupied_ids = self.index\n        # `occupied_ids` is a Polars Series; calling `is_in` with a Series\n        # of the same datatype is ambiguous in newer Polars. Use `implode`\n        # to collapse the Series into a list-like value for membership checks.\n        occupied_cells = self.space.cells.filter(\n            pl.col(\"agent_id\").is_in(occupied_ids.implode())\n        )\n        if occupied_cells.is_empty():\n            return\n        # The agent ordering here uses the agent_id values stored in the\n        # occupied cells frame; indexing the agent set with that vector updates\n        # the matching agents' sugar values in one vectorised write.\n        agent_ids = occupied_cells[\"agent_id\"]\n        self[agent_ids, \"sugar\"] = (\n            self[agent_ids, \"sugar\"]\n            + occupied_cells[\"sugar\"]\n            - self[agent_ids, \"metabolism\"]\n        )\n        # After harvesting, occupied cells have zero sugar.\n        self.space.set_cells(\n            occupied_cells.select([\"dim_0\", \"dim_1\"]),\n            {\"sugar\": pl.Series(np.zeros(len(occupied_cells), dtype=np.int64))},\n        )\n\n    def _remove_starved(self) -&gt; None:\n        \"\"\"Discard agents whose sugar stock has fallen to zero or below.\n\n        This method performs a vectorised filter on the agent frame and\n        removes any matching rows from the set.\n        \"\"\"\n        starved = self.df.filter(pl.col(\"sugar\") &lt;= 0)\n        if not starved.is_empty():\n            # ``discard`` accepts a DataFrame of agents to remove.\n            self.discard(starved)\n</pre>   class AntsBase(AgentSet):     \"\"\"Base agent set for the Sugarscape tutorial.      This class implements the common behaviour shared by all agent     movement variants (sequential, numba-accelerated and parallel).      Notes     -----     - Agents are expected to have integer traits: ``sugar``, ``metabolism``       and ``vision``. These are validated in :meth:`__init__`.     - Subclasses must implement :meth:`move` which changes agent positions       on the grid (via :meth:`mesa_frames.Grid` helpers).     \"\"\"      def __init__(self, model: Model, agent_frame: pl.DataFrame) -&gt; None:         \"\"\"Initialise the agent set and validate required trait columns.          Parameters         ----------         model : Model             The parent model which provides RNG and space.         agent_frame : pl.DataFrame             A Polars DataFrame with at least the columns ``sugar``,             ``metabolism`` and ``vision`` for each agent.          Raises         ------         ValueError             If required trait columns are missing from ``agent_frame``.         \"\"\"         super().__init__(model)         required = {\"sugar\", \"metabolism\", \"vision\"}         missing = required.difference(agent_frame.columns)         if missing:             raise ValueError(                 f\"Initial agent frame must include columns {sorted(required)}; missing {sorted(missing)}.\"             )         self.add(agent_frame.clone())      def step(self) -&gt; None:         \"\"\"Advance the agent set by one time step.          The update order is important: agents are first shuffled to randomise         move order (this is important only for sequential variants), then they move, harvest sugar         from their occupied cells, and finally any agents whose sugar falls         to zero or below are removed.         \"\"\"         # Randomise ordering for movement decisions when required by the         # implementation (e.g. sequential update uses this shuffle).         self.shuffle(inplace=True)         # Movement policy implemented by subclasses.         self.move()         # Agents harvest sugar on their occupied cells.         self.eat()         # Remove agents that starved after eating.         self._remove_starved()      def move(self) -&gt; None:  # pragma: no cover         \"\"\"Abstract movement method.          Subclasses must override this method to update agent positions on the         grid. Implementations should use :meth:`mesa_frames.Grid.move_agents`         or similar helpers provided by the space API.         \"\"\"         raise NotImplementedError      def eat(self) -&gt; None:         \"\"\"Agents harvest sugar from the cells they currently occupy.          Behaviour:         - Look up the set of occupied cells (cells that reference an agent           id).         - For each occupied cell, add the cell sugar to the agent's sugar           stock and subtract the agent's metabolism cost.         - After agents harvest, set the sugar on those cells to zero (they           were consumed).         \"\"\"         # Map of currently occupied agent ids on the grid.         occupied_ids = self.index         # `occupied_ids` is a Polars Series; calling `is_in` with a Series         # of the same datatype is ambiguous in newer Polars. Use `implode`         # to collapse the Series into a list-like value for membership checks.         occupied_cells = self.space.cells.filter(             pl.col(\"agent_id\").is_in(occupied_ids.implode())         )         if occupied_cells.is_empty():             return         # The agent ordering here uses the agent_id values stored in the         # occupied cells frame; indexing the agent set with that vector updates         # the matching agents' sugar values in one vectorised write.         agent_ids = occupied_cells[\"agent_id\"]         self[agent_ids, \"sugar\"] = (             self[agent_ids, \"sugar\"]             + occupied_cells[\"sugar\"]             - self[agent_ids, \"metabolism\"]         )         # After harvesting, occupied cells have zero sugar.         self.space.set_cells(             occupied_cells.select([\"dim_0\", \"dim_1\"]),             {\"sugar\": pl.Series(np.zeros(len(occupied_cells), dtype=np.int64))},         )      def _remove_starved(self) -&gt; None:         \"\"\"Discard agents whose sugar stock has fallen to zero or below.          This method performs a vectorised filter on the agent frame and         removes any matching rows from the set.         \"\"\"         starved = self.df.filter(pl.col(\"sugar\") &lt;= 0)         if not starved.is_empty():             # ``discard`` accepts a DataFrame of agents to remove.             self.discard(starved) In\u00a0[6]: Copied! <pre>class AntsSequential(AntsBase):\n    def _visible_cells(\n        self, origin: tuple[int, int], vision: int\n    ) -&gt; list[tuple[int, int]]:\n        \"\"\"List cells visible from an origin along the four cardinal axes.\n\n        The visibility set includes the origin cell itself and cells at\n        Manhattan distances 1..vision along the four cardinal directions\n        (up, down, left, right), clipped to the grid bounds.\n\n        Parameters\n        ----------\n        origin : tuple[int, int]\n            The agent's current coordinate ``(x, y)``.\n        vision : int\n            Maximum Manhattan radius to consider along each axis.\n\n        Returns\n        -------\n        list[tuple[int, int]]\n            Ordered list of visible cells (origin first, then increasing\n            step distance along each axis).\n        \"\"\"\n        x0, y0 = origin\n        width, height = self.space.dimensions\n        cells: list[tuple[int, int]] = [origin]\n        # Look outward one step at a time in the four cardinal directions.\n        for step in range(1, vision + 1):\n            if x0 + step &lt; width:\n                cells.append((x0 + step, y0))\n            if x0 - step &gt;= 0:\n                cells.append((x0 - step, y0))\n            if y0 + step &lt; height:\n                cells.append((x0, y0 + step))\n            if y0 - step &gt;= 0:\n                cells.append((x0, y0 - step))\n        return cells\n\n    def _choose_best_cell(\n        self,\n        origin: tuple[int, int],\n        vision: int,\n        sugar_map: dict[tuple[int, int], int],\n        blocked: set[tuple[int, int]] | None,\n    ) -&gt; tuple[int, int]:\n        \"\"\"Select the best visible cell according to the movement rules.\n\n        Tie-break rules (in order):\n        1. Prefer cells with strictly greater sugar.\n        2. If equal sugar, prefer the cell with smaller distance from the\n           origin (measured with the Frobenius norm returned by\n           ``space.get_distances``).\n        3. If still tied, prefer the cell with smaller coordinates (lexicographic\n           ordering of the ``(x, y)`` tuple).\n\n        Parameters\n        ----------\n        origin : tuple[int, int]\n            Agent's current coordinate.\n        vision : int\n            Maximum vision radius along cardinal axes.\n        sugar_map : dict[tuple[int, int], int]\n            Mapping from ``(x, y)`` to sugar amount.\n        blocked : set[tuple[int, int]] | None\n            Optional set of coordinates that should be considered occupied and\n            therefore skipped (except the origin which is always allowed).\n\n        Returns\n        -------\n        tuple[int, int]\n            Chosen target coordinate (may be the origin if no better cell is\n            available).\n        \"\"\"\n        best_cell = origin\n        best_sugar = sugar_map.get(origin, 0)\n        best_distance = 0\n        ox, oy = origin\n        for candidate in self._visible_cells(origin, vision):\n            # Skip blocked cells (occupied by other agents) unless it's the\n            # agent's current cell which we always consider.\n            if blocked and candidate != origin and candidate in blocked:\n                continue\n            sugar_here = sugar_map.get(candidate, 0)\n            # Use step-based Manhattan distance (number of steps along cardinal\n            # axes) which is the same metric used by the Numba path. This avoids\n            # calling the heavier `space.get_distances` per candidate.\n            cx, cy = candidate\n            distance = abs(cx - ox) + abs(cy - oy)\n            better = False\n            # Primary criterion: strictly more sugar.\n            if sugar_here &gt; best_sugar:\n                better = True\n            elif sugar_here == best_sugar:\n                # Secondary: closer distance.\n                if distance &lt; best_distance:\n                    better = True\n                # Tertiary: lexicographic tie-break on coordinates.\n                elif distance == best_distance and candidate &lt; best_cell:\n                    better = True\n            if better:\n                best_cell = candidate\n                best_sugar = sugar_here\n                best_distance = distance\n        return best_cell\n\n    def _current_sugar_map(self) -&gt; dict[tuple[int, int], int]:\n        \"\"\"Return a mapping from grid coordinates to the current sugar value.\n\n        Returns\n        -------\n        dict[tuple[int, int], int]\n            Keys are ``(x, y)`` tuples and values are the integer sugar amount\n            on that cell (zero if missing/None).\n        \"\"\"\n        cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])\n        # Build a plain Python dict for fast lookups in the movement code.\n        return {\n            (int(x), int(y)): 0 if sugar is None else int(sugar)\n            for x, y, sugar in cells.iter_rows()\n        }\n\n    def move(self) -&gt; None:\n        sugar_map = self._current_sugar_map()\n        state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")\n        positions = {\n            int(row[\"unique_id\"]): (int(row[\"dim_0\"]), int(row[\"dim_1\"]))\n            for row in state.iter_rows(named=True)\n        }\n        taken: set[tuple[int, int]] = set(positions.values())\n\n        for row in state.iter_rows(named=True):\n            agent_id = int(row[\"unique_id\"])\n            vision = int(row[\"vision\"])\n            current = positions[agent_id]\n            taken.discard(current)\n            target = self._choose_best_cell(current, vision, sugar_map, taken)\n            taken.add(target)\n            positions[agent_id] = target\n            if target != current:\n                self.space.move_agents(agent_id, target)\n</pre>   class AntsSequential(AntsBase):     def _visible_cells(         self, origin: tuple[int, int], vision: int     ) -&gt; list[tuple[int, int]]:         \"\"\"List cells visible from an origin along the four cardinal axes.          The visibility set includes the origin cell itself and cells at         Manhattan distances 1..vision along the four cardinal directions         (up, down, left, right), clipped to the grid bounds.          Parameters         ----------         origin : tuple[int, int]             The agent's current coordinate ``(x, y)``.         vision : int             Maximum Manhattan radius to consider along each axis.          Returns         -------         list[tuple[int, int]]             Ordered list of visible cells (origin first, then increasing             step distance along each axis).         \"\"\"         x0, y0 = origin         width, height = self.space.dimensions         cells: list[tuple[int, int]] = [origin]         # Look outward one step at a time in the four cardinal directions.         for step in range(1, vision + 1):             if x0 + step &lt; width:                 cells.append((x0 + step, y0))             if x0 - step &gt;= 0:                 cells.append((x0 - step, y0))             if y0 + step &lt; height:                 cells.append((x0, y0 + step))             if y0 - step &gt;= 0:                 cells.append((x0, y0 - step))         return cells      def _choose_best_cell(         self,         origin: tuple[int, int],         vision: int,         sugar_map: dict[tuple[int, int], int],         blocked: set[tuple[int, int]] | None,     ) -&gt; tuple[int, int]:         \"\"\"Select the best visible cell according to the movement rules.          Tie-break rules (in order):         1. Prefer cells with strictly greater sugar.         2. If equal sugar, prefer the cell with smaller distance from the            origin (measured with the Frobenius norm returned by            ``space.get_distances``).         3. If still tied, prefer the cell with smaller coordinates (lexicographic            ordering of the ``(x, y)`` tuple).          Parameters         ----------         origin : tuple[int, int]             Agent's current coordinate.         vision : int             Maximum vision radius along cardinal axes.         sugar_map : dict[tuple[int, int], int]             Mapping from ``(x, y)`` to sugar amount.         blocked : set[tuple[int, int]] | None             Optional set of coordinates that should be considered occupied and             therefore skipped (except the origin which is always allowed).          Returns         -------         tuple[int, int]             Chosen target coordinate (may be the origin if no better cell is             available).         \"\"\"         best_cell = origin         best_sugar = sugar_map.get(origin, 0)         best_distance = 0         ox, oy = origin         for candidate in self._visible_cells(origin, vision):             # Skip blocked cells (occupied by other agents) unless it's the             # agent's current cell which we always consider.             if blocked and candidate != origin and candidate in blocked:                 continue             sugar_here = sugar_map.get(candidate, 0)             # Use step-based Manhattan distance (number of steps along cardinal             # axes) which is the same metric used by the Numba path. This avoids             # calling the heavier `space.get_distances` per candidate.             cx, cy = candidate             distance = abs(cx - ox) + abs(cy - oy)             better = False             # Primary criterion: strictly more sugar.             if sugar_here &gt; best_sugar:                 better = True             elif sugar_here == best_sugar:                 # Secondary: closer distance.                 if distance &lt; best_distance:                     better = True                 # Tertiary: lexicographic tie-break on coordinates.                 elif distance == best_distance and candidate &lt; best_cell:                     better = True             if better:                 best_cell = candidate                 best_sugar = sugar_here                 best_distance = distance         return best_cell      def _current_sugar_map(self) -&gt; dict[tuple[int, int], int]:         \"\"\"Return a mapping from grid coordinates to the current sugar value.          Returns         -------         dict[tuple[int, int], int]             Keys are ``(x, y)`` tuples and values are the integer sugar amount             on that cell (zero if missing/None).         \"\"\"         cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])         # Build a plain Python dict for fast lookups in the movement code.         return {             (int(x), int(y)): 0 if sugar is None else int(sugar)             for x, y, sugar in cells.iter_rows()         }      def move(self) -&gt; None:         sugar_map = self._current_sugar_map()         state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")         positions = {             int(row[\"unique_id\"]): (int(row[\"dim_0\"]), int(row[\"dim_1\"]))             for row in state.iter_rows(named=True)         }         taken: set[tuple[int, int]] = set(positions.values())          for row in state.iter_rows(named=True):             agent_id = int(row[\"unique_id\"])             vision = int(row[\"vision\"])             current = positions[agent_id]             taken.discard(current)             target = self._choose_best_cell(current, vision, sugar_map, taken)             taken.add(target)             positions[agent_id] = target             if target != current:                 self.space.move_agents(agent_id, target) In\u00a0[7]: Copied! <pre>@njit(cache=True)\ndef _numba_should_replace(\n    best_sugar: int,\n    best_distance: int,\n    best_x: int,\n    best_y: int,\n    candidate_sugar: int,\n    candidate_distance: int,\n    candidate_x: int,\n    candidate_y: int,\n) -&gt; bool:\n    \"\"\"Numba helper: decide whether a candidate cell should replace the\n    current best cell according to the movement tie-break rules.\n\n    This implements the same ordering used in :meth:`_choose_best_cell` but\n    in a tightly-typed, compiled form suitable for Numba loops.\n\n    Parameters\n    ----------\n    best_sugar : int\n        Sugar at the current best cell.\n    best_distance : int\n        Manhattan distance from the origin to the current best cell.\n    best_x : int\n        X coordinate of the current best cell.\n    best_y : int\n        Y coordinate of the current best cell.\n    candidate_sugar : int\n        Sugar at the candidate cell.\n    candidate_distance : int\n        Manhattan distance from the origin to the candidate cell.\n    candidate_x : int\n        X coordinate of the candidate cell.\n    candidate_y : int\n        Y coordinate of the candidate cell.\n\n    Returns\n    -------\n    bool\n        True if the candidate should replace the current best cell.\n    \"\"\"\n    # Primary criterion: prefer strictly greater sugar.\n    if candidate_sugar &gt; best_sugar:\n        return True\n    # If sugar ties, prefer the closer cell.\n    if candidate_sugar == best_sugar:\n        if candidate_distance &lt; best_distance:\n            return True\n        # If distance ties as well, compare coordinates lexicographically.\n        if candidate_distance == best_distance:\n            if candidate_x &lt; best_x:\n                return True\n            if candidate_x == best_x and candidate_y &lt; best_y:\n                return True\n    return False\n\n\n@njit(cache=True)\ndef _numba_find_best_cell(\n    x0: int,\n    y0: int,\n    vision: int,\n    sugar_array: np.ndarray,\n    occupied: np.ndarray,\n) -&gt; tuple[int, int]:\n    width, height = sugar_array.shape\n    best_x = x0\n    best_y = y0\n    best_sugar = sugar_array[x0, y0]\n    best_distance = 0\n\n    # Examine visible cells along the four cardinal directions, increasing\n    # step by step. The 'occupied' array marks cells that are currently\n    # unavailable (True = occupied). The origin cell is allowed as the\n    # default; callers typically clear the origin before searching.\n    for step in range(1, vision + 1):\n        nx = x0 + step\n        if nx &lt; width and not occupied[nx, y0]:\n            sugar_here = sugar_array[nx, y0]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0\n            ):\n                best_x = nx\n                best_y = y0\n                best_sugar = sugar_here\n                best_distance = step\n\n        nx = x0 - step\n        if nx &gt;= 0 and not occupied[nx, y0]:\n            sugar_here = sugar_array[nx, y0]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0\n            ):\n                best_x = nx\n                best_y = y0\n                best_sugar = sugar_here\n                best_distance = step\n\n        ny = y0 + step\n        if ny &lt; height and not occupied[x0, ny]:\n            sugar_here = sugar_array[x0, ny]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny\n            ):\n                best_x = x0\n                best_y = ny\n                best_sugar = sugar_here\n                best_distance = step\n\n        ny = y0 - step\n        if ny &gt;= 0 and not occupied[x0, ny]:\n            sugar_here = sugar_array[x0, ny]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny\n            ):\n                best_x = x0\n                best_y = ny\n                best_sugar = sugar_here\n                best_distance = step\n\n    return best_x, best_y\n\n\n@njit(cache=True)\ndef sequential_move_numba(\n    dim0: np.ndarray,\n    dim1: np.ndarray,\n    vision: np.ndarray,\n    sugar_array: np.ndarray,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Numba-accelerated sequential movement helper.\n\n    This function emulates the traditional asynchronous (sequential) update\n    where agents move one at a time in the current ordering. It accepts\n    numpy arrays describing agent positions and vision ranges, and a 2D\n    sugar array for lookup.\n\n    Parameters\n    ----------\n    dim0 : np.ndarray\n        1D integer array of length n_agents containing the x coordinates\n        for each agent.\n    dim1 : np.ndarray\n        1D integer array of length n_agents containing the y coordinates\n        for each agent.\n    vision : np.ndarray\n        1D integer array of vision radii for each agent.\n    sugar_array : np.ndarray\n        2D array shaped (width, height) containing per-cell sugar values.\n\n    Returns\n    -------\n    tuple[np.ndarray, np.ndarray]\n        Updated arrays of x and y coordinates after sequential movement.\n    \"\"\"\n    n_agents = dim0.shape[0]\n    width, height = sugar_array.shape\n    # Copy inputs to avoid mutating caller arrays in-place.\n    new_dim0 = dim0.copy()\n    new_dim1 = dim1.copy()\n    # Occupancy grid: True when a cell is currently occupied by an agent.\n    occupied = np.zeros((width, height), dtype=np.bool_)\n\n    # Mark initial occupancy.\n    for i in range(n_agents):\n        occupied[new_dim0[i], new_dim1[i]] = True\n\n    # Process agents in order. For each agent we clear its current cell in\n    # the occupancy grid (so it can consider moving into it), search for the\n    # best unoccupied visible cell, and mark the chosen destination as\n    # occupied. This models agents moving one-by-one.\n    for i in range(n_agents):\n        x0 = new_dim0[i]\n        y0 = new_dim1[i]\n        # Free the agent's current cell so it is considered available during\n        # the search (agents may choose to stay, in which case we'll re-mark\n        # it below).\n        occupied[x0, y0] = False\n        best_x, best_y = _numba_find_best_cell(\n            x0, y0, int(vision[i]), sugar_array, occupied\n        )\n        # Claim the chosen destination.\n        occupied[best_x, best_y] = True\n        new_dim0[i] = best_x\n        new_dim1[i] = best_y\n\n    return new_dim0, new_dim1\n\n\nclass AntsNumba(AntsBase):\n    def move(self) -&gt; None:\n        state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")\n        if state.is_empty():\n            return\n        agent_ids = state[\"unique_id\"]\n        dim0 = state[\"dim_0\"].to_numpy().astype(np.int64)\n        dim1 = state[\"dim_1\"].to_numpy().astype(np.int64)\n        vision = state[\"vision\"].to_numpy().astype(np.int64)\n\n        sugar_array = (\n            self.space.cells.sort([\"dim_0\", \"dim_1\"])\n            .with_columns(pl.col(\"sugar\").fill_null(0))[\"sugar\"]\n            .to_numpy()\n            .reshape(self.space.dimensions)\n        )\n\n        new_dim0, new_dim1 = sequential_move_numba(dim0, dim1, vision, sugar_array)\n        coords = pl.DataFrame({\"dim_0\": new_dim0.tolist(), \"dim_1\": new_dim1.tolist()})\n        self.space.move_agents(agent_ids, coords)\n</pre> @njit(cache=True) def _numba_should_replace(     best_sugar: int,     best_distance: int,     best_x: int,     best_y: int,     candidate_sugar: int,     candidate_distance: int,     candidate_x: int,     candidate_y: int, ) -&gt; bool:     \"\"\"Numba helper: decide whether a candidate cell should replace the     current best cell according to the movement tie-break rules.      This implements the same ordering used in :meth:`_choose_best_cell` but     in a tightly-typed, compiled form suitable for Numba loops.      Parameters     ----------     best_sugar : int         Sugar at the current best cell.     best_distance : int         Manhattan distance from the origin to the current best cell.     best_x : int         X coordinate of the current best cell.     best_y : int         Y coordinate of the current best cell.     candidate_sugar : int         Sugar at the candidate cell.     candidate_distance : int         Manhattan distance from the origin to the candidate cell.     candidate_x : int         X coordinate of the candidate cell.     candidate_y : int         Y coordinate of the candidate cell.      Returns     -------     bool         True if the candidate should replace the current best cell.     \"\"\"     # Primary criterion: prefer strictly greater sugar.     if candidate_sugar &gt; best_sugar:         return True     # If sugar ties, prefer the closer cell.     if candidate_sugar == best_sugar:         if candidate_distance &lt; best_distance:             return True         # If distance ties as well, compare coordinates lexicographically.         if candidate_distance == best_distance:             if candidate_x &lt; best_x:                 return True             if candidate_x == best_x and candidate_y &lt; best_y:                 return True     return False   @njit(cache=True) def _numba_find_best_cell(     x0: int,     y0: int,     vision: int,     sugar_array: np.ndarray,     occupied: np.ndarray, ) -&gt; tuple[int, int]:     width, height = sugar_array.shape     best_x = x0     best_y = y0     best_sugar = sugar_array[x0, y0]     best_distance = 0      # Examine visible cells along the four cardinal directions, increasing     # step by step. The 'occupied' array marks cells that are currently     # unavailable (True = occupied). The origin cell is allowed as the     # default; callers typically clear the origin before searching.     for step in range(1, vision + 1):         nx = x0 + step         if nx &lt; width and not occupied[nx, y0]:             sugar_here = sugar_array[nx, y0]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0             ):                 best_x = nx                 best_y = y0                 best_sugar = sugar_here                 best_distance = step          nx = x0 - step         if nx &gt;= 0 and not occupied[nx, y0]:             sugar_here = sugar_array[nx, y0]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0             ):                 best_x = nx                 best_y = y0                 best_sugar = sugar_here                 best_distance = step          ny = y0 + step         if ny &lt; height and not occupied[x0, ny]:             sugar_here = sugar_array[x0, ny]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny             ):                 best_x = x0                 best_y = ny                 best_sugar = sugar_here                 best_distance = step          ny = y0 - step         if ny &gt;= 0 and not occupied[x0, ny]:             sugar_here = sugar_array[x0, ny]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny             ):                 best_x = x0                 best_y = ny                 best_sugar = sugar_here                 best_distance = step      return best_x, best_y   @njit(cache=True) def sequential_move_numba(     dim0: np.ndarray,     dim1: np.ndarray,     vision: np.ndarray,     sugar_array: np.ndarray, ) -&gt; tuple[np.ndarray, np.ndarray]:     \"\"\"Numba-accelerated sequential movement helper.      This function emulates the traditional asynchronous (sequential) update     where agents move one at a time in the current ordering. It accepts     numpy arrays describing agent positions and vision ranges, and a 2D     sugar array for lookup.      Parameters     ----------     dim0 : np.ndarray         1D integer array of length n_agents containing the x coordinates         for each agent.     dim1 : np.ndarray         1D integer array of length n_agents containing the y coordinates         for each agent.     vision : np.ndarray         1D integer array of vision radii for each agent.     sugar_array : np.ndarray         2D array shaped (width, height) containing per-cell sugar values.      Returns     -------     tuple[np.ndarray, np.ndarray]         Updated arrays of x and y coordinates after sequential movement.     \"\"\"     n_agents = dim0.shape[0]     width, height = sugar_array.shape     # Copy inputs to avoid mutating caller arrays in-place.     new_dim0 = dim0.copy()     new_dim1 = dim1.copy()     # Occupancy grid: True when a cell is currently occupied by an agent.     occupied = np.zeros((width, height), dtype=np.bool_)      # Mark initial occupancy.     for i in range(n_agents):         occupied[new_dim0[i], new_dim1[i]] = True      # Process agents in order. For each agent we clear its current cell in     # the occupancy grid (so it can consider moving into it), search for the     # best unoccupied visible cell, and mark the chosen destination as     # occupied. This models agents moving one-by-one.     for i in range(n_agents):         x0 = new_dim0[i]         y0 = new_dim1[i]         # Free the agent's current cell so it is considered available during         # the search (agents may choose to stay, in which case we'll re-mark         # it below).         occupied[x0, y0] = False         best_x, best_y = _numba_find_best_cell(             x0, y0, int(vision[i]), sugar_array, occupied         )         # Claim the chosen destination.         occupied[best_x, best_y] = True         new_dim0[i] = best_x         new_dim1[i] = best_y      return new_dim0, new_dim1   class AntsNumba(AntsBase):     def move(self) -&gt; None:         state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")         if state.is_empty():             return         agent_ids = state[\"unique_id\"]         dim0 = state[\"dim_0\"].to_numpy().astype(np.int64)         dim1 = state[\"dim_1\"].to_numpy().astype(np.int64)         vision = state[\"vision\"].to_numpy().astype(np.int64)          sugar_array = (             self.space.cells.sort([\"dim_0\", \"dim_1\"])             .with_columns(pl.col(\"sugar\").fill_null(0))[\"sugar\"]             .to_numpy()             .reshape(self.space.dimensions)         )          new_dim0, new_dim1 = sequential_move_numba(dim0, dim1, vision, sugar_array)         coords = pl.DataFrame({\"dim_0\": new_dim0.tolist(), \"dim_1\": new_dim1.tolist()})         self.space.move_agents(agent_ids, coords) In\u00a0[8]: Copied! <pre>class AntsParallel(AntsBase):\n    def move(self) -&gt; None:\n        \"\"\"Move agents in parallel by ranking visible cells and resolving conflicts.\n\n        Declarative mental model: express *what* each agent wants (ranked candidates),\n        then use dataframe ops to *allocate* (joins, group_by with a lottery).\n        Performance is handled by Polars/LazyFrames; avoid premature micro-optimisations.\n\n        Returns\n        -------\n        None\n            Movement updates happen in-place on the underlying space.\n        \"\"\"\n        # Early exit if there are no agents.\n        if len(self.df) == 0:\n            return\n\n        # current_pos columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_center   \u2506 dim_1_center   \u2502\n        # \u2502 ---      \u2506 ---            \u2506 ---            \u2502\n        # \u2502 u64      \u2506 i64            \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        current_pos = self.pos.select(\n            [\n                pl.col(\"unique_id\").alias(\"agent_id\"),\n                pl.col(\"dim_0\").alias(\"dim_0_center\"),\n                pl.col(\"dim_1\").alias(\"dim_1_center\"),\n            ]\n        )\n\n        neighborhood = self._build_neighborhood_frame(current_pos)\n        choices, origins, max_rank = self._rank_candidates(neighborhood, current_pos)\n        if choices.is_empty():\n            return\n\n        assigned = self._resolve_conflicts_in_rounds(choices, origins, max_rank)\n        if assigned.is_empty():\n            return\n\n        # move_df columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 unique_id  \u2506 dim_0      \u2506 dim_1      \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---        \u2502\n        # \u2502 u64        \u2506 i64        \u2506 i64        \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        move_df = pl.DataFrame(\n            {\n                \"unique_id\": assigned[\"agent_id\"],\n                \"dim_0\": assigned[\"dim_0_candidate\"],\n                \"dim_1\": assigned[\"dim_1_candidate\"],\n            }\n        )\n        # `move_agents` accepts IdsLike and SpaceCoordinates (Polars Series/DataFrame),\n        # so pass Series/DataFrame directly rather than converting to Python lists.\n        self.space.move_agents(move_df[\"unique_id\"], move_df.select([\"dim_0\", \"dim_1\"]))\n\n    def _build_neighborhood_frame(self, current_pos: pl.DataFrame) -&gt; pl.DataFrame:\n        \"\"\"Assemble the sugar-weighted neighbourhood for each sensing agent.\n\n        Parameters\n        ----------\n        current_pos : pl.DataFrame\n            DataFrame with columns ``agent_id``, ``dim_0_center`` and\n            ``dim_1_center`` describing the current position of each agent.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``agent_id``, ``radius``, ``dim_0_candidate``,\n            ``dim_1_candidate`` and ``sugar`` describing the visible cells for\n            each agent.\n        \"\"\"\n        # Build a neighbourhood frame: for each agent and visible cell we\n        # attach the cell sugar. The raw offsets contain the candidate\n        # cell coordinates and the center coordinates for the sensing agent.\n        # Raw neighborhood columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0      \u2506 dim_1      \u2506 radius \u2506 dim_0_center   \u2506 dim_1_center   \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---    \u2506 ---            \u2506 ---            \u2502\n        # \u2502 i64        \u2506 i64        \u2506 i64    \u2506 i64            \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        neighborhood_cells = self.space.get_neighborhood(\n            radius=self[\"vision\"], agents=self, include_center=True\n        )\n\n        # sugar_cells columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0      \u2506 dim_1      \u2506 sugar  \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---    \u2502\n        # \u2502 i64        \u2506 i64        \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\n        sugar_cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])\n\n        neighborhood_cells = (\n            neighborhood_cells.join(sugar_cells, on=[\"dim_0\", \"dim_1\"], how=\"left\")\n            .with_columns(pl.col(\"sugar\").fill_null(0))\n            .rename({\"dim_0\": \"dim_0_candidate\", \"dim_1\": \"dim_1_candidate\"})\n        )\n\n        neighborhood_cells = neighborhood_cells.join(\n            current_pos,\n            left_on=[\"dim_0_center\", \"dim_1_center\"],\n            right_on=[\"dim_0_center\", \"dim_1_center\"],\n            how=\"left\",\n        )\n\n        # Final neighborhood columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 radius \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2502\n        # \u2502 ---      \u2506 ---    \u2506 ---              \u2506 ---              \u2506 ---    \u2502\n        # \u2502 u64      \u2506 i64    \u2506 i64              \u2506 i64              \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        neighborhood_cells = neighborhood_cells.drop(\n            [\"dim_0_center\", \"dim_1_center\"]\n        ).select([\"agent_id\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\", \"sugar\"])\n\n        return neighborhood_cells\n\n    def _rank_candidates(\n        self,\n        neighborhood: pl.DataFrame,\n        current_pos: pl.DataFrame,\n    ) -&gt; tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n        \"\"\"Rank candidate destination cells for each agent.\n\n        Parameters\n        ----------\n        neighborhood : pl.DataFrame\n            Output of :meth:`_build_neighborhood_frame` with columns\n            ``agent_id``, ``radius``, ``dim_0_candidate``, ``dim_1_candidate``\n            and ``sugar``.\n        current_pos : pl.DataFrame\n            Frame with columns ``agent_id``, ``dim_0_center`` and\n            ``dim_1_center`` describing where each agent currently stands.\n\n        Returns\n        -------\n        choices : pl.DataFrame\n            Ranked candidates per agent with columns ``agent_id``,\n            ``dim_0_candidate``, ``dim_1_candidate``, ``sugar``, ``radius`` and\n            ``rank``.\n        origins : pl.DataFrame\n            Original coordinates per agent with columns ``agent_id``,\n            ``dim_0`` and ``dim_1``.\n        max_rank : pl.DataFrame\n            Maximum available rank per agent with columns ``agent_id`` and\n            ``max_rank``.\n        \"\"\"\n        # Create ranked choices per agent: sort by sugar (desc), radius\n        # (asc), then coordinates. Keep the first unique entry per cell.\n\n        # choices columns (after select):\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2502\n        # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2502\n        # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        choices = (\n            neighborhood.select(\n                [\n                    \"agent_id\",\n                    \"dim_0_candidate\",\n                    \"dim_1_candidate\",\n                    \"sugar\",\n                    \"radius\",\n                ]\n            )\n            .sort(\n                [\"agent_id\", \"sugar\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\"],\n                descending=[False, True, False, False, False],\n            )\n            .unique(\n                subset=[\"agent_id\", \"dim_0_candidate\", \"dim_1_candidate\"],\n                keep=\"first\",\n                maintain_order=True,\n            )\n            .with_columns(pl.col(\"agent_id\").cum_count().over(\"agent_id\").alias(\"rank\"))\n        )\n\n        # Precompute per-agent candidate rank once so conflict resolution can\n        # promote losers by incrementing a cheap `current_rank` counter,\n        # without re-sorting after each round. Alternative: drop taken cells\n        # and re-rank by sugar every round; simpler conceptually but requires\n        # repeated sorts and deduplication, which is heavier than filtering by\n        # `rank &gt;= current_rank`.\n\n        # Origins for fallback (if an agent exhausts candidates it stays put).\n        # origins columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2502\n        # \u2502 ---      \u2506 ---        \u2506 ---        \u2502\n        # \u2502 u64      \u2506 i64        \u2506 i64        \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        origins = current_pos.select(\n            [\n                \"agent_id\",\n                pl.col(\"dim_0_center\").alias(\"dim_0\"),\n                pl.col(\"dim_1_center\").alias(\"dim_1\"),\n            ]\n        )\n\n        # Track the maximum available rank per agent to clamp promotions.\n        # This bounds `current_rank`; once an agent reaches `max_rank` and\n        # cannot secure a cell, they fall back to origin cleanly instead of\n        # chasing nonexistent ranks.\n        # max_rank columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 max_rank \u2502\n        # \u2502 ---      \u2506 ---       \u2502\n        # \u2502 u64      \u2506 u32       \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        max_rank = choices.group_by(\"agent_id\").agg(\n            pl.col(\"rank\").max().alias(\"max_rank\")\n        )\n        return choices, origins, max_rank\n\n    def _resolve_conflicts_in_rounds(\n        self,\n        choices: pl.DataFrame,\n        origins: pl.DataFrame,\n        max_rank: pl.DataFrame,\n    ) -&gt; pl.DataFrame:\n        \"\"\"Resolve movement conflicts through iterative lottery rounds.\n\n        Parameters\n        ----------\n        choices : pl.DataFrame\n            Ranked candidate cells per agent with headers matching the\n            ``choices`` frame returned by :meth:`_rank_candidates`.\n        origins : pl.DataFrame\n            Agent origin coordinates with columns ``agent_id``, ``dim_0`` and\n            ``dim_1``.\n        max_rank : pl.DataFrame\n            Maximum rank offset per agent with columns ``agent_id`` and\n            ``max_rank``.\n\n        Returns\n        -------\n        pl.DataFrame\n            Allocated movements with columns ``agent_id``, ``dim_0_candidate``\n            and ``dim_1_candidate``; each row records the destination assigned\n            to an agent.\n        \"\"\"\n        # Prepare unresolved agents and working tables.\n        agent_ids = choices[\"agent_id\"].unique(maintain_order=True)\n\n        # unresolved columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 current_rank  \u2502\n        # \u2502 ---      \u2506 ---            \u2502\n        # \u2502 u64      \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        unresolved = pl.DataFrame(\n            {\n                \"agent_id\": agent_ids,\n                \"current_rank\": pl.Series(np.zeros(len(agent_ids), dtype=np.int64)),\n            }\n        )\n\n        # assigned columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2502\n        # \u2502 ---      \u2506 ---              \u2506 ---              \u2502\n        # \u2502 u64      \u2506 i64              \u2506 i64              \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        assigned = pl.DataFrame(\n            {\n                \"agent_id\": pl.Series(\n                    name=\"agent_id\", values=[], dtype=agent_ids.dtype\n                ),\n                \"dim_0_candidate\": pl.Series(\n                    name=\"dim_0_candidate\", values=[], dtype=pl.Int64\n                ),\n                \"dim_1_candidate\": pl.Series(\n                    name=\"dim_1_candidate\", values=[], dtype=pl.Int64\n                ),\n            }\n        )\n\n        # taken columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0_candidate  \u2506 dim_1_candidate  \u2502\n        # \u2502 ---              \u2506 ---              \u2502\n        # \u2502 i64              \u2506 i64              \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        # Treat all currently occupied cells (origins) as taken from the start.\n        # Each agent may still target its own origin; we handle that exception\n        # when filtering candidate pools.\n        taken = origins.select(\n            [\n                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n            ]\n        )\n        origins_for_filter = origins.rename(\n            {\"dim_0\": \"dim_0_origin\", \"dim_1\": \"dim_1_origin\"}\n        )\n\n        # Resolve in rounds: each unresolved agent proposes its current-ranked\n        # candidate; winners per-cell are selected at random and losers are\n        # promoted to their next choice.\n        while unresolved.height &gt; 0:\n            # Using precomputed `rank` lets us select candidates with\n            # `rank &gt;= current_rank` and avoid re-ranking after each round.\n            # Alternative: remove taken cells and re-sort remaining candidates\n            # by sugar/distance per round (heavier due to repeated sort/dedupe).\n            # candidate_pool columns (after join with unresolved):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            candidate_pool = choices.join(unresolved, on=\"agent_id\")\n            candidate_pool = candidate_pool.filter(\n                pl.col(\"rank\") &gt;= pl.col(\"current_rank\")\n            )\n            candidate_pool = (\n                candidate_pool.join(origins_for_filter, on=\"agent_id\", how=\"left\")\n                .join(\n                    taken.with_columns(pl.lit(True).alias(\"is_taken\")),\n                    on=[\"dim_0_candidate\", \"dim_1_candidate\"],\n                    how=\"left\",\n                )\n                .filter(\n                    pl.col(\"is_taken\").is_null()\n                    | (\n                        (pl.col(\"dim_0_candidate\") == pl.col(\"dim_0_origin\"))\n                        &amp; (pl.col(\"dim_1_candidate\") == pl.col(\"dim_1_origin\"))\n                    )\n                )\n                .drop([\"dim_0_origin\", \"dim_1_origin\", \"is_taken\"])\n            )\n\n            if candidate_pool.is_empty():\n                # No available candidates \u2014 everyone falls back to origin.\n                # Note: this covers both agents with no visible cells left and\n                # the case where all remaining candidates are already taken.\n                # fallback columns:\n                # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2506 current_rank \u2502\n                # \u2502 ---      \u2506 ---        \u2506 ---        \u2506 ---          \u2502\n                # \u2502 u64      \u2506 i64        \u2506 i64        \u2506 i64          \u2502\n                # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n                fallback = unresolved.join(origins, on=\"agent_id\", how=\"left\")\n                assigned = pl.concat(\n                    [\n                        assigned,\n                        fallback.select(\n                            [\n                                \"agent_id\",\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                break\n\n            # best_candidates columns (per agent first choice):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            best_candidates = (\n                candidate_pool.sort([\"agent_id\", \"rank\"])\n                .group_by(\"agent_id\", maintain_order=True)\n                .first()\n            )\n\n            # Agents that had no candidate this round fall back to origin.\n            # missing columns:\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            missing = unresolved.join(\n                best_candidates.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n            )\n            if not missing.is_empty():\n                # fallback (missing) columns match fallback table above.\n                fallback = missing.join(origins, on=\"agent_id\", how=\"left\")\n                assigned = pl.concat(\n                    [\n                        assigned,\n                        fallback.select(\n                            [\n                                \"agent_id\",\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                unresolved = unresolved.join(\n                    missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n                )\n                best_candidates = best_candidates.join(\n                    missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n                )\n                if unresolved.is_empty() or best_candidates.is_empty():\n                    continue\n\n            # Add a small random lottery to break ties deterministically for\n            # each candidate set.\n            lottery = pl.Series(\"lottery\", self.random.random(best_candidates.height))\n            best_candidates = best_candidates.with_columns(lottery)\n\n            # winners columns:\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502 lottery \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2506 ---     \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2506 f64     \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            winners = (\n                best_candidates.sort([\"dim_0_candidate\", \"dim_1_candidate\", \"lottery\"])\n                .group_by([\"dim_0_candidate\", \"dim_1_candidate\"], maintain_order=True)\n                .first()\n            )\n\n            assigned = pl.concat(\n                [\n                    assigned,\n                    winners.select(\n                        [\n                            \"agent_id\",\n                            pl.col(\"dim_0_candidate\"),\n                            pl.col(\"dim_1_candidate\"),\n                        ]\n                    ),\n                ],\n                how=\"vertical\",\n            )\n            taken = pl.concat(\n                [\n                    taken,\n                    winners.select([\"dim_0_candidate\", \"dim_1_candidate\"]),\n                ],\n                how=\"vertical\",\n            )\n            # Origins of agents that move away become available to others in\n            # subsequent rounds. Keep origins for agents that stayed put.\n            vacated = (\n                winners.join(origins_for_filter, on=\"agent_id\", how=\"left\")\n                .filter(\n                    (pl.col(\"dim_0_candidate\") != pl.col(\"dim_0_origin\"))\n                    | (pl.col(\"dim_1_candidate\") != pl.col(\"dim_1_origin\"))\n                )\n                .select(\n                    pl.col(\"dim_0_origin\").alias(\"dim_0_candidate\"),\n                    pl.col(\"dim_1_origin\").alias(\"dim_1_candidate\"),\n                )\n            )\n            if not vacated.is_empty():\n                taken = taken.join(\n                    vacated,\n                    on=[\"dim_0_candidate\", \"dim_1_candidate\"],\n                    how=\"anti\",\n                )\n\n            winner_ids = winners.select(\"agent_id\")\n            unresolved = unresolved.join(winner_ids, on=\"agent_id\", how=\"anti\")\n            if unresolved.is_empty():\n                break\n\n            # loser candidates columns mirror best_candidates (minus winners).\n            losers = best_candidates.join(winner_ids, on=\"agent_id\", how=\"anti\")\n            if losers.is_empty():\n                continue\n\n            # loser_updates columns (after select):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 next_rank \u2502\n            # \u2502 ---      \u2506 ---       \u2502\n            # \u2502 u64      \u2506 i64       \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            loser_updates = (\n                losers.select(\n                    \"agent_id\",\n                    (pl.col(\"rank\") + 1).cast(pl.Int64).alias(\"next_rank\"),\n                )\n                .join(max_rank, on=\"agent_id\", how=\"left\")\n                .with_columns(\n                    pl.min_horizontal(pl.col(\"next_rank\"), pl.col(\"max_rank\")).alias(\n                        \"next_rank\"\n                    )\n                )\n                .select([\"agent_id\", \"next_rank\"])\n            )\n\n            # Promote losers' current_rank (if any) and continue.\n            # unresolved (updated) retains columns agent_id/current_rank.\n            unresolved = (\n                unresolved.join(loser_updates, on=\"agent_id\", how=\"left\")\n                .with_columns(\n                    pl.when(pl.col(\"next_rank\").is_not_null())\n                    .then(pl.col(\"next_rank\"))\n                    .otherwise(pl.col(\"current_rank\"))\n                    .alias(\"current_rank\")\n                )\n                .drop(\"next_rank\")\n            )\n\n        return assigned\n</pre>   class AntsParallel(AntsBase):     def move(self) -&gt; None:         \"\"\"Move agents in parallel by ranking visible cells and resolving conflicts.          Declarative mental model: express *what* each agent wants (ranked candidates),         then use dataframe ops to *allocate* (joins, group_by with a lottery).         Performance is handled by Polars/LazyFrames; avoid premature micro-optimisations.          Returns         -------         None             Movement updates happen in-place on the underlying space.         \"\"\"         # Early exit if there are no agents.         if len(self.df) == 0:             return          # current_pos columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_center   \u2506 dim_1_center   \u2502         # \u2502 ---      \u2506 ---            \u2506 ---            \u2502         # \u2502 u64      \u2506 i64            \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         current_pos = self.pos.select(             [                 pl.col(\"unique_id\").alias(\"agent_id\"),                 pl.col(\"dim_0\").alias(\"dim_0_center\"),                 pl.col(\"dim_1\").alias(\"dim_1_center\"),             ]         )          neighborhood = self._build_neighborhood_frame(current_pos)         choices, origins, max_rank = self._rank_candidates(neighborhood, current_pos)         if choices.is_empty():             return          assigned = self._resolve_conflicts_in_rounds(choices, origins, max_rank)         if assigned.is_empty():             return          # move_df columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 unique_id  \u2506 dim_0      \u2506 dim_1      \u2502         # \u2502 ---        \u2506 ---        \u2506 ---        \u2502         # \u2502 u64        \u2506 i64        \u2506 i64        \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         move_df = pl.DataFrame(             {                 \"unique_id\": assigned[\"agent_id\"],                 \"dim_0\": assigned[\"dim_0_candidate\"],                 \"dim_1\": assigned[\"dim_1_candidate\"],             }         )         # `move_agents` accepts IdsLike and SpaceCoordinates (Polars Series/DataFrame),         # so pass Series/DataFrame directly rather than converting to Python lists.         self.space.move_agents(move_df[\"unique_id\"], move_df.select([\"dim_0\", \"dim_1\"]))      def _build_neighborhood_frame(self, current_pos: pl.DataFrame) -&gt; pl.DataFrame:         \"\"\"Assemble the sugar-weighted neighbourhood for each sensing agent.          Parameters         ----------         current_pos : pl.DataFrame             DataFrame with columns ``agent_id``, ``dim_0_center`` and             ``dim_1_center`` describing the current position of each agent.          Returns         -------         pl.DataFrame             DataFrame with columns ``agent_id``, ``radius``, ``dim_0_candidate``,             ``dim_1_candidate`` and ``sugar`` describing the visible cells for             each agent.         \"\"\"         # Build a neighbourhood frame: for each agent and visible cell we         # attach the cell sugar. The raw offsets contain the candidate         # cell coordinates and the center coordinates for the sensing agent.         # Raw neighborhood columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0      \u2506 dim_1      \u2506 radius \u2506 dim_0_center   \u2506 dim_1_center   \u2502         # \u2502 ---        \u2506 ---        \u2506 ---    \u2506 ---            \u2506 ---            \u2502         # \u2502 i64        \u2506 i64        \u2506 i64    \u2506 i64            \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         neighborhood_cells = self.space.get_neighborhood(             radius=self[\"vision\"], agents=self, include_center=True         )          # sugar_cells columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0      \u2506 dim_1      \u2506 sugar  \u2502         # \u2502 ---        \u2506 ---        \u2506 ---    \u2502         # \u2502 i64        \u2506 i64        \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561          sugar_cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])          neighborhood_cells = (             neighborhood_cells.join(sugar_cells, on=[\"dim_0\", \"dim_1\"], how=\"left\")             .with_columns(pl.col(\"sugar\").fill_null(0))             .rename({\"dim_0\": \"dim_0_candidate\", \"dim_1\": \"dim_1_candidate\"})         )          neighborhood_cells = neighborhood_cells.join(             current_pos,             left_on=[\"dim_0_center\", \"dim_1_center\"],             right_on=[\"dim_0_center\", \"dim_1_center\"],             how=\"left\",         )          # Final neighborhood columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 radius \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2502         # \u2502 ---      \u2506 ---    \u2506 ---              \u2506 ---              \u2506 ---    \u2502         # \u2502 u64      \u2506 i64    \u2506 i64              \u2506 i64              \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         neighborhood_cells = neighborhood_cells.drop(             [\"dim_0_center\", \"dim_1_center\"]         ).select([\"agent_id\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\", \"sugar\"])          return neighborhood_cells      def _rank_candidates(         self,         neighborhood: pl.DataFrame,         current_pos: pl.DataFrame,     ) -&gt; tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:         \"\"\"Rank candidate destination cells for each agent.          Parameters         ----------         neighborhood : pl.DataFrame             Output of :meth:`_build_neighborhood_frame` with columns             ``agent_id``, ``radius``, ``dim_0_candidate``, ``dim_1_candidate``             and ``sugar``.         current_pos : pl.DataFrame             Frame with columns ``agent_id``, ``dim_0_center`` and             ``dim_1_center`` describing where each agent currently stands.          Returns         -------         choices : pl.DataFrame             Ranked candidates per agent with columns ``agent_id``,             ``dim_0_candidate``, ``dim_1_candidate``, ``sugar``, ``radius`` and             ``rank``.         origins : pl.DataFrame             Original coordinates per agent with columns ``agent_id``,             ``dim_0`` and ``dim_1``.         max_rank : pl.DataFrame             Maximum available rank per agent with columns ``agent_id`` and             ``max_rank``.         \"\"\"         # Create ranked choices per agent: sort by sugar (desc), radius         # (asc), then coordinates. Keep the first unique entry per cell.          # choices columns (after select):         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2502         # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2502         # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         choices = (             neighborhood.select(                 [                     \"agent_id\",                     \"dim_0_candidate\",                     \"dim_1_candidate\",                     \"sugar\",                     \"radius\",                 ]             )             .sort(                 [\"agent_id\", \"sugar\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\"],                 descending=[False, True, False, False, False],             )             .unique(                 subset=[\"agent_id\", \"dim_0_candidate\", \"dim_1_candidate\"],                 keep=\"first\",                 maintain_order=True,             )             .with_columns(pl.col(\"agent_id\").cum_count().over(\"agent_id\").alias(\"rank\"))         )          # Precompute per-agent candidate rank once so conflict resolution can         # promote losers by incrementing a cheap `current_rank` counter,         # without re-sorting after each round. Alternative: drop taken cells         # and re-rank by sugar every round; simpler conceptually but requires         # repeated sorts and deduplication, which is heavier than filtering by         # `rank &gt;= current_rank`.          # Origins for fallback (if an agent exhausts candidates it stays put).         # origins columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2502         # \u2502 ---      \u2506 ---        \u2506 ---        \u2502         # \u2502 u64      \u2506 i64        \u2506 i64        \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         origins = current_pos.select(             [                 \"agent_id\",                 pl.col(\"dim_0_center\").alias(\"dim_0\"),                 pl.col(\"dim_1_center\").alias(\"dim_1\"),             ]         )          # Track the maximum available rank per agent to clamp promotions.         # This bounds `current_rank`; once an agent reaches `max_rank` and         # cannot secure a cell, they fall back to origin cleanly instead of         # chasing nonexistent ranks.         # max_rank columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 max_rank \u2502         # \u2502 ---      \u2506 ---       \u2502         # \u2502 u64      \u2506 u32       \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         max_rank = choices.group_by(\"agent_id\").agg(             pl.col(\"rank\").max().alias(\"max_rank\")         )         return choices, origins, max_rank      def _resolve_conflicts_in_rounds(         self,         choices: pl.DataFrame,         origins: pl.DataFrame,         max_rank: pl.DataFrame,     ) -&gt; pl.DataFrame:         \"\"\"Resolve movement conflicts through iterative lottery rounds.          Parameters         ----------         choices : pl.DataFrame             Ranked candidate cells per agent with headers matching the             ``choices`` frame returned by :meth:`_rank_candidates`.         origins : pl.DataFrame             Agent origin coordinates with columns ``agent_id``, ``dim_0`` and             ``dim_1``.         max_rank : pl.DataFrame             Maximum rank offset per agent with columns ``agent_id`` and             ``max_rank``.          Returns         -------         pl.DataFrame             Allocated movements with columns ``agent_id``, ``dim_0_candidate``             and ``dim_1_candidate``; each row records the destination assigned             to an agent.         \"\"\"         # Prepare unresolved agents and working tables.         agent_ids = choices[\"agent_id\"].unique(maintain_order=True)          # unresolved columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 current_rank  \u2502         # \u2502 ---      \u2506 ---            \u2502         # \u2502 u64      \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         unresolved = pl.DataFrame(             {                 \"agent_id\": agent_ids,                 \"current_rank\": pl.Series(np.zeros(len(agent_ids), dtype=np.int64)),             }         )          # assigned columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2502         # \u2502 ---      \u2506 ---              \u2506 ---              \u2502         # \u2502 u64      \u2506 i64              \u2506 i64              \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         assigned = pl.DataFrame(             {                 \"agent_id\": pl.Series(                     name=\"agent_id\", values=[], dtype=agent_ids.dtype                 ),                 \"dim_0_candidate\": pl.Series(                     name=\"dim_0_candidate\", values=[], dtype=pl.Int64                 ),                 \"dim_1_candidate\": pl.Series(                     name=\"dim_1_candidate\", values=[], dtype=pl.Int64                 ),             }         )          # taken columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0_candidate  \u2506 dim_1_candidate  \u2502         # \u2502 ---              \u2506 ---              \u2502         # \u2502 i64              \u2506 i64              \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         # Treat all currently occupied cells (origins) as taken from the start.         # Each agent may still target its own origin; we handle that exception         # when filtering candidate pools.         taken = origins.select(             [                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),             ]         )         origins_for_filter = origins.rename(             {\"dim_0\": \"dim_0_origin\", \"dim_1\": \"dim_1_origin\"}         )          # Resolve in rounds: each unresolved agent proposes its current-ranked         # candidate; winners per-cell are selected at random and losers are         # promoted to their next choice.         while unresolved.height &gt; 0:             # Using precomputed `rank` lets us select candidates with             # `rank &gt;= current_rank` and avoid re-ranking after each round.             # Alternative: remove taken cells and re-sort remaining candidates             # by sugar/distance per round (heavier due to repeated sort/dedupe).             # candidate_pool columns (after join with unresolved):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             candidate_pool = choices.join(unresolved, on=\"agent_id\")             candidate_pool = candidate_pool.filter(                 pl.col(\"rank\") &gt;= pl.col(\"current_rank\")             )             candidate_pool = (                 candidate_pool.join(origins_for_filter, on=\"agent_id\", how=\"left\")                 .join(                     taken.with_columns(pl.lit(True).alias(\"is_taken\")),                     on=[\"dim_0_candidate\", \"dim_1_candidate\"],                     how=\"left\",                 )                 .filter(                     pl.col(\"is_taken\").is_null()                     | (                         (pl.col(\"dim_0_candidate\") == pl.col(\"dim_0_origin\"))                         &amp; (pl.col(\"dim_1_candidate\") == pl.col(\"dim_1_origin\"))                     )                 )                 .drop([\"dim_0_origin\", \"dim_1_origin\", \"is_taken\"])             )              if candidate_pool.is_empty():                 # No available candidates \u2014 everyone falls back to origin.                 # Note: this covers both agents with no visible cells left and                 # the case where all remaining candidates are already taken.                 # fallback columns:                 # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2506 current_rank \u2502                 # \u2502 ---      \u2506 ---        \u2506 ---        \u2506 ---          \u2502                 # \u2502 u64      \u2506 i64        \u2506 i64        \u2506 i64          \u2502                 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561                 fallback = unresolved.join(origins, on=\"agent_id\", how=\"left\")                 assigned = pl.concat(                     [                         assigned,                         fallback.select(                             [                                 \"agent_id\",                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 break              # best_candidates columns (per agent first choice):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             best_candidates = (                 candidate_pool.sort([\"agent_id\", \"rank\"])                 .group_by(\"agent_id\", maintain_order=True)                 .first()             )              # Agents that had no candidate this round fall back to origin.             # missing columns:             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---          \u2502             # \u2502 u64      \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             missing = unresolved.join(                 best_candidates.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"             )             if not missing.is_empty():                 # fallback (missing) columns match fallback table above.                 fallback = missing.join(origins, on=\"agent_id\", how=\"left\")                 assigned = pl.concat(                     [                         assigned,                         fallback.select(                             [                                 \"agent_id\",                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 unresolved = unresolved.join(                     missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"                 )                 best_candidates = best_candidates.join(                     missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"                 )                 if unresolved.is_empty() or best_candidates.is_empty():                     continue              # Add a small random lottery to break ties deterministically for             # each candidate set.             lottery = pl.Series(\"lottery\", self.random.random(best_candidates.height))             best_candidates = best_candidates.with_columns(lottery)              # winners columns:             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502 lottery \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2506 ---     \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2506 f64     \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             winners = (                 best_candidates.sort([\"dim_0_candidate\", \"dim_1_candidate\", \"lottery\"])                 .group_by([\"dim_0_candidate\", \"dim_1_candidate\"], maintain_order=True)                 .first()             )              assigned = pl.concat(                 [                     assigned,                     winners.select(                         [                             \"agent_id\",                             pl.col(\"dim_0_candidate\"),                             pl.col(\"dim_1_candidate\"),                         ]                     ),                 ],                 how=\"vertical\",             )             taken = pl.concat(                 [                     taken,                     winners.select([\"dim_0_candidate\", \"dim_1_candidate\"]),                 ],                 how=\"vertical\",             )             # Origins of agents that move away become available to others in             # subsequent rounds. Keep origins for agents that stayed put.             vacated = (                 winners.join(origins_for_filter, on=\"agent_id\", how=\"left\")                 .filter(                     (pl.col(\"dim_0_candidate\") != pl.col(\"dim_0_origin\"))                     | (pl.col(\"dim_1_candidate\") != pl.col(\"dim_1_origin\"))                 )                 .select(                     pl.col(\"dim_0_origin\").alias(\"dim_0_candidate\"),                     pl.col(\"dim_1_origin\").alias(\"dim_1_candidate\"),                 )             )             if not vacated.is_empty():                 taken = taken.join(                     vacated,                     on=[\"dim_0_candidate\", \"dim_1_candidate\"],                     how=\"anti\",                 )              winner_ids = winners.select(\"agent_id\")             unresolved = unresolved.join(winner_ids, on=\"agent_id\", how=\"anti\")             if unresolved.is_empty():                 break              # loser candidates columns mirror best_candidates (minus winners).             losers = best_candidates.join(winner_ids, on=\"agent_id\", how=\"anti\")             if losers.is_empty():                 continue              # loser_updates columns (after select):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 next_rank \u2502             # \u2502 ---      \u2506 ---       \u2502             # \u2502 u64      \u2506 i64       \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             loser_updates = (                 losers.select(                     \"agent_id\",                     (pl.col(\"rank\") + 1).cast(pl.Int64).alias(\"next_rank\"),                 )                 .join(max_rank, on=\"agent_id\", how=\"left\")                 .with_columns(                     pl.min_horizontal(pl.col(\"next_rank\"), pl.col(\"max_rank\")).alias(                         \"next_rank\"                     )                 )                 .select([\"agent_id\", \"next_rank\"])             )              # Promote losers' current_rank (if any) and continue.             # unresolved (updated) retains columns agent_id/current_rank.             unresolved = (                 unresolved.join(loser_updates, on=\"agent_id\", how=\"left\")                 .with_columns(                     pl.when(pl.col(\"next_rank\").is_not_null())                     .then(pl.col(\"next_rank\"))                     .otherwise(pl.col(\"current_rank\"))                     .alias(\"current_rank\")                 )                 .drop(\"next_rank\")             )          return assigned In\u00a0[9]: Copied! <pre>GRID_WIDTH = 20\nGRID_HEIGHT = 20\nNUM_AGENTS = 100\nMODEL_STEPS = 60\nMAX_SUGAR = 4\nSEED = 42\n\n\ndef run_variant(\n    agent_cls: type[AntsBase],\n    *,\n    steps: int,\n    seed: int,\n) -&gt; tuple[Sugarscape, float]:\n    model = Sugarscape(\n        agent_type=agent_cls,\n        n_agents=NUM_AGENTS,\n        width=GRID_WIDTH,\n        height=GRID_HEIGHT,\n        max_sugar=MAX_SUGAR,\n        seed=seed,\n    )\n    start = perf_counter()\n    model.run(steps)\n    return model, perf_counter() - start\n\n\nvariant_specs: dict[str, type[AntsBase]] = {\n    \"Sequential (Python loop)\": AntsSequential,\n    \"Sequential (Numba)\": AntsNumba,\n    \"Parallel (Polars)\": AntsParallel,\n}\n\nmodels: dict[str, Sugarscape] = {}\nframes: dict[str, pl.DataFrame] = {}\nruntimes: dict[str, float] = {}\n\nfor variant_name, agent_cls in variant_specs.items():\n    model, runtime = run_variant(agent_cls, steps=MODEL_STEPS, seed=SEED)\n    models[variant_name] = model\n    frames[variant_name] = model.datacollector.data[\"model\"]\n    runtimes[variant_name] = runtime\n\n    show_output(\n        frames[variant_name]\n        .select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"])\n        .tail(5),\n        title=f\"{variant_name} aggregate trajectory (last 5 steps)\",\n        max_rows=5,\n        collapsible=True,\n    )\n    show_output(f\"{variant_name} runtime: {runtime:.3f} s\")\n    if not _in_ipython():\n        print()\n\nruntime_table = (\n    pl.DataFrame(\n        [\n            {\n                \"update_rule\": variant_name,\n                \"runtime_seconds\": runtimes.get(variant_name, float(\"nan\")),\n            }\n            for variant_name in variant_specs.keys()\n        ]\n    )\n    .with_columns(pl.col(\"runtime_seconds\").round(4))\n    .sort(\"runtime_seconds\", descending=False, nulls_last=True)\n)\n\nshow_output(\n    runtime_table,\n    title=\"Runtime comparison (fastest first)\",\n    collapsible=True,\n    open_by_default=True,\n)\n\n# Access models/frames on demand; keep namespace minimal.\nnumba_model_frame = frames.get(\"Sequential (Numba)\", pl.DataFrame())\npar_model_frame = frames.get(\"Parallel (Polars)\", pl.DataFrame())\n</pre>  GRID_WIDTH = 20 GRID_HEIGHT = 20 NUM_AGENTS = 100 MODEL_STEPS = 60 MAX_SUGAR = 4 SEED = 42   def run_variant(     agent_cls: type[AntsBase],     *,     steps: int,     seed: int, ) -&gt; tuple[Sugarscape, float]:     model = Sugarscape(         agent_type=agent_cls,         n_agents=NUM_AGENTS,         width=GRID_WIDTH,         height=GRID_HEIGHT,         max_sugar=MAX_SUGAR,         seed=seed,     )     start = perf_counter()     model.run(steps)     return model, perf_counter() - start   variant_specs: dict[str, type[AntsBase]] = {     \"Sequential (Python loop)\": AntsSequential,     \"Sequential (Numba)\": AntsNumba,     \"Parallel (Polars)\": AntsParallel, }  models: dict[str, Sugarscape] = {} frames: dict[str, pl.DataFrame] = {} runtimes: dict[str, float] = {}  for variant_name, agent_cls in variant_specs.items():     model, runtime = run_variant(agent_cls, steps=MODEL_STEPS, seed=SEED)     models[variant_name] = model     frames[variant_name] = model.datacollector.data[\"model\"]     runtimes[variant_name] = runtime      show_output(         frames[variant_name]         .select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"])         .tail(5),         title=f\"{variant_name} aggregate trajectory (last 5 steps)\",         max_rows=5,         collapsible=True,     )     show_output(f\"{variant_name} runtime: {runtime:.3f} s\")     if not _in_ipython():         print()  runtime_table = (     pl.DataFrame(         [             {                 \"update_rule\": variant_name,                 \"runtime_seconds\": runtimes.get(variant_name, float(\"nan\")),             }             for variant_name in variant_specs.keys()         ]     )     .with_columns(pl.col(\"runtime_seconds\").round(4))     .sort(\"runtime_seconds\", descending=False, nulls_last=True) )  show_output(     runtime_table,     title=\"Runtime comparison (fastest first)\",     collapsible=True,     open_by_default=True, )  # Access models/frames on demand; keep namespace minimal. numba_model_frame = frames.get(\"Sequential (Numba)\", pl.DataFrame()) par_model_frame = frames.get(\"Parallel (Polars)\", pl.DataFrame()) Sequential (Python loop) aggregate trajectory (last 5 steps) step mean_sugar total_sugar agents_alive 56 64.033333 3842.0 60.0 57 65.000000 3900.0 60.0 58 65.883333 3953.0 60.0 59 66.933333 4016.0 60.0 60 67.900000 4074.0 60.0 <pre>'Sequential (Python loop) runtime: 12.932 s'</pre> Sequential (Numba) aggregate trajectory (last 5 steps) step mean_sugar total_sugar agents_alive 56 64.033333 3842.0 60.0 57 65.000000 3900.0 60.0 58 65.883333 3953.0 60.0 59 66.933333 4016.0 60.0 60 67.900000 4074.0 60.0 <pre>'Sequential (Numba) runtime: 2.214 s'</pre> Parallel (Polars) aggregate trajectory (last 5 steps) step mean_sugar total_sugar agents_alive 56 68.122807 3883.0 57.0 57 69.263158 3948.0 57.0 58 70.298246 4007.0 57.0 59 71.491228 4075.0 57.0 60 72.508772 4133.0 57.0 <pre>'Parallel (Polars) runtime: 1.852 s'</pre> Runtime comparison (fastest first) update_rule runtime_seconds Parallel (Polars) 1.8525 Sequential (Numba) 2.2137 Sequential (Python loop) 12.9323 In\u00a0[10]: Copied! <pre>comparison = numba_model_frame.select(\n    [\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]\n).join(\n    par_model_frame.select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]),\n    on=\"step\",\n    how=\"inner\",\n    suffix=\"_parallel\",\n)\ncomparison = comparison.with_columns(\n    (pl.col(\"mean_sugar\") - pl.col(\"mean_sugar_parallel\")).abs().alias(\"mean_diff\"),\n    (pl.col(\"total_sugar\") - pl.col(\"total_sugar_parallel\")).abs().alias(\"total_diff\"),\n    (pl.col(\"agents_alive\") - pl.col(\"agents_alive_parallel\"))\n    .abs()\n    .alias(\"count_diff\"),\n)\nshow_output(\n    comparison.select([\"step\", \"mean_diff\", \"total_diff\", \"count_diff\"]).head(10),\n    title=\"Step-level absolute differences (first 10 steps)\",\n    max_rows=10,\n    collapsible=True,\n)\n\n\n# Build the steady-state metrics table from the DataCollector output rather than\n# recomputing reporters directly on the model objects. The collector already\n# stored the model-level reporters (gini, correlations, etc.) every step.\ndef _last_row(df: pl.DataFrame) -&gt; pl.DataFrame:\n    if df.is_empty():\n        return df\n    # Ensure we take the final time step in case steps &lt; MODEL_STEPS due to extinction.\n    return df.sort(\"step\").tail(1)\n\n\nnumba_last = _last_row(frames.get(\"Sequential (Numba)\", pl.DataFrame()))\nparallel_last = _last_row(frames.get(\"Parallel (Polars)\", pl.DataFrame()))\n\nmetrics_pieces: list[pl.DataFrame] = []\nif not numba_last.is_empty():\n    metrics_pieces.append(\n        numba_last.select(\n            [\n                pl.lit(\"Sequential (Numba)\").alias(\"update_rule\"),\n                \"gini\",\n                \"corr_sugar_metabolism\",\n                \"corr_sugar_vision\",\n                pl.col(\"agents_alive\"),\n            ]\n        )\n    )\nif not parallel_last.is_empty():\n    metrics_pieces.append(\n        parallel_last.select(\n            [\n                pl.lit(\"Parallel (random tie-break)\").alias(\"update_rule\"),\n                \"gini\",\n                \"corr_sugar_metabolism\",\n                \"corr_sugar_vision\",\n                pl.col(\"agents_alive\"),\n            ]\n        )\n    )\n\nmetrics_table = (\n    pl.concat(metrics_pieces, how=\"vertical\") if metrics_pieces else pl.DataFrame()\n)\n\nshow_output(\n    metrics_table.select(\n        [\n            \"update_rule\",\n            pl.col(\"gini\").round(4),\n            pl.col(\"corr_sugar_metabolism\").round(4),\n            pl.col(\"corr_sugar_vision\").round(4),\n            pl.col(\"agents_alive\"),\n        ]\n    ),\n    title=\"Steady-state inequality metrics\",\n    collapsible=True,\n    open_by_default=True,\n)\n\nif metrics_table.height &gt;= 2:\n    numba_gini = metrics_table.filter(pl.col(\"update_rule\") == \"Sequential (Numba)\")[\n        \"gini\"\n    ][0]\n    par_gini = metrics_table.filter(\n        pl.col(\"update_rule\") == \"Parallel (random tie-break)\"\n    )[\"gini\"][0]\n    show_output(\n        f\"Absolute Gini gap (numba vs parallel): {abs(numba_gini - par_gini):.4f}\"\n    )\n</pre> comparison = numba_model_frame.select(     [\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"] ).join(     par_model_frame.select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]),     on=\"step\",     how=\"inner\",     suffix=\"_parallel\", ) comparison = comparison.with_columns(     (pl.col(\"mean_sugar\") - pl.col(\"mean_sugar_parallel\")).abs().alias(\"mean_diff\"),     (pl.col(\"total_sugar\") - pl.col(\"total_sugar_parallel\")).abs().alias(\"total_diff\"),     (pl.col(\"agents_alive\") - pl.col(\"agents_alive_parallel\"))     .abs()     .alias(\"count_diff\"), ) show_output(     comparison.select([\"step\", \"mean_diff\", \"total_diff\", \"count_diff\"]).head(10),     title=\"Step-level absolute differences (first 10 steps)\",     max_rows=10,     collapsible=True, )   # Build the steady-state metrics table from the DataCollector output rather than # recomputing reporters directly on the model objects. The collector already # stored the model-level reporters (gini, correlations, etc.) every step. def _last_row(df: pl.DataFrame) -&gt; pl.DataFrame:     if df.is_empty():         return df     # Ensure we take the final time step in case steps &lt; MODEL_STEPS due to extinction.     return df.sort(\"step\").tail(1)   numba_last = _last_row(frames.get(\"Sequential (Numba)\", pl.DataFrame())) parallel_last = _last_row(frames.get(\"Parallel (Polars)\", pl.DataFrame()))  metrics_pieces: list[pl.DataFrame] = [] if not numba_last.is_empty():     metrics_pieces.append(         numba_last.select(             [                 pl.lit(\"Sequential (Numba)\").alias(\"update_rule\"),                 \"gini\",                 \"corr_sugar_metabolism\",                 \"corr_sugar_vision\",                 pl.col(\"agents_alive\"),             ]         )     ) if not parallel_last.is_empty():     metrics_pieces.append(         parallel_last.select(             [                 pl.lit(\"Parallel (random tie-break)\").alias(\"update_rule\"),                 \"gini\",                 \"corr_sugar_metabolism\",                 \"corr_sugar_vision\",                 pl.col(\"agents_alive\"),             ]         )     )  metrics_table = (     pl.concat(metrics_pieces, how=\"vertical\") if metrics_pieces else pl.DataFrame() )  show_output(     metrics_table.select(         [             \"update_rule\",             pl.col(\"gini\").round(4),             pl.col(\"corr_sugar_metabolism\").round(4),             pl.col(\"corr_sugar_vision\").round(4),             pl.col(\"agents_alive\"),         ]     ),     title=\"Steady-state inequality metrics\",     collapsible=True,     open_by_default=True, )  if metrics_table.height &gt;= 2:     numba_gini = metrics_table.filter(pl.col(\"update_rule\") == \"Sequential (Numba)\")[         \"gini\"     ][0]     par_gini = metrics_table.filter(         pl.col(\"update_rule\") == \"Parallel (random tie-break)\"     )[\"gini\"][0]     show_output(         f\"Absolute Gini gap (numba vs parallel): {abs(numba_gini - par_gini):.4f}\"     ) Step-level absolute differences (first 10 steps) step mean_diff total_diff count_diff 0 0.000000 0.0 0.0 1 0.020000 2.0 0.0 2 0.030000 3.0 0.0 3 0.140000 14.0 0.0 4 0.090000 9.0 0.0 5 0.120000 12.0 0.0 6 0.192615 3.0 1.0 7 0.061856 6.0 0.0 8 0.295822 4.0 2.0 9 0.215899 4.0 1.0 Steady-state inequality metrics update_rule gini corr_sugar_metabolism corr_sugar_vision agents_alive Sequential (Numba) 0.3041 -0.8445 0.4645 60.0 Parallel (random tie-break) 0.2590 -0.8855 0.3377 57.0 <pre>'Absolute Gini gap (numba vs parallel): 0.0451'</pre>"},{"location":"tutorials/3_advanced_tutorial/#advanced-tutorial-rebuilding-sugarscape-with-mesa-frames","title":"Advanced Tutorial \u2014 Rebuilding Sugarscape with mesa-frames\u00b6","text":"<p>We revisit the classic Sugarscape instant-growback model described in chapter 2 of Growing Artificial Societies (Epstein &amp; Axtell, 1996) and rebuild it step by step using <code>mesa-frames</code>. Along the way we highlight why the traditional definition is not ideal for high-performance with mesa-frames and how a simple relaxation can unlock vectorisation and lead to similar macro behaviour.</p>"},{"location":"tutorials/3_advanced_tutorial/#sugarscape-in-plain-terms","title":"Sugarscape in Plain Terms\u00b6","text":"<p>We model a population of ants living on a rectangular grid rich in sugar. Each cell can host at most one ant and holds a fixed amount of sugar. Every time step unfolds as follows:</p> <ul> <li>Sense: each ant looks outward along the four cardinal directions up to its <code>vision</code> radius and spots open cells.</li> <li>Move: the ant chooses the cell with highest sugar (breaking ties by distance and coordinates). In the instant-growback variant used here, any cell that was occupied at the end of the previous step has sugar 0 (it was harvested and did not regrow).</li> <li>Eat &amp; survive: ants harvest the sugar on the cell they occupy. If their sugar stock falls below their <code>metabolism</code> cost, they die.</li> <li>Regrow: sugar instantly regrows to its maximum level on empty cells. The landscape is drawn from a uniform distribution, so resources are homogeneous on average and the interesting dynamics come from agent heterogeneity and congestion.</li> </ul> <p>The update schedule matters for micro-behaviour, so we study three variants:</p> <ol> <li>Sequential loop (asynchronous): This is the traditional definition. Ants move one at a time in random order. This cannot be vectorised easily as the best move for an ant might depend on the moves of earlier ants (for example, if they target the same cell).</li> <li>Sequential with Numba: matches the first variant but relies on a compiled helper for speed.</li> <li>Parallel (synchronous): ants rank candidate destinations using the start-of-step sugar field; conflicts are resolved by a random lottery in rounds (losers fall back to their next choice). If an ant wins a destination other than its origin, its origin becomes available to other ants in later rounds of the same step.</li> </ol> <p>The first variant (pure Python loops) is a natural starting point, but it is not the mesa-frames philosophy. The latter two are: we aim to write rules declaratively and let the dataframe engine worry about performance. Our guiding principle is to focus on modelling first and performance second. Only when a rule is truly inherently sequential do we fall back to a compiled kernel (Numba or JAX).</p> <p>Our goal is to compare these update rules and show how far a synchronous, dataframe-friendly rule can go as a performance-oriented relaxation of the classic sequential schedule. Some macroscopic summaries (like total sugar or the Gini coefficient of wealth) often remain qualitatively similar, while more fine-grained statistics (like wealth\u2013trait correlations) can drift noticeably for individual seeds because conflict resolution changes which traits win contested cells.</p>"},{"location":"tutorials/3_advanced_tutorial/#1-imports","title":"1. Imports\u00b6","text":""},{"location":"tutorials/3_advanced_tutorial/#2-model-definition","title":"2. Model definition\u00b6","text":"<p>In this section we define some helpers and the model class that wires together the grid and the agents. The <code>agent_type</code> parameter stays flexible so we can plug in different movement policies later, but the model now owns the logic that generates the sugar field and the initial agent frame. Because both helpers use <code>self.random</code>, instantiating each variant with the same seed keeps the initial conditions identical across the sequential, Numba, and parallel implementations.</p> <p>The space is a von Neumann grid (which means agents can only move up, down, left, or right) with capacity 1, meaning each cell can host at most one agent. The sugar field is stored as part of the cell data frame, with columns for current sugar and maximum sugar (for regrowth). The model also sets up a data collector to track aggregate statistics and agent traits over time.</p> <p>The <code>step</code> method advances the sugar field, triggers the agent set's step.</p> <p>We also define some useful functions to compute metrics like the Gini coefficient and correlations.</p>"},{"location":"tutorials/3_advanced_tutorial/#3-agent-definition","title":"3. Agent definition\u00b6","text":""},{"location":"tutorials/3_advanced_tutorial/#31-base-agent-class","title":"3.1 Base agent class\u00b6","text":"<p>Now let's define the agent class (the ant class). We start with a base class which implements the common logic for eating and starvation, while leaving the <code>move</code> method abstract. The base class also provides helper methods for sensing visible cells and choosing the best cell based on sugar, distance, and coordinates. This will allow us to define different movement policies (sequential, Numba-accelerated, and parallel) as subclasses that only need to implement the <code>move</code> method.</p>"},{"location":"tutorials/3_advanced_tutorial/#32-sequential-movement","title":"3.2 Sequential movement\u00b6","text":"<p>We now implement the simplest movement policy: sequential (asynchronous). Each agent moves one at a time in the current ordering, choosing the best visible cell according to the rules.</p> <p>This implementation uses plain Python loops as the logic cannot be easily vectorised. As a result, it is slow for large populations and grids. We will later show how to speed it up with Numba.</p>"},{"location":"tutorials/3_advanced_tutorial/#33-speeding-up-the-loop-with-numba","title":"3.3 Speeding Up the Loop with Numba\u00b6","text":"<p>As we will see later, the previous sequential implementation is slow for large populations and grids because it relies on plain Python loops. We can speed it up significantly by using Numba to compile the movement logic.</p> <p>Numba compiles numerical Python code to fast machine code at runtime. To use Numba, we need to rewrite the movement logic in a way that is compatible with Numba's restrictions (using tightly typed numpy arrays and accessing data indexes directly).</p>"},{"location":"tutorials/3_advanced_tutorial/#34-simultaneous-movement-with-conflict-resolution-the-polars-mesa-frames-idiomatic-way","title":"3.4 Simultaneous Movement with Conflict Resolution (the Polars mesa-frames idiomatic way)\u00b6","text":"<p>The previous implementation is optimal speed-wise but it's a bit low-level. It requires maintaining an occupancy grid and imperative loops and it might become tricky to extend with more complex movement rules or models. To stay in mesa-frames idiom, we can implement a parallel movement policy that uses Polars DataFrame operations to resolve conflicts when multiple agents target the same cell. These conflicts are resolved in rounds: in each round, each agent proposes its current best candidate cell; winners per cell are chosen at random, and losers are promoted to their next-ranked choice. This continues until all agents have moved. This implementation is a tad slower but still efficient and easier to read (for a Polars user).</p>"},{"location":"tutorials/3_advanced_tutorial/#4-run-the-model-variants","title":"4. Run the Model Variants\u00b6","text":"<p>We iterate over each movement policy with a shared helper so all runs reuse the same seed. The tutorial runs all three variants (Python sequential, Numba sequential, and parallel) by default; edit the script if you want to skip the slow pure-Python baseline.</p>"},{"location":"tutorials/3_advanced_tutorial/#5-comparing-the-update-rules","title":"5. Comparing the Update Rules\u00b6","text":"<p>Even though micro rules differ, aggregate trajectories remain qualitatively similar (sugar trends up while population gradually declines). When we join the traces step-by-step, we see small but noticeable deviations introduced by synchronous conflict resolution (e.g., a few more retirements when conflicts cluster).</p> <p>In our run (seed=42, with vacated origins available to others), the final-step Gini differs by \u22480.045, and wealth-trait correlations diverge by a few 1e-2 to 1e-1. These gaps vary by seed and grid size. In practice the parallel rule is best seen as a performance-oriented relaxation of the sequential schedule: it can preserve broad macro trends, but it is not a drop-in replacement when you care about seed-level microstructure.</p>"},{"location":"tutorials/3_advanced_tutorial/#6-takeaways-and-next-steps","title":"6. Takeaways and Next Steps\u00b6","text":"<p>Some final notes:</p> <ul> <li>mesa-frames should preferably be used when you have many agents and operations can be vectorized.</li> <li>If your model is not easily vectorizable, consider using Numba or reducing your microscopic rule to a vectorizable form. As we saw, the macroscopic behavior can remain consistent (and be more similar to real-world systems).</li> </ul> <p>Currently, the Polars implementation spends most of the time in join operations.</p> <p>Polars + LazyFrames roadmap - future mesa-frames releases will expose LazyFrame-powered sets and spaces (which can also use a GPU cuda accelerated backend which greatly accelerates joins), so the same Polars code you wrote here will scale even further without touching Numba.</p>"},{"location":"tutorials/4_datacollector/","title":"Data Collector Tutorial","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[2]: Copied! <pre>#!pip install git+https://github.com/projectmesa/mesa-frames mesa\n</pre> #!pip install git+https://github.com/projectmesa/mesa-frames mesa In\u00a0[3]: Copied! <pre>from mesa_frames import Model, AgentSet, DataCollector\nimport polars as pl\n\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        # one column, one unit of wealth each\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.select(self.wealth &gt; 0)\n        receivers = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        income = receivers.group_by(\"unique_id\").len()\n        self[income[\"unique_id\"], \"wealth\"] += income[\"len\"]\n\n\nclass MoneyModel(Model):\n    def __init__(self, n: int):\n        super().__init__()\n        self.sets.add(MoneyAgents(n, self))\n        self.dc = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n                \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n            },\n            agent_reporters={\n                \"wealth\": \"wealth\",  # pull existing column\n            },\n            storage=\"memory\",  # we'll switch this per example\n            storage_uri=None,\n            trigger=lambda m: m.steps % 2\n            == 0,  # collect every 2 steps via conditional_collect\n            reset_memory=True,\n        )\n\n    def step(self):\n        self.sets.do(\"step\")\n\n    def run(self, steps: int, conditional: bool = True):\n        for _ in range(steps):\n            self.step()\n            self.dc.conditional_collect()  # or .collect if you want to collect every step regardless of trigger\n\n\nmodel = MoneyModel(1000)\nmodel.run(10)\nmodel.dc.data  # peek in-memory dataframes\n</pre> from mesa_frames import Model, AgentSet, DataCollector import polars as pl   class MoneyAgents(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         # one column, one unit of wealth each         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.select(self.wealth &gt; 0)         receivers = self.df.sample(n=len(self.active_agents), with_replacement=True)         self[\"active\", \"wealth\"] -= 1         income = receivers.group_by(\"unique_id\").len()         self[income[\"unique_id\"], \"wealth\"] += income[\"len\"]   class MoneyModel(Model):     def __init__(self, n: int):         super().__init__()         self.sets.add(MoneyAgents(n, self))         self.dc = DataCollector(             model=self,             model_reporters={                 \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),                 \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),             },             agent_reporters={                 \"wealth\": \"wealth\",  # pull existing column             },             storage=\"memory\",  # we'll switch this per example             storage_uri=None,             trigger=lambda m: m.steps % 2             == 0,  # collect every 2 steps via conditional_collect             reset_memory=True,         )      def step(self):         self.sets.do(\"step\")      def run(self, steps: int, conditional: bool = True):         for _ in range(steps):             self.step()             self.dc.conditional_collect()  # or .collect if you want to collect every step regardless of trigger   model = MoneyModel(1000) model.run(10) model.dc.data  # peek in-memory dataframes Out[3]: <pre>{'model': shape: (5, 5)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 step \u2506 seed                            \u2506 batch \u2506 total_wealth \u2506 n_agents \u2502\n \u2502 ---  \u2506 ---                             \u2506 ---   \u2506 ---          \u2506 ---      \u2502\n \u2502 i64  \u2506 str                             \u2506 i64   \u2506 f64          \u2506 i64      \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 2    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 4    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 6    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 8    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 10   \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518,\n 'agent': shape: (5_000, 4)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 wealth_MoneyAgents \u2506 step \u2506 seed                            \u2506 batch \u2502\n \u2502 ---                \u2506 ---  \u2506 ---                             \u2506 ---   \u2502\n \u2502 f64                \u2506 i32  \u2506 str                             \u2506 i32   \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 0.0                \u2506 2    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 2    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 3.0                \u2506 2    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 2    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 2    \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 \u2026                  \u2506 \u2026    \u2506 \u2026                               \u2506 \u2026     \u2502\n \u2502 0.0                \u2506 10   \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 10   \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 10   \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 2.0                \u2506 10   \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 10   \u2506 304388568780017011125276432106\u2026 \u2506 0     \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518}</pre> In\u00a0[4]: Copied! <pre>import os\n\nos.makedirs(\"./data_csv\", exist_ok=True)\nmodel_csv = MoneyModel(1000)\nmodel_csv.dc = DataCollector(\n    model=model_csv,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"csv\",  # saving as csv\n    storage_uri=\"./data_csv\",\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_csv.run(10)\nmodel_csv.dc.flush()\nos.listdir(\"./data_csv\")\n</pre> import os  os.makedirs(\"./data_csv\", exist_ok=True) model_csv = MoneyModel(1000) model_csv.dc = DataCollector(     model=model_csv,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"csv\",  # saving as csv     storage_uri=\"./data_csv\",     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_csv.run(10) model_csv.dc.flush() os.listdir(\"./data_csv\") Out[4]: <pre>[]</pre> In\u00a0[5]: Copied! <pre>os.makedirs(\"./data_parquet\", exist_ok=True)\nmodel_parq = MoneyModel(1000)\nmodel_parq.dc = DataCollector(\n    model=model_parq,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"parquet\",  # save as parquet\n    storage_uri=\"data_parquet\",\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_parq.run(10)\nmodel_parq.dc.flush()\nos.listdir(\"./data_parquet\")\n</pre> os.makedirs(\"./data_parquet\", exist_ok=True) model_parq = MoneyModel(1000) model_parq.dc = DataCollector(     model=model_parq,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"parquet\",  # save as parquet     storage_uri=\"data_parquet\",     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_parq.run(10) model_parq.dc.flush() os.listdir(\"./data_parquet\") Out[5]: <pre>[]</pre> In\u00a0[6]: Copied! <pre>model_s3 = MoneyModel(1000)\nmodel_s3.dc = DataCollector(\n    model=model_s3,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"S3-csv\",  # save as csv in S3\n    storage_uri=\"s3://my-bucket/experiments/run-1\",  # change it to required path\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_s3.run(10)\nmodel_s3.dc.flush()\n</pre> model_s3 = MoneyModel(1000) model_s3.dc = DataCollector(     model=model_s3,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"S3-csv\",  # save as csv in S3     storage_uri=\"s3://my-bucket/experiments/run-1\",  # change it to required path     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_s3.run(10) model_s3.dc.flush() In\u00a0[7]: Copied! <pre>DDL_MODEL = r\"\"\"\nCREATE SCHEMA IF NOT EXISTS public;\nCREATE TABLE IF NOT EXISTS public.model_data (\n  step INTEGER,\n  seed VARCHAR,\n  total_wealth BIGINT,\n  n_agents INTEGER\n);\n\"\"\"\nDDL_AGENT = r\"\"\"\nCREATE TABLE IF NOT EXISTS public.agent_data (\n  step INTEGER,\n  seed VARCHAR,\n  unique_id BIGINT,\n  wealth BIGINT\n);\n\"\"\"\nprint(DDL_MODEL)\nprint(DDL_AGENT)\n</pre> DDL_MODEL = r\"\"\" CREATE SCHEMA IF NOT EXISTS public; CREATE TABLE IF NOT EXISTS public.model_data (   step INTEGER,   seed VARCHAR,   total_wealth BIGINT,   n_agents INTEGER ); \"\"\" DDL_AGENT = r\"\"\" CREATE TABLE IF NOT EXISTS public.agent_data (   step INTEGER,   seed VARCHAR,   unique_id BIGINT,   wealth BIGINT ); \"\"\" print(DDL_MODEL) print(DDL_AGENT) <pre>\nCREATE SCHEMA IF NOT EXISTS public;\nCREATE TABLE IF NOT EXISTS public.model_data (\n  step INTEGER,\n  seed VARCHAR,\n  total_wealth BIGINT,\n  n_agents INTEGER\n);\n\n\nCREATE TABLE IF NOT EXISTS public.agent_data (\n  step INTEGER,\n  seed VARCHAR,\n  unique_id BIGINT,\n  wealth BIGINT\n);\n\n</pre> <p>After creating the tables (outside this notebook or via a DB connection cell), configure and flush:</p> In\u00a0[8]: Copied! <pre>POSTGRES_URI = \"postgresql://user:pass@localhost:5432/mydb\"\nm_pg = MoneyModel(300)\nm_pg.dc._storage = \"postgresql\"\nm_pg.dc._storage_uri = POSTGRES_URI\nm_pg.run(6)\nm_pg.dc.flush()\n</pre> POSTGRES_URI = \"postgresql://user:pass@localhost:5432/mydb\" m_pg = MoneyModel(300) m_pg.dc._storage = \"postgresql\" m_pg.dc._storage_uri = POSTGRES_URI m_pg.run(6) m_pg.dc.flush() In\u00a0[9]: Copied! <pre>m = MoneyModel(100)\nm.dc.trigger = lambda model: model._steps % 3 == 0  # every 3rd step\nm.run(10, conditional=True)\nm.dc.data[\"model\"].head()\n</pre> m = MoneyModel(100) m.dc.trigger = lambda model: model._steps % 3 == 0  # every 3rd step m.run(10, conditional=True) m.dc.data[\"model\"].head() Out[9]: shape: (5, 5)stepseedbatchtotal_wealthn_agentsi64stri64f64i642\"228877995575074633143113668944\u20260100.01004\"228877995575074633143113668944\u20260100.01006\"228877995575074633143113668944\u20260100.01008\"228877995575074633143113668944\u20260100.010010\"228877995575074633143113668944\u20260100.0100 <p>Generated on 2025-08-30.</p>"},{"location":"tutorials/4_datacollector/#data-collector-tutorial","title":"Data Collector Tutorial\u00b6","text":"<p>This notebook walks you through using the concrete <code>DataCollector</code> in <code>mesa-frames</code> to collect model- and agent-level data and write it to different storage backends: memory, CSV, Parquet, S3, and PostgreSQL.</p> <p>It also shows how to use conditional triggers and how the schema validation behaves for PostgreSQL.</p>"},{"location":"tutorials/4_datacollector/#installation-colab-or-fresh-env","title":"Installation (Colab or fresh env)\u00b6","text":"<p>Uncomment and run the next cell if you're in Colab or a clean environment.</p>"},{"location":"tutorials/4_datacollector/#minimal-example-model","title":"Minimal Example Model\u00b6","text":"<p>We create a tiny model using the <code>Model</code> and an <code>AgentSet</code>-style agent container. This is just to demonstrate collection APIs.</p>"},{"location":"tutorials/4_datacollector/#saving-the-data-for-later-use","title":"Saving the data for later use\u00b6","text":"<p><code>DataCollector</code> supports multiple storage backends. Files are saved with step number and batch number (e.g., <code>model_step10_batch2.csv</code>) so multiple collects at the same step don\u2019t overwrite.</p> <ul> <li>CSV: <code>storage=\"csv\"</code> \u2192 writes <code>model_step{n}_batch{k}.csv</code>, easy to open anywhere.</li> <li>Parquet: <code>storage=\"parquet\"</code> \u2192 compressed, efficient for large datasets.</li> <li>S3: <code>storage=\"S3-csv\"</code>/<code>storage=\"S3-parquet\"</code> \u2192 saves CSV/Parquet directly to Amazon S3.</li> <li>PostgreSQL: <code>storage=\"postgresql\"</code> \u2192 inserts results into <code>model_data</code> and <code>agent_data</code> tables for querying.</li> </ul>"},{"location":"tutorials/4_datacollector/#writing-to-local-csv","title":"Writing to Local CSV\u00b6","text":"<p>Switch the storage to <code>csv</code> and provide a folder path. Files are written as <code>model_step{n}.csv</code> and <code>agent_step{n}.csv</code>.</p>"},{"location":"tutorials/4_datacollector/#writing-to-local-parquet","title":"Writing to Local Parquet\u00b6","text":"<p>Use <code>parquet</code> for columnar output.</p>"},{"location":"tutorials/4_datacollector/#writing-to-amazon-s3-csv-or-parquet","title":"Writing to Amazon S3 (CSV or Parquet)\u00b6","text":"<p>Set AWS credentials via environment variables or your usual config. Then choose <code>S3-csv</code> or <code>S3-parquet</code> and pass an S3 URI (e.g., <code>s3://my-bucket/experiments/run-1</code>).</p> <p>Note: This cell requires network access &amp; credentials when actually run.</p>"},{"location":"tutorials/4_datacollector/#writing-to-postgresql","title":"Writing to PostgreSQL\u00b6","text":"<p>PostgreSQL requires that the target tables exist and that the expected reporter columns are present. The collector will validate tables/columns up front and raise descriptive errors if something is missing.</p> <p>Below is a minimal schema example. Adjust columns to your configured reporters.</p>"},{"location":"tutorials/4_datacollector/#triggers-conditional-collection","title":"Triggers &amp; Conditional Collection\u00b6","text":"<p>The collector accepts a <code>trigger: Callable[[Model], bool]</code>. When using <code>conditional_collect()</code>, the collector checks the trigger and collects only if it returns <code>True</code>.</p> <p>You can always call <code>collect()</code> to gather data unconditionally.</p>"},{"location":"tutorials/4_datacollector/#troubleshooting","title":"Troubleshooting\u00b6","text":"<ul> <li>ValueError: Please define a storage_uri \u2014 for non-memory backends you must set <code>_storage_uri</code>.</li> <li>Missing columns in table \u2014 check the PostgreSQL error text; create/alter the table to include the columns for your configured <code>model_reporters</code> and <code>agent_reporters</code>, plus required <code>step</code> and <code>seed</code>.</li> <li>Permissions/credentials errors (S3/PostgreSQL) \u2014 ensure correct IAM/credentials or database permissions.</li> </ul>"},{"location":"user-guide/0_getting-started/","title":"Getting Started \ud83d\ude80","text":""},{"location":"user-guide/0_getting-started/#main-concepts","title":"Main Concepts \ud83e\udde0","text":""},{"location":"user-guide/0_getting-started/#dataframe-based-object-oriented-framework","title":"DataFrame-Based Object-Oriented Framework \ud83d\udcca","text":"<p>Unlike traditional mesa models where each agent is an individual Python object, mesa-frames stores all agents of a particular type in a single DataFrame. We operate only at the AgentSet level.</p> <p>This approach allows for:</p> <ul> <li>Efficient memory usage</li> <li>Improved performance through vectorized operations on agent attributes (This is what makes <code>mesa-frames</code> fast)</li> </ul> <p>Objects can be easily subclassed to respect mesa's object-oriented philosophy.</p>"},{"location":"user-guide/0_getting-started/#vectorized-operations","title":"Vectorized Operations \u26a1","text":"<p><code>mesa-frames</code> leverages Polars to replace Python loops with column-wise expressions executed in native Rust. This allows you to update all agents simultaneously, the main source of <code>mesa-frames</code>' performance advantage.</p> <p>Unlike traditional <code>mesa</code> models, where the activation order of agents can affect results (see Comer, 2014), <code>mesa-frames</code> processes all agents in parallel by default. This removes order-dependent effects, though you should handle conflicts explicitly when sequential logic is required.</p> <p>Best practice</p> <p>Always start by expressing agent logic in a vectorized form. Fall back to loops only when ordering or conflict resolution is essential.</p> <p>For a deeper understanding of vectorization and why it accelerates computation, see:</p> <ul> <li>How vectorization speeds up your Python code \u2014 PythonSpeed</li> </ul> <p>Here's a comparison between mesa-frames and mesa:</p> mesa-framesmesa <pre><code>class MoneyAgents(AgentSet):\n    # initialization...\n    def give_money(self):\n        # Active agents are changed to wealthy agents\n        self.select(self.wealth &gt; 0)\n\n        # Receiving agents are sampled (only native expressions currently supported)\n        other_agents = self.df.sample(\n            n=len(self.active_agents), with_replacement=True\n        )\n\n        # Wealth of wealthy is decreased by 1\n        self[\"active\", \"wealth\"] -= 1\n\n        # Compute the income of the other agents (only native expressions currently supported)\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        self[new_wealth, \"wealth\"] += new_wealth[\"len\"]\n</code></pre> <pre><code>class MoneyAgent(mesa.Agent):\n    # initialization...\n    def give_money(self):\n        # Verify agent has some wealth\n        if self.wealth &gt; 0:\n            other_agent = self.random.choice(self.model.sets)\n            if other_agent is not None:\n                other_agent.wealth += 1\n                self.wealth -= 1\n</code></pre> <p>As you can see, while in mesa you should iterate through all the agents' steps in the model class, here you execute the method once for all agents.</p>"},{"location":"user-guide/0_getting-started/#coming-from-mesa","title":"Coming from mesa \ud83d\udd00","text":"<p>If you're familiar with mesa, this guide will help you understand the key differences in code structure between mesa and mesa-frames.</p>"},{"location":"user-guide/0_getting-started/#agent-representation","title":"Agent Representation \ud83d\udc65","text":"<ul> <li>mesa: Each agent is an individual object instance. Methods are defined for individual agents and called on each agent.</li> <li>mesa-frames: Agents are rows in a DataFrame, grouped into AgentSets. Methods are defined for AgentSets and operate on all agents simultaneously.</li> </ul> mesa-framesmesa <pre><code>class MoneyAgents(AgentSet):\n    def __init__(self, n, model):\n        super().__init__(model)\n        self += pl.DataFrame({\n            \"wealth\": pl.ones(n)\n            })\n    def step(self):\n        givers = self.wealth &gt; 0\n        receivers = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[givers, \"wealth\"] -= 1\n        new_wealth = receivers.group_by(\"unique_id\").len()\n        self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"len\"]\n</code></pre> <pre><code>class MoneyAgent(Agent):\n    def __init__(self, unique_id, model):\n        super().__init__(unique_id, model)\n        self.wealth = 1\n\n    def step(self):\n        if self.wealth &gt; 0:\n            other_agent = self.random.choice(self.model.schedule.agents)\n            other_agent.wealth += 1\n            self.wealth -= 1\n</code></pre>"},{"location":"user-guide/0_getting-started/#model-structure","title":"Model Structure \ud83c\udfd7\ufe0f","text":"<ul> <li>mesa: Models manage individual agents and use a scheduler.</li> <li>mesa-frames: Models manage AgentSets and directly control the simulation flow.</li> </ul> mesa-framesmesa <pre><code>class MoneyModel(Model):\n    def __init__(self, N):\n        super().__init__()\n        self.sets += MoneyAgents(N, self)\n\n    def step(self):\n        self.sets.do(\"step\")\n</code></pre> <pre><code>class MoneyModel(Model):\n    def __init__(self, N):\n        self.num_agents = N\n        self.schedule = RandomActivation(self)\n        for i in range(self.num_agents):\n            a = MoneyAgent(i, self)\n            self.schedule.add(a)\n\n    def step(self):\n        self.schedule.step()\n</code></pre>"},{"location":"user-guide/0_getting-started/#from-imperative-code-to-behavioral-rules","title":"From Imperative Code to Behavioral Rules \ud83d\udcad","text":"<p>When scientists describe an ABM-like process they typically write a system of state-transition functions:</p> \\[ x_i(t+1) = f_i\\big(x_i(t),\\; \\mathcal{N}(i,t),\\; E(t)\\big) \\] <p>Here, \\(x_i(t)\\) is the agent\u2019s state, \\(\\mathcal{N}(i,t)\\) its neighborhood or local environment, and \\(E(t)\\) a global environment; \\(f_i\\) is the behavioral law.</p> <p>In classic <code>mesa</code>, agent behavior is implemented through explicit loops: each agent individually gathers information from its neighbors, computes its next state, and often stores this in a buffer to ensure synchronous updates. The behavioral law \\(f_i\\) is distributed across multiple steps: neighbor iteration, temporary buffers, and scheduling logic, resulting in procedural, step-by-step control flow.</p> <p>In <code>mesa-frames</code>, these stages are unified into a single vectorized transformation. Agent interactions, state transitions, and updates are expressed as DataFrame operations (such as joins, group-bys, and column expressions) allowing all agents to process perceptions and commit actions simultaneously. This approach centralizes the behavioral law \\(f_i\\) into concise, declarative rules, improving clarity and performance.</p>"},{"location":"user-guide/0_getting-started/#example-network-contagion-linear-threshold","title":"Example: Network contagion (Linear Threshold)","text":"<p>Behavioral rule: a node activates if the number of active neighbors \u2265 its threshold.</p> mesa-framesmesa <p>Single vectorized transformation. A join brings in source activity, a group-by aggregates exposures per destination, and a column expression applies the activation equation and commits in one pass, no explicit loops or staging structure needed.</p> <pre><code>class Nodes(AgentSet):\n    # self.df columns: agent_id, active (bool), theta (int)\n    # self.model.space.edges: DataFrame[src, dst]\n    def step(self):\n        E = self.model.space.edges  # [src, dst]\n        # Exposure: active neighbors per dst (vectorized join + groupby)\n        exposures = (\n            E.join(\n                self.df.select(pl.col(\"agent_id\").alias(\"src\"),\n                               pl.col(\"active\").alias(\"src_active\")),\n                on=\"src\", how=\"left\"\n            )\n            .with_columns(pl.col(\"src_active\").fill_null(False))\n            .group_by(\"dst\")\n            .agg(pl.col(\"src_active\").sum().alias(\"k_active\"))\n        )\n        # Behavioral equation applied to all agents, committed in-place\n        self.df = (\n            self.df\n            .join(exposures, left_on=\"agent_id\", right_on=\"dst\", how=\"left\")\n            .with_columns(pl.col(\"k_active\").fill_null(0))\n            .with_columns(\n                (pl.col(\"active\") | (pl.col(\"k_active\") &gt;= pl.col(\"theta\")))\n                .alias(\"active\")\n            )\n            .drop([\"k_active\", \"dst\"])\n        )\n</code></pre> <p>Two-phase imperative procedure. Each agent loops over its neighbors to count active ones (exposure), stores a provisional next state to avoid premature mutation, then a separate pass commits all buffered states for synchronicity.</p> <pre><code>class Node(mesa.Agent):\n    def step(self):\n        # (1) Gather exposure: count active neighbors right now\n        k_active = sum(\n            1 for j in self.model.G.neighbors(self.unique_id)\n            if self.model.id2agent[j].active\n        )\n        # (2) Compute next state (don't mutate yet to stay synchronous)\n        self.next_active = self.active or (k_active &gt;= self.theta)\n\n# Second pass (outside the agent method) performs the commit:\nfor a in model.agents:\n    a.active = a.next_active\n</code></pre> <p>Transition tips \u2014 quick summary</p> <ol> <li>Think in sets: operate on AgentSets/DataFrames, not per-agent objects.</li> <li>Write transitions as Polars column expressions; avoid Python loops.</li> <li>Use joins + group-bys to compute interactions/exposure across relations.</li> <li>Commit state synchronously in one vectorized pass.</li> <li>Group similar agents into one AgentSet with typed columns.</li> <li>Use UDFs or staged/iterative patterns only for true race/conflict cases.</li> </ol>"},{"location":"user-guide/0_getting-started/#handling-race-conditions","title":"Handling Race Conditions \ud83c\udfc1","text":"<p>When simultaneous activation is not possible, you need to handle race conditions carefully. There are two main approaches:</p> <ol> <li> <p>Custom UDF with Numba \ud83d\udd27: Use a custom User Defined Function (UDF) with Numba for efficient sequential processing.</p> </li> <li> <p>Polars UDF Guide</p> </li> <li> <p>Looping Mechanism \ud83d\udd01: Implement a looping mechanism on vectorized operations.</p> </li> </ol> <p>For a more detailed implementation of handling race conditions, see the Advanced Tutorial. It walks through the Sugarscape model with instantaneous growback and shows practical patterns for staged vectorization and conflict resolution.</p>"},{"location":"user-guide/1_classes/","title":"Classes \ud83d\udcda","text":""},{"location":"user-guide/1_classes/#agentset","title":"AgentSet \ud83d\udc65","text":"<p>To create your own AgentSet class, you need to subclass the AgentSet class and make sure to call <code>super().__init__(model)</code>.</p> <p>Typically, the next step would be to populate the class with your agents. To do that, you need to add a DataFrame to the AgentSet. You can do <code>self += agents</code> or <code>self.add(agents)</code>, where <code>agents</code> is a DataFrame or something that could be passed to a DataFrame constructor, like a dictionary or lists of lists. You need to make sure your DataFrame doesn't have a 'unique_id' column because IDs are generated automatically, otherwise you will get an error raised. In the DataFrame, you should also put any attribute of the agent you are using.</p> <p>How can you choose which agents should be in the same AgentSet? The idea is that you should minimize the missing values in the DataFrame (so they should have similar/same attributes) and mostly everybody should do the same actions.</p> <p>Example:</p> <pre><code>class MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self.initial_wealth = pl.ones(n)\n        self += pl.DataFrame({\n            \"wealth\": self.initial_wealth\n        })\n\n    def step(self):\n        self[\"wealth\"] = self[\"wealth\"] + self.random.integers(n)\n</code></pre> <p>You can access the underlying DataFrame where agents are stored with <code>self.df</code>. This allows you to use DataFrame methods like <code>self.df.sample</code> or <code>self.df.group_by(\"wealth\")</code> and more.</p>"},{"location":"user-guide/1_classes/#model","title":"Model \ud83c\udfd7\ufe0f","text":"<p>To add your AgentSet to your Model, use the registry <code>self.sets</code> with <code>+=</code> or <code>add</code>.</p> <p>Note: All agent sets live inside <code>AgentSetRegistry</code> (available as <code>model.sets</code>). Access sets through the registry, and access DataFrames from the set itself. For example: <code>self.sets[\"Preys\"].df</code>.</p> <p>Example:</p> <pre><code>class EcosystemModel(Model):\n    def __init__(self, n_prey, n_predators):\n        super().__init__()\n        self.sets += Preys(n_prey, self)\n        self.sets += Predators(n_predators, self)\n\n    def step(self):\n        self.sets.do(\"move\")\n        self.sets.do(\"hunt\")\n        # Access specific sets via the registry\n        self.sets[\"Preys\"].do(\"reproduce\")\n</code></pre>"},{"location":"user-guide/1_classes/#space-grid","title":"Space: Grid \ud83c\udf10","text":"<p>mesa-frames provides efficient implementations of spatial environments:</p> <ul> <li>Spatial operations (like moving agents) are vectorized for performance</li> </ul> <p>Example:</p> <pre><code>class GridWorld(Model):\n    def __init__(self, width, height):\n        super().__init__()\n        self.space = Grid(self, (width, height))\n        self.sets += AgentSet(100, self)\n        self.space.place_to_empty(self.sets)\n</code></pre> <p>A continuous GeoSpace, NetworkSpace, and a collection to have multiple spaces in the models are in the works! \ud83d\udea7</p>"},{"location":"user-guide/1_classes/#datacollector","title":"DataCollector \ud83d\uddc2\ufe0f","text":"<p><code>DataCollector</code> records model- and agent-level data during simulation. You configure what to collect, how to store it, and when to trigger collection.</p> <p>Example:</p> <pre><code>class ExampleModel(Model):\n    def __init__(self):\n        super().__init__()\n        # Add the set to the registry\n        self.sets.add(MoneyAgents(100, self))\n        # Configure reporters: use the registry to locate sets; get df from the set\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n            },\n            agent_reporters={\"wealth\": \"wealth\"},\n            storage=\"csv\",\n            storage_uri=\"./data\",\n            trigger=lambda m: m.steps % 2 == 0,\n        )\n\n    def step(self):\n        # Step all sets via the registry\n        self.sets.do(\"step\")\n        self.datacollector.conditional_collect()\n        self.datacollector.flush()\n</code></pre>"}]}