{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"mesa-frames CI/CD Package Meta Chat"},{"location":"#scale-mesa-beyond-its-limits","title":"Scale Mesa beyond its limits","text":"<p>Classic Mesa stores each agent as a Python object, which quickly becomes a bottleneck at scale. mesa-frames reimagines agent storage using Polars DataFrames, so agents live in a columnar store rather than the Python heap.</p> <p>You keep the Mesa-style <code>Model</code> / <code>AgentSet</code> structure, but updates are vectorized and memory-efficient.</p>"},{"location":"#why-it-matters","title":"Why it matters","text":"<ul> <li>\u26a1 10\u00d7 faster bulk updates on 10k+ agents (see Benchmarks)</li> <li>\ud83d\udcca Columnar execution via Polars: SIMD ops, multi-core support</li> <li>\ud83d\udd04 Declarative logic: agent rules as transformations, not Python loops</li> <li>\ud83d\ude80 Roadmap: Lazy queries and GPU support for even faster models</li> </ul>"},{"location":"#who-is-it-for","title":"Who is it for?","text":"<ul> <li>Researchers needing to scale to tens or hundreds of thousands of agents</li> <li>Users whose agent logic can be written as vectorized, set-based operations</li> </ul> <p>\u274c Not a good fit if: your model depends on strict per-agent sequencing, complex non-vectorizable methods, or fine-grained identity tracking.</p>"},{"location":"#why-dataframes","title":"Why DataFrames?","text":"<p>DataFrames enable SIMD and columnar operations that are far more efficient than Python loops. mesa-frames currently uses Polars as its backend.</p> Feature mesa (classic) mesa-frames Storage Python objects Polars DataFrame Updates Loops Vectorized ops Memory overhead High Low Max agents (practical) ~10^3 ~10^6+"},{"location":"#benchmarks","title":"Benchmarks","text":"<p>mesa-frames delivers consistent speedups across both toy and canonical ABMs. At 10k agents, it runs ~10\u00d7 faster than classic Mesa, and the gap grows with scale.</p> <p></p> <p></p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Install</li> </ol> <pre><code>   pip install mesa-frames\n</code></pre> <p>Or for development:</p> <pre><code>git clone https://github.com/projectmesa/mesa-frames.git\ncd mesa-frames\nuv sync --all-extras\n</code></pre> <ol> <li>Create a model</li> </ol> <pre><code>from mesa_frames import AgentSet, Model\nimport polars as pl\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def give_money(self):\n        self.select(self.wealth &gt; 0)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n        self[new_wealth, \"wealth\"] += new_wealth[\"len\"]\n\n    def step(self):\n        self.do(\"give_money\")\n\nclass MoneyModelDF(Model):\n    def __init__(self, N: int):\n        super().__init__()\n        self.sets += MoneyAgents(N, self)\n\n    def step(self):\n        self.sets.do(\"step\")\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<p>Community contributions welcome \u2014 see the full roadmap</p> <ul> <li>Transition to LazyFrames for optimization and GPU support</li> <li>Auto-vectorize existing Mesa models via decorator</li> <li>Increase possible Spaces</li> <li>Refine the API to align to Mesa</li> </ul>"},{"location":"#license","title":"License","text":"<p>Copyright \u00a9 2025 Adam Amer, Project Mesa team and contributors</p> <p>Licensed under the Apache License, Version 2.0.</p>"},{"location":"contributing/","title":"Contributing to mesa-frames \ud83d\ude80","text":"<p>Thank you for taking the time to contribute to mesa-frames! Since the project is still in its early stages, we warmly welcome contributions that will help shape its development. \ud83c\udf89</p> <p>For a more general and comprehensive guide, please refer to mesa's main contribution guidelines. \ud83d\udcdc</p>"},{"location":"contributing/#project-roadmap","title":"Project Roadmap \ud83d\uddfa\ufe0f","text":"<p>Before contributing, we recommend reviewing our roadmap file to understand the project's current priorities, upcoming features, and long-term vision. This will help ensure your contributions align with the project's direction.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute \ud83d\udca1","text":""},{"location":"contributing/#1-prerequisite-installations","title":"1. Prerequisite Installations \u2699\ufe0f","text":"<p>Before you begin contributing, ensure that you have the necessary tools installed:</p> <ul> <li>Install Python (at least the version specified in <code>requires-python</code> of <code>pyproject.toml</code>). \ud83d\udc0d</li> <li>We recommend using a virtual environment manager like:</li> <li>Astral's UV \ud83c\udf1f</li> <li>Hatch \ud83c\udfd7\ufe0f</li> <li>Install pre-commit to enforce code quality standards before pushing changes:</li> <li>Pre-commit installation guide \u2705</li> <li>More about pre-commit hooks</li> <li>If using VS Code, consider installing these extensions to automatically enforce formatting:</li> <li>Ruff \u2013 Python linting &amp; formatting \ud83d\udc3e</li> <li>Markdownlint \u2013 Markdown linting (for documentation) \u270d\ufe0f</li> <li>Git Hooks \u2013 Automatically runs &amp; visualizes pre-commit hooks \ud83d\udd17</li> </ul>"},{"location":"contributing/#2-contribution-process","title":"2. Contribution Process \ud83d\udee0\ufe0f","text":""},{"location":"contributing/#step-1-choose-an-issue","title":"Step 1: Choose an Issue \ud83d\udccc","text":"<ul> <li>Pick an existing issue or create a new one if necessary.</li> <li>Ensure that your contribution aligns with the project's goals.</li> </ul>"},{"location":"contributing/#step-2-set-up-your-local-repository","title":"Step 2: Set Up Your Local Repository \ud83d\udcbb","text":"<ol> <li>Fork the repository on GitHub.</li> <li>Clone your fork to your local machine:</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/mesa-frames.git\n</code></pre> <ol> <li>Create a new branch with a descriptive name:</li> </ol> <pre><code>git checkout -b feature-name\n</code></pre> <ol> <li>Prevent merge commit clutter by setting rebase mode:</li> </ol> <pre><code>git config pull.rebase true\n</code></pre>"},{"location":"contributing/#step-3-install-dependencies","title":"Step 3: Install Dependencies \ud83d\udce6","text":"<p>We manage the development environment with uv:</p> <pre><code>uv sync --all-extras\n</code></pre> <p>This creates <code>.venv/</code> and installs mesa-frames with the development extras.</p>"},{"location":"contributing/#step-4-make-and-commit-changes","title":"Step 4: Make and Commit Changes \u2728","text":"<ol> <li>Make necessary edits and save the code.</li> <li>Add and commit your changes with meaningful commit messages:</li> </ol> <pre><code>git add FILE_NAME\ngit commit -m \"Fix issue X: Brief description of the fix\"\n</code></pre> <ul> <li>Keep commits small and focused on a single logical change.</li> <li>Follow Tim Pope\u2019s commit message guidelines. \ud83d\udcdd</li> </ul>"},{"location":"contributing/#step-5-code-quality-and-testing","title":"Step 5: Code Quality and Testing \u2705","text":"<ul> <li>Run pre-commit hooks to enforce code quality standards:</li> </ul> <pre><code>uv run pre-commit run -a\n</code></pre> <ul> <li>Run tests to ensure your contribution does not break functionality:</li> </ul> <pre><code>uv run pytest -q --cov=mesa_frames --cov-report=term-missing\n</code></pre> <ul> <li>Optional: Enable runtime type checking during development for enhanced type safety:</li> </ul> <pre><code>MESA_FRAMES_RUNTIME_TYPECHECKING=1 uv run pytest -q --cov=mesa_frames --cov-report=term-missing\n</code></pre> <p>!!! tip \"Automatically Enabled\"       Runtime type checking is automatically enabled in these scenarios:</p> <pre><code>  - **Hatch development environment** (`hatch shell dev`)\n  - **VS Code debugging** (when using the debugger)\n  - **VS Code testing** (when running tests through VS Code's testing interface)\n\n  No manual setup needed in these environments!\n</code></pre> <p>For more details on runtime type checking, see the Development Guidelines.</p>"},{"location":"contributing/#step-6-documentation-updates-if-needed","title":"Step 6: Documentation Updates (If Needed) \ud83d\udcd6","text":"<ul> <li>If you add a new feature, update the documentation accordingly.</li> <li>We use MKDocs for documentation:</li> <li>Modify or create markdown files in the <code>docs/</code> folder.</li> <li> <p>Preview your changes by running:</p> <pre><code>uv run mkdocs serve\n</code></pre> </li> <li> <p>Open <code>http://127.0.0.1:8000</code> in your browser to verify documentation updates.</p> </li> </ul>"},{"location":"contributing/#step-7-push-changes-and-open-a-pull-request-pr","title":"Step 7: Push Changes and Open a Pull Request (PR) \ud83d\ude80","text":"<ol> <li>Push your changes to your fork:</li> </ol> <pre><code>git push origin feature-name\n</code></pre> <ol> <li>Open a pull request (PR):</li> <li>Follow GitHub\u2019s PR guide.</li> <li>Link the issue you are solving in the PR description.</li> </ol> <p>Thank you again for your contribution! \ud83c\udf89</p>"},{"location":"roadmap/","title":"Roadmap \ud83d\uddfa\ufe0f","text":"<p>This document outlines the development roadmap for the mesa-frames project. It provides insights into our current priorities, upcoming features, and long-term vision.</p>"},{"location":"roadmap/#010-stable-release-goals","title":"0.1.0 Stable Release Goals \ud83c\udfaf","text":""},{"location":"roadmap/#1-transitioning-polars-implementation-from-eager-api-to-lazy-api","title":"1. Transitioning polars implementation from eager API to lazy API","text":"<p>One of our major priorities was to move from pandas to polars as the primary dataframe backend. This transition was motivated by performance considerations. Now we should transition to using the lazily evaluated version of polars.</p> <p>Related issues: #10: GPU integration: Dask, cuda (cudf) and RAPIDS (Polars), #89: Investigate using Ibis for the common interface library to any DF backend, #52: Use of LazyFrames for Polars implementation</p>"},{"location":"roadmap/#progress-and-next-steps","title":"Progress and Next Steps","text":"<ul> <li>We are exploring Ibis or narwhals as a common interface library that could support multiple backends (Polars, DuckDB, Spark etc.), but since most of the development is currently in polars, we will currently continue using Polars.</li> <li>We're transitioning to the lazy API, mainly in order to use GPU acceleration</li> </ul>"},{"location":"roadmap/#2-handling-concurrency-management","title":"2. Handling Concurrency Management","text":"<p>A critical aspect of agent-based models is efficiently managing concurrent agent movements, especially when multiple agents attempt to move to the same location simultaneously. We aim to implement abstractions that handle these concurrency conditions automatically.</p> <p>Related issues: #108: Adding abstraction of optimal agent movement, #48: Emulate RandomActivation with DataFrame.rolling</p>"},{"location":"roadmap/#sugarscape-example-of-concurrency-issues","title":"Sugarscape Example of Concurrency Issues","text":"<p>Testing with many potential collisions revealed a specific issue:</p> <p>Problem scenario:</p> <ul> <li>Consider two agents targeting the same cell:</li> <li>A mid-priority agent (higher in the agent order)</li> <li>A low-priority agent (lower in the agent order)</li> <li>The mid-priority agent has low preference for the cell</li> <li>The low-priority agent has high preference for the cell</li> <li>Without accounting for priority:</li> <li>The mid-priority agent's best moves kept getting \"stolen\" by higher priority agents</li> <li>This forced it to resort to lower preference target cells</li> <li>However, these lower preference cells were often already taken by lower priority agents in previous iterations</li> </ul> <p>Solution approach:</p> <ul> <li>Implement a \"priority\" count to ensure that each action is \"legal\"</li> <li>This prevents race conditions but requires recomputing the priority at each iteration</li> <li>Current implementation may be slower than Numba due to this overhead</li> <li>After the Ibis refactoring, we can investigate if lazy evaluation can help mitigate this performance issue</li> </ul> <p>The Sugarscape example demonstrates the need for this abstraction, as multiple agents often attempt to move to the same cell simultaneously. By generalizing this functionality, we can eliminate the need for users to implement complex conflict resolution logic repeatedly.</p>"},{"location":"roadmap/#progress-and-next-steps_1","title":"Progress and Next Steps","text":"<ul> <li>Create utility functions in <code>DiscreteSpace</code> and <code>AgentSetRegistry</code> to move agents optimally based on specified attributes</li> <li>Provide built-in resolution strategies for common concurrency scenarios</li> <li>Ensure the implementation works efficiently with the vectorized approach of mesa-frames</li> </ul>"},{"location":"roadmap/#additional-010-goals","title":"Additional 0.1.0 Goals","text":"<ul> <li>Complete core API stabilization</li> <li>Completely mirror mesa's functionality</li> <li>Improve documentation and examples</li> <li>Address outstanding bugs and performance issues</li> </ul>"},{"location":"roadmap/#beyond-010","title":"Beyond 0.1.0","text":"<p>Future roadmap items will be added as the project evolves and new priorities emerge.</p> <p>We welcome community feedback on our roadmap! Please open an issue if you have suggestions or would like to contribute to any of these initiatives.</p>"},{"location":"development/","title":"Development Guidelines","text":""},{"location":"development/#runtime-type-checking","title":"Runtime Type Checking \ud83d\udd0d","text":"<p>mesa-frames includes optional runtime type checking using beartype for development and debugging purposes. This feature helps catch type-related errors early during development and testing.</p> <p>Automatically Enabled</p> <p>Runtime type checking is automatically enabled in the following scenarios:</p> <ul> <li>Hatch development environment (<code>hatch shell dev</code>) \u2014 via <code>pyproject.toml</code> configuration</li> <li>VS Code debugging \u2014 when using the debugger (<code>F5</code> or \"Python Debugger: Current File\")</li> <li>VS Code testing \u2014 when running tests through VS Code's testing interface</li> </ul> <p>No manual setup required in these environments!</p>"},{"location":"development/#development-environment-setup","title":"Development Environment Setup","text":""},{"location":"development/#option-1-hatch-development-environment-recommended","title":"Option 1: Hatch Development Environment (Recommended)","text":"<p>The easiest way to enable runtime type checking is to use Hatch's development environment:</p> <pre><code># Enter the development environment (auto-enables runtime type checking)\nhatch shell dev\n\n# Verify it's enabled\npython -c \"import os; print('Runtime type checking:', os.getenv('MESA_FRAMES_RUNTIME_TYPECHECKING'))\"\n# \u2192 Runtime type checking: true\n</code></pre>"},{"location":"development/#option-2-manual-environment-variable","title":"Option 2: Manual Environment Variable","text":"<p>For other development setups, you can manually enable runtime type checking:</p> <p>Runtime type checking can be enabled by setting the <code>MESA_FRAMES_RUNTIME_TYPECHECKING</code> environment variable:</p> <pre><code>export MESA_FRAMES_RUNTIME_TYPECHECKING=1\n# or\nexport MESA_FRAMES_RUNTIME_TYPECHECKING=true\n# or\nexport MESA_FRAMES_RUNTIME_TYPECHECKING=yes\n</code></pre>"},{"location":"development/#usage-examples","title":"Usage Examples","text":"<p>Automatic Activation</p> <p>If you're using Hatch dev environment, VS Code debugging, or VS Code testing, runtime type checking is already enabled automatically. The examples below are for manual activation in other scenarios.</p>"},{"location":"development/#for-development-and-testing","title":"For Development and Testing","text":"<pre><code># Enable runtime type checking for testing\nMESA_FRAMES_RUNTIME_TYPECHECKING=1 uv run pytest\n\n# Enable runtime type checking for running scripts\nMESA_FRAMES_RUNTIME_TYPECHECKING=1 uv run python your_script.py\n</code></pre>"},{"location":"development/#in-your-ide-or-development-environment","title":"In Your IDE or Development Environment","text":"<p>VS Code (Already Configured):</p> <ul> <li>Debugging: Runtime type checking is automatically enabled when using VS Code's debugger</li> <li>Testing: Automatically enabled when running tests through VS Code's testing interface</li> <li> <p>Manual override: You can also add it manually in <code>.vscode/settings.json</code>:</p> <pre><code>{\n    \"python.env\": {\n        \"MESA_FRAMES_RUNTIME_TYPECHECKING\": \"1\"\n    }\n}\n</code></pre> </li> </ul> <p>PyCharm: In your run configuration, add the environment variable:</p> <pre><code>MESA_FRAMES_RUNTIME_TYPECHECKING=1\n</code></pre>"},{"location":"development/#how-it-works","title":"How It Works","text":"<p>When enabled, the runtime type checking system:</p> <ol> <li>Automatically instruments all mesa-frames packages with beartype decorators</li> <li>Validates function arguments and return values at runtime</li> <li>Provides detailed error messages when type mismatches occur</li> <li>Helps catch type-related bugs during development</li> </ol>"},{"location":"development/#requirements","title":"Requirements","text":"<p>Runtime type checking requires the optional <code>beartype</code> dependency:</p> <pre><code># Install beartype for runtime type checking\nuv add beartype\n# or\npip install beartype\n</code></pre> <p>Optional Dependency</p> <p>If <code>beartype</code> is not installed and runtime type checking is enabled, mesa-frames will issue a warning and continue without type checking.</p>"},{"location":"development/#performance-considerations","title":"Performance Considerations","text":"<p>Development Only</p> <p>Runtime type checking adds significant overhead and should only be used during development and testing. Do not enable it in production environments.</p> <p>The overhead includes:</p> <ul> <li>Function call interception and validation</li> <li>Type checking computations at runtime</li> <li>Memory usage for type checking infrastructure</li> </ul>"},{"location":"development/#when-to-use-runtime-type-checking","title":"When to Use Runtime Type Checking","text":"<p>\u2705 Automatically enabled (recommended):</p> <ul> <li>Hatch development environment (<code>hatch shell dev</code>)</li> <li>VS Code debugging sessions</li> <li>VS Code test execution</li> <li>Contributing to mesa-frames development</li> </ul> <p>\u2705 Manual activation (when needed):</p> <ul> <li>Development and debugging in other IDEs</li> <li>Writing new features outside VS Code</li> <li>Running unit tests from command line</li> <li>Troubleshooting type-related issues</li> </ul> <p>\u274c Not recommended for:</p> <ul> <li>Production deployments</li> <li>Performance benchmarking</li> <li>Large-scale simulations</li> <li>Final model runs</li> </ul>"},{"location":"development/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues with runtime type checking:</p> <ol> <li>Check beartype installation:</li> </ol> <pre><code>uv run python -c \"import beartype; print(beartype.__version__)\"\n</code></pre> <ol> <li>Verify environment variable:</li> </ol> <pre><code>echo $MESA_FRAMES_RUNTIME_TYPECHECKING\n</code></pre> <ol> <li>For automatic configurations:</li> <li>Hatch dev: Ensure you're in the dev environment (<code>hatch shell dev</code>)</li> <li>VS Code debugging: Check that the debugger configuration in <code>.vscode/launch.json</code> includes the environment variable</li> <li> <p>VS Code testing: Verify that <code>.env.test</code> file exists and contains <code>MESA_FRAMES_RUNTIME_TYPECHECKING=true</code></p> </li> <li> <p>Check for warnings in your application logs</p> </li> <li> <p>Disable temporarily if needed:</p> </li> </ol> <pre><code>unset MESA_FRAMES_RUNTIME_TYPECHECKING\n</code></pre> <p>Pro Tip</p> <p>Runtime type checking is particularly useful when developing custom AgentSet implementations or working with complex DataFrame operations where type safety is crucial.</p>"},{"location":"user-guide/0_getting-started/","title":"Getting Started \ud83d\ude80","text":""},{"location":"user-guide/0_getting-started/#main-concepts","title":"Main Concepts \ud83e\udde0","text":""},{"location":"user-guide/0_getting-started/#dataframe-based-object-oriented-framework","title":"DataFrame-Based Object-Oriented Framework \ud83d\udcca","text":"<p>Unlike traditional mesa models where each agent is an individual Python object, mesa-frames stores all agents of a particular type in a single DataFrame. We operate only at the AgentSet level.</p> <p>This approach allows for:</p> <ul> <li>Efficient memory usage</li> <li>Improved performance through vectorized operations on agent attributes (This is what makes <code>mesa-frames</code> fast)</li> </ul> <p>Objects can be easily subclassed to respect mesa's object-oriented philosophy.</p>"},{"location":"user-guide/0_getting-started/#vectorized-operations","title":"Vectorized Operations \u26a1","text":"<p>mesa-frames leverages the power of vectorized operations provided by DataFrame libraries:</p> <ul> <li>Operations are performed on entire columns of data at once</li> <li>This approach is significantly faster than iterating over individual agents</li> <li>Complex behaviors can be expressed in fewer lines of code</li> </ul> <p>Default to vectorized operations when expressing agent behaviour; that's where mesa-frames gains most of its speed-ups. If your agents must act sequentially (for example, to resolve conflicts or enforce ordering), fall back to loops or staged vectorized passes\u2014mesa-frames will behave more like base mesa in those situations. We'll unpack these trade-offs in the SugarScape advanced tutorial.</p> <p>It's important to note that in traditional <code>mesa</code> models, the order in which agents are activated can significantly impact the results of the model (see Comer, 2014). <code>mesa-frames</code>, by default, doesn't have this issue as all agents are processed simultaneously. However, this comes with the trade-off of needing to carefully implement conflict resolution mechanisms when sequential processing is required. We'll discuss how to handle these situations later in this guide.</p> <p>Check out these resources to understand vectorization and why it speeds up the code:</p> <ul> <li>What is vectorization?</li> <li>Vectorization Explained, Step by Step</li> </ul> <p>Here's a comparison between mesa-frames and mesa:</p> mesa-framesmesa <pre><code>class MoneyAgents(AgentSet):\n    # initialization...\n    def give_money(self):\n        # Active agents are changed to wealthy agents\n        self.select(self.wealth &gt; 0)\n\n        # Receiving agents are sampled (only native expressions currently supported)\n        other_agents = self.model.sets.sample(\n            n=len(self.active_agents), with_replacement=True\n        )\n\n        # Wealth of wealthy is decreased by 1\n        self[\"active\", \"wealth\"] -= 1\n\n        # Compute the income of the other agents (only native expressions currently supported)\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        self[new_wealth, \"wealth\"] += new_wealth[\"len\"]\n</code></pre> <pre><code>class MoneyAgent(mesa.Agent):\n    # initialization...\n    def give_money(self):\n        # Verify agent has some wealth\n        if self.wealth &gt; 0:\n            other_agent = self.random.choice(self.model.sets)\n            if other_agent is not None:\n                other_agent.wealth += 1\n                self.wealth -= 1\n</code></pre> <p>As you can see, while in mesa you should iterate through all the agents' steps in the model class, here you execute the method once for all agents.</p>"},{"location":"user-guide/0_getting-started/#coming-from-mesa","title":"Coming from mesa \ud83d\udd00","text":"<p>If you're familiar with mesa, this guide will help you understand the key differences in code structure between mesa and mesa-frames.</p>"},{"location":"user-guide/0_getting-started/#agent-representation","title":"Agent Representation \ud83d\udc65","text":"<ul> <li>mesa: Each agent is an individual object instance. Methods are defined for individual agents and called on each agent.</li> <li>mesa-frames: Agents are rows in a DataFrame, grouped into AgentSets. Methods are defined for AgentSets and operate on all agents simultaneously.</li> </ul> mesa-framesmesa <pre><code>class MoneyAgents(AgentSet):\n    def __init__(self, n, model):\n        super().__init__(model)\n        self += pl.DataFrame({\n            \"wealth\": pl.ones(n)\n            })\n    def step(self):\n        givers = self.wealth &gt; 0\n        receivers = self.model.sets.sample(n=len(self.active_agents))\n        self[givers, \"wealth\"] -= 1\n        new_wealth = receivers.groupby(\"unique_id\").count()\n        self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"count\"]\n</code></pre> <pre><code>class MoneyAgent(Agent):\n    def __init__(self, unique_id, model):\n        super().__init__(unique_id, model)\n        self.wealth = 1\n\n    def step(self):\n        if self.wealth &gt; 0:\n            other_agent = self.random.choice(self.model.schedule.agents)\n            other_agent.wealth += 1\n            self.wealth -= 1\n</code></pre>"},{"location":"user-guide/0_getting-started/#model-structure","title":"Model Structure \ud83c\udfd7\ufe0f","text":"<ul> <li>mesa: Models manage individual agents and use a scheduler.</li> <li>mesa-frames: Models manage AgentSets and directly control the simulation flow.</li> </ul> mesa-framesmesa <pre><code>class MoneyModel(Model):\n    def __init__(self, N):\n        super().__init__()\n        self.sets += MoneyAgents(N, self)\n\n    def step(self):\n        self.sets.do(\"step\")\n</code></pre> <pre><code>class MoneyModel(Model):\n    def __init__(self, N):\n        self.num_agents = N\n        self.schedule = RandomActivation(self)\n        for i in range(self.num_agents):\n            a = MoneyAgent(i, self)\n            self.schedule.add(a)\n\n    def step(self):\n        self.schedule.step()\n</code></pre>"},{"location":"user-guide/0_getting-started/#transition-tips","title":"Transition Tips \ud83d\udca1","text":"<ol> <li>Think in Sets \ud83c\udfad: Instead of individual agents, think about operations on groups of agents.</li> <li>Leverage DataFrame Operations \ud83d\udee0\ufe0f: Familiarize yourself with Polars operations for efficient agent manipulation.</li> <li>Vectorize Logic \ud83d\ude85: Convert loops and conditionals to vectorized operations where possible.</li> <li>Use AgentSets \ud83d\udce6: Group similar agents into AgentSets instead of creating many individual agent classes.</li> </ol>"},{"location":"user-guide/0_getting-started/#handling-race-conditions","title":"Handling Race Conditions \ud83c\udfc1","text":"<p>When simultaneous activation is not possible, you need to handle race conditions carefully. There are two main approaches:</p> <ol> <li> <p>Custom UDF with Numba \ud83d\udd27: Use a custom User Defined Function (UDF) with Numba for efficient sequential processing.</p> </li> <li> <p>Polars UDF Guide</p> </li> <li> <p>Looping Mechanism \ud83d\udd01: Implement a looping mechanism on vectorized operations.</p> </li> </ol> <p>For a more detailed implementation of handling race conditions, please refer to the <code>examples/sugarscape-ig</code> in the mesa-frames repository. This example demonstrates how to implement the Sugarscape model with instantaneous growback, which requires careful handling of sequential agent actions.</p>"},{"location":"user-guide/1_classes/","title":"Classes \ud83d\udcda","text":""},{"location":"user-guide/1_classes/#agentset","title":"AgentSet \ud83d\udc65","text":"<p>To create your own AgentSet class, you need to subclass the AgentSet class and make sure to call <code>super().__init__(model)</code>.</p> <p>Typically, the next step would be to populate the class with your agents. To do that, you need to add a DataFrame to the AgentSet. You can do <code>self += agents</code> or <code>self.add(agents)</code>, where <code>agents</code> is a DataFrame or something that could be passed to a DataFrame constructor, like a dictionary or lists of lists. You need to make sure your DataFrame doesn't have a 'unique_id' column because IDs are generated automatically, otherwise you will get an error raised. In the DataFrame, you should also put any attribute of the agent you are using.</p> <p>How can you choose which agents should be in the same AgentSet? The idea is that you should minimize the missing values in the DataFrame (so they should have similar/same attributes) and mostly everybody should do the same actions.</p> <p>Example:</p> <pre><code>class MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self.initial_wealth = pl.ones(n)\n        self += pl.DataFrame({\n            \"wealth\": self.initial_wealth\n        })\n\n    def step(self):\n        self[\"wealth\"] = self[\"wealth\"] + self.random.integers(n)\n</code></pre> <p>You can access the underlying DataFrame where agents are stored with <code>self.df</code>. This allows you to use DataFrame methods like <code>self.df.sample</code> or <code>self.df.group_by(\"wealth\")</code> and more.</p>"},{"location":"user-guide/1_classes/#model","title":"Model \ud83c\udfd7\ufe0f","text":"<p>To add your AgentSet to your Model, use the registry <code>self.sets</code> with <code>+=</code> or <code>add</code>.</p> <p>Note: All agent sets live inside <code>AgentSetRegistry</code> (available as <code>model.sets</code>). Access sets through the registry, and access DataFrames from the set itself. For example: <code>self.sets[\"Preys\"].df</code>.</p> <p>Example:</p> <pre><code>class EcosystemModel(Model):\n    def __init__(self, n_prey, n_predators):\n        super().__init__()\n        self.sets += Preys(n_prey, self)\n        self.sets += Predators(n_predators, self)\n\n    def step(self):\n        self.sets.do(\"move\")\n        self.sets.do(\"hunt\")\n        # Access specific sets via the registry\n        self.sets[\"Preys\"].do(\"reproduce\")\n</code></pre>"},{"location":"user-guide/1_classes/#space-grid","title":"Space: Grid \ud83c\udf10","text":"<p>mesa-frames provides efficient implementations of spatial environments:</p> <ul> <li>Spatial operations (like moving agents) are vectorized for performance</li> </ul> <p>Example:</p> <pre><code>class GridWorld(Model):\n    def __init__(self, width, height):\n        super().__init__()\n        self.space = Grid(self, (width, height))\n        self.sets += AgentSet(100, self)\n        self.space.place_to_empty(self.sets)\n</code></pre> <p>A continuous GeoSpace, NetworkSpace, and a collection to have multiple spaces in the models are in the works! \ud83d\udea7</p>"},{"location":"user-guide/1_classes/#datacollector","title":"DataCollector \ud83d\uddc2\ufe0f","text":"<p><code>DataCollector</code> records model- and agent-level data during simulation. You configure what to collect, how to store it, and when to trigger collection.</p> <p>Example:</p> <pre><code>class ExampleModel(Model):\n    def __init__(self):\n        super().__init__()\n        # Add the set to the registry\n        self.sets.add(MoneyAgents(100, self))\n        # Configure reporters: use the registry to locate sets; get df from the set\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n            },\n            agent_reporters={\"wealth\": \"wealth\"},\n            storage=\"csv\",\n            storage_uri=\"./data\",\n            trigger=lambda m: m.steps % 2 == 0,\n        )\n\n    def step(self):\n        # Step all sets via the registry\n        self.sets.do(\"step\")\n        self.datacollector.conditional_collect()\n        self.datacollector.flush()\n</code></pre>"},{"location":"user-guide/2_introductory_tutorial/","title":"2 introductory tutorial","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[2]: Copied! <pre>!pip install git+https://github.com/projectmesa/mesa-frames mesa\n</pre> !pip install git+https://github.com/projectmesa/mesa-frames mesa <pre>Collecting git+https://github.com/projectmesa/mesa-frames\r\n  Cloning https://github.com/projectmesa/mesa-frames to /tmp/pip-req-build-iljdk9g2\r\n  Running command git clone --filter=blob:none --quiet https://github.com/projectmesa/mesa-frames /tmp/pip-req-build-iljdk9g2\r\n</pre> <pre>  Resolved https://github.com/projectmesa/mesa-frames to commit 33555b4b4cb6b95c69120b04bccf948a6da808eb\r\n</pre> <pre>  Installing build dependencies ... -</pre> <pre>\b \b\\</pre> <pre>\b \b|</pre> <pre>\b \b/</pre> <pre>\b \b-</pre> <pre>\b \bdone\r\n</pre> <pre>  Getting requirements to build wheel ... done\r\n</pre> <pre>  Preparing metadata (pyproject.toml) ... done\r\nRequirement already satisfied: mesa in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (3.3.0)\r\nRequirement already satisfied: boto3&gt;=1.35.91 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: numpy&gt;=2.0.2 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.3.3)\r\nRequirement already satisfied: polars&gt;=1.30.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.34.0)\r\nRequirement already satisfied: psycopg2-binary==2.9.10 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.9.10)\r\nRequirement already satisfied: pyarrow&gt;=20.0.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (21.0.0)\r\nRequirement already satisfied: pandas in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (2.3.3)\r\nRequirement already satisfied: scipy in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (1.16.2)\r\nRequirement already satisfied: tqdm in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (4.67.1)\r\nRequirement already satisfied: botocore&lt;1.41.0,&gt;=1.40.51 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.0.1)\r\nRequirement already satisfied: s3transfer&lt;0.15.0,&gt;=0.14.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (0.14.0)\r\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.5.0)\r\nRequirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.17.0)\r\nRequirement already satisfied: polars-runtime-32==1.34.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from polars&gt;=1.30.0-&gt;mesa_frames==0.1.1.dev0) (1.34.0)\r\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\n</pre> In\u00a0[3]: Copied! <pre>from mesa_frames import Model, AgentSet, DataCollector\n\n\nclass MoneyModel(Model):\n    def __init__(self, N: int, agents_cls):\n        super().__init__()\n        self.n_agents = N\n        self.sets += agents_cls(N, self)\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum()\n            },\n            agent_reporters={\"wealth\": \"wealth\"},\n            storage=\"csv\",\n            storage_uri=\"./data\",\n            trigger=lambda m: m.schedule.steps % 2 == 0,\n        )\n\n    def step(self):\n        # Executes the step method for every agentset in self.sets\n        self.sets.do(\"step\")\n\n    def run_model(self, n):\n        for _ in range(n):\n            self.step()\n            self.datacollector.conditional_collect\n        self.datacollector.flush()\n</pre> from mesa_frames import Model, AgentSet, DataCollector   class MoneyModel(Model):     def __init__(self, N: int, agents_cls):         super().__init__()         self.n_agents = N         self.sets += agents_cls(N, self)         self.datacollector = DataCollector(             model=self,             model_reporters={                 \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum()             },             agent_reporters={\"wealth\": \"wealth\"},             storage=\"csv\",             storage_uri=\"./data\",             trigger=lambda m: m.schedule.steps % 2 == 0,         )      def step(self):         # Executes the step method for every agentset in self.sets         self.sets.do(\"step\")      def run_model(self, n):         for _ in range(n):             self.step()             self.datacollector.conditional_collect         self.datacollector.flush() In\u00a0[4]: Copied! <pre>import polars as pl\n\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.do(\"give_money\")\n\n    def give_money(self):\n        self.select(self.wealth &gt; 0)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n        self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"len\"]\n</pre> import polars as pl   class MoneyAgents(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.do(\"give_money\")      def give_money(self):         self.select(self.wealth &gt; 0)         other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)         self[\"active\", \"wealth\"] -= 1         new_wealth = other_agents.group_by(\"unique_id\").len()         self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"len\"] In\u00a0[5]: Copied! <pre># Create and run the model\nmodel = MoneyModel(1000, MoneyAgents)\nmodel.run_model(100)\n\nwealth_dist = list(model.sets.df.values())[0]\n\n# Print the final wealth distribution\nprint(wealth_dist.select(pl.col(\"wealth\")).describe())\n</pre> # Create and run the model model = MoneyModel(1000, MoneyAgents) model.run_model(100)  wealth_dist = list(model.sets.df.values())[0]  # Print the final wealth distribution print(wealth_dist.select(pl.col(\"wealth\")).describe()) <pre>shape: (9, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 statistic  \u2506 wealth   \u2502\n\u2502 ---        \u2506 ---      \u2502\n\u2502 str        \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 count      \u2506 1000.0   \u2502\n\u2502 null_count \u2506 0.0      \u2502\n\u2502 mean       \u2506 1.0      \u2502\n\u2502 std        \u2506 1.135469 \u2502\n\u2502 min        \u2506 0.0      \u2502\n\u2502 25%        \u2506 0.0      \u2502\n\u2502 50%        \u2506 1.0      \u2502\n\u2502 75%        \u2506 1.0      \u2502\n\u2502 max        \u2506 6.0      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>This output shows the statistical summary of the wealth distribution after 100 steps of the simulation with 1000 agents.</p> In\u00a0[6]: Copied! <pre>class MoneyAgentsConcise(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        ## Adding the agents to the agent set\n        # 1. Changing the df attribute directly (not recommended, if other agents were added before, they will be lost)\n        \"\"\"self.df = pl.DataFrame(\n            {\"wealth\": pl.ones(n, eager=True)}\n        )\"\"\"\n        # 2. Adding the dataframe with add\n        \"\"\"self.add(\n            pl.DataFrame(\n                {\n                    \"wealth\": pl.ones(n, eager=True),\n                }\n            )\n        )\"\"\"\n        # 3. Adding the dataframe with __iadd__\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        # The give_money method is called\n        # self.give_money()\n        self.do(\"give_money\")\n\n    def give_money(self):\n        ## Active agents are changed to wealthy agents\n        # 1. Using the __getitem__ method\n        # self.select(self[\"wealth\"] &gt; 0)\n        # 2. Using the fallback __getattr__ method\n        self.select(self.wealth &gt; 0)\n\n        # Receiving agents are sampled (only native expressions currently supported)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n\n        # Wealth of wealthy is decreased by 1\n        # 1. Using the __setitem__ method with self.active_agents mask\n        # self[self.active_agents, \"wealth\"] -= 1\n        # 2. Using the __setitem__ method with \"active\" mask\n        self[\"active\", \"wealth\"] -= 1\n\n        # Compute the income of the other agents (only native expressions currently supported)\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        # 1. Using the set method\n        \"\"\"self.set(\n            attr_names=\"wealth\",\n            values=pl.col(\"wealth\") + new_wealth[\"len\"],\n            mask=new_wealth,\n        )\"\"\"\n\n        # 2. Using the __setitem__ method\n        self[new_wealth, \"wealth\"] += new_wealth[\"len\"]\n\n\nclass MoneyAgentsNative(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.do(\"give_money\")\n\n    def give_money(self):\n        ## Active agents are changed to wealthy agents\n        self.select(pl.col(\"wealth\") &gt; 0)\n\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n\n        # Wealth of wealthy is decreased by 1\n        self.df = self.df.with_columns(\n            wealth=pl.when(\n                pl.col(\"unique_id\").is_in(self.active_agents[\"unique_id\"].implode())\n            )\n            .then(pl.col(\"wealth\") - 1)\n            .otherwise(pl.col(\"wealth\"))\n        )\n\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        self.df = (\n            self.df.join(new_wealth, on=\"unique_id\", how=\"left\")\n            .fill_null(0)\n            .with_columns(wealth=pl.col(\"wealth\") + pl.col(\"len\"))\n            .drop(\"len\")\n        )\n</pre> class MoneyAgentsConcise(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         ## Adding the agents to the agent set         # 1. Changing the df attribute directly (not recommended, if other agents were added before, they will be lost)         \"\"\"self.df = pl.DataFrame(             {\"wealth\": pl.ones(n, eager=True)}         )\"\"\"         # 2. Adding the dataframe with add         \"\"\"self.add(             pl.DataFrame(                 {                     \"wealth\": pl.ones(n, eager=True),                 }             )         )\"\"\"         # 3. Adding the dataframe with __iadd__         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         # The give_money method is called         # self.give_money()         self.do(\"give_money\")      def give_money(self):         ## Active agents are changed to wealthy agents         # 1. Using the __getitem__ method         # self.select(self[\"wealth\"] &gt; 0)         # 2. Using the fallback __getattr__ method         self.select(self.wealth &gt; 0)          # Receiving agents are sampled (only native expressions currently supported)         other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)          # Wealth of wealthy is decreased by 1         # 1. Using the __setitem__ method with self.active_agents mask         # self[self.active_agents, \"wealth\"] -= 1         # 2. Using the __setitem__ method with \"active\" mask         self[\"active\", \"wealth\"] -= 1          # Compute the income of the other agents (only native expressions currently supported)         new_wealth = other_agents.group_by(\"unique_id\").len()          # Add the income to the other agents         # 1. Using the set method         \"\"\"self.set(             attr_names=\"wealth\",             values=pl.col(\"wealth\") + new_wealth[\"len\"],             mask=new_wealth,         )\"\"\"          # 2. Using the __setitem__ method         self[new_wealth, \"wealth\"] += new_wealth[\"len\"]   class MoneyAgentsNative(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.do(\"give_money\")      def give_money(self):         ## Active agents are changed to wealthy agents         self.select(pl.col(\"wealth\") &gt; 0)          other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)          # Wealth of wealthy is decreased by 1         self.df = self.df.with_columns(             wealth=pl.when(                 pl.col(\"unique_id\").is_in(self.active_agents[\"unique_id\"].implode())             )             .then(pl.col(\"wealth\") - 1)             .otherwise(pl.col(\"wealth\"))         )          new_wealth = other_agents.group_by(\"unique_id\").len()          # Add the income to the other agents         self.df = (             self.df.join(new_wealth, on=\"unique_id\", how=\"left\")             .fill_null(0)             .with_columns(wealth=pl.col(\"wealth\") + pl.col(\"len\"))             .drop(\"len\")         ) <p>Add Mesa implementation of MoneyAgent and MoneyModel classes to test Mesa performance</p> In\u00a0[7]: Copied! <pre>import mesa\n\n\nclass MesaMoneyAgent(mesa.Agent):\n    \"\"\"An agent with fixed initial wealth.\"\"\"\n\n    def __init__(self, model):\n        # Pass the parameters to the parent class.\n        super().__init__(model)\n\n        # Create the agent's variable and set the initial values.\n        self.wealth = 1\n\n    def step(self):\n        # Verify agent has some wealth\n        if self.wealth &gt; 0:\n            other_agent: MesaMoneyAgent = self.model.random.choice(self.model.agents)\n            if other_agent is not None:\n                other_agent.wealth += 1\n                self.wealth -= 1\n\n\nclass MesaMoneyModel(mesa.Model):\n    \"\"\"A model with some number of agents.\"\"\"\n\n    def __init__(self, N: int):\n        super().__init__()\n        self.num_agents = N\n        for _ in range(N):\n            self.agents.add(MesaMoneyAgent(self))\n\n    def step(self):\n        \"\"\"Advance the model by one step.\"\"\"\n        self.agents.shuffle_do(\"step\")\n\n    def run_model(self, n_steps) -&gt; None:\n        for _ in range(n_steps):\n            self.step()\n</pre> import mesa   class MesaMoneyAgent(mesa.Agent):     \"\"\"An agent with fixed initial wealth.\"\"\"      def __init__(self, model):         # Pass the parameters to the parent class.         super().__init__(model)          # Create the agent's variable and set the initial values.         self.wealth = 1      def step(self):         # Verify agent has some wealth         if self.wealth &gt; 0:             other_agent: MesaMoneyAgent = self.model.random.choice(self.model.agents)             if other_agent is not None:                 other_agent.wealth += 1                 self.wealth -= 1   class MesaMoneyModel(mesa.Model):     \"\"\"A model with some number of agents.\"\"\"      def __init__(self, N: int):         super().__init__()         self.num_agents = N         for _ in range(N):             self.agents.add(MesaMoneyAgent(self))      def step(self):         \"\"\"Advance the model by one step.\"\"\"         self.agents.shuffle_do(\"step\")      def run_model(self, n_steps) -&gt; None:         for _ in range(n_steps):             self.step() <pre>/home/runner/work/mesa-frames/mesa-frames/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[8]: Copied! <pre>import time\n\n\ndef run_simulation(model: MesaMoneyModel | MoneyModel, n_steps: int):\n    start_time = time.time()\n    model.run_model(n_steps)\n    end_time = time.time()\n    return end_time - start_time\n\n\n# Compare mesa and mesa-frames implementations\nn_agents_list = [10**2, 10**3 + 1, 2 * 10**3]\nn_steps = 100\nprint(\"Execution times:\")\nfor implementation in [\n    \"mesa\",\n    \"mesa-frames (pl concise)\",\n    \"mesa-frames (pl native)\",\n]:\n    print(f\"---------------\\n{implementation}:\")\n    for n_agents in n_agents_list:\n        if implementation == \"mesa\":\n            ntime = run_simulation(MesaMoneyModel(n_agents), n_steps)\n        elif implementation == \"mesa-frames (pl concise)\":\n            ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsConcise), n_steps)\n        elif implementation == \"mesa-frames (pl native)\":\n            ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsNative), n_steps)\n\n        print(f\"  Number of agents: {n_agents}, Time: {ntime:.2f} seconds\")\n    print(\"---------------\")\n</pre> import time   def run_simulation(model: MesaMoneyModel | MoneyModel, n_steps: int):     start_time = time.time()     model.run_model(n_steps)     end_time = time.time()     return end_time - start_time   # Compare mesa and mesa-frames implementations n_agents_list = [10**2, 10**3 + 1, 2 * 10**3] n_steps = 100 print(\"Execution times:\") for implementation in [     \"mesa\",     \"mesa-frames (pl concise)\",     \"mesa-frames (pl native)\", ]:     print(f\"---------------\\n{implementation}:\")     for n_agents in n_agents_list:         if implementation == \"mesa\":             ntime = run_simulation(MesaMoneyModel(n_agents), n_steps)         elif implementation == \"mesa-frames (pl concise)\":             ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsConcise), n_steps)         elif implementation == \"mesa-frames (pl native)\":             ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsNative), n_steps)          print(f\"  Number of agents: {n_agents}, Time: {ntime:.2f} seconds\")     print(\"---------------\") <pre>Execution times:\n---------------\nmesa:\n  Number of agents: 100, Time: 0.05 seconds\n</pre> <pre>  Number of agents: 1001, Time: 3.60 seconds\n</pre> <pre>  Number of agents: 2000, Time: 14.23 seconds\n---------------\n---------------\nmesa-frames (pl concise):\n</pre> <pre>  Number of agents: 100, Time: 0.32 seconds\n</pre> <pre>  Number of agents: 1001, Time: 0.35 seconds\n</pre> <pre>  Number of agents: 2000, Time: 0.37 seconds\n---------------\n---------------\nmesa-frames (pl native):\n  Number of agents: 100, Time: 0.14 seconds\n</pre> <pre>  Number of agents: 1001, Time: 0.14 seconds\n  Number of agents: 2000, Time: 0.16 seconds\n---------------\n</pre>"},{"location":"user-guide/2_introductory_tutorial/#installation-if-running-in-colab","title":"Installation (if running in Colab)\u00b6","text":"<p>Run the following cell to install <code>mesa-frames</code> if you are using Google Colab.</p>"},{"location":"user-guide/2_introductory_tutorial/#introductory-tutorial-boltzmann-wealth-model-with-mesa-frames","title":"Introductory Tutorial: Boltzmann Wealth Model with mesa-frames \ud83d\udcb0\ud83d\ude80\u00b6","text":"<p>In this tutorial, we'll implement the Boltzmann Wealth Model using mesa-frames. This model simulates the distribution of wealth among agents, where agents randomly give money to each other.</p>"},{"location":"user-guide/2_introductory_tutorial/#setting-up-the-model","title":"Setting Up the Model \ud83c\udfd7\ufe0f\u00b6","text":"<p>First, let's import the necessary modules and set up our model class:</p>"},{"location":"user-guide/2_introductory_tutorial/#implementing-the-agentset","title":"Implementing the AgentSet \ud83d\udc65\u00b6","text":"<p>Now, let's implement our <code>MoneyAgents</code> using polars backends.</p>"},{"location":"user-guide/2_introductory_tutorial/#running-the-model","title":"Running the Model \u25b6\ufe0f\u00b6","text":"<p>Now that we have our model and agent set defined, let's run a simulation:</p>"},{"location":"user-guide/2_introductory_tutorial/#performance-comparison","title":"Performance Comparison \ud83c\udfce\ufe0f\ud83d\udca8\u00b6","text":"<p>One of the key advantages of mesa-frames is its performance with large numbers of agents. Let's compare the performance of mesa and polars:</p>"},{"location":"user-guide/2_introductory_tutorial/#conclusion","title":"Conclusion \ud83c\udf89\u00b6","text":"<ul> <li>All mesa-frames implementations significantly outperform the original mesa implementation. \ud83c\udfc6</li> <li>The native implementation for Polars shows better performance than their concise counterparts. \ud83d\udcaa</li> <li>The Polars native implementation shows the most impressive speed-up, ranging from 10.86x to 17.60x faster than mesa! \ud83d\ude80\ud83d\ude80\ud83d\ude80</li> <li>The performance advantage of mesa-frames becomes more pronounced as the number of agents increases. \ud83d\udcc8</li> </ul>"},{"location":"user-guide/2_introductory_tutorial/","title":"2 introductory tutorial","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[2]: Copied! <pre>!pip install git+https://github.com/projectmesa/mesa-frames mesa\n</pre> !pip install git+https://github.com/projectmesa/mesa-frames mesa <pre>Collecting git+https://github.com/projectmesa/mesa-frames\r\n  Cloning https://github.com/projectmesa/mesa-frames to /tmp/pip-req-build-91nig4tl\r\n  Running command git clone --filter=blob:none --quiet https://github.com/projectmesa/mesa-frames /tmp/pip-req-build-91nig4tl\r\n</pre> <pre>  Resolved https://github.com/projectmesa/mesa-frames to commit 33555b4b4cb6b95c69120b04bccf948a6da808eb\r\n</pre> <pre>  Installing build dependencies ... -</pre> <pre>\b \b\\</pre> <pre>\b \bdone\r\n</pre> <pre>  Getting requirements to build wheel ... done\r\n</pre> <pre>  Preparing metadata (pyproject.toml) ... done\r\nRequirement already satisfied: mesa in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (3.3.0)\r\nRequirement already satisfied: boto3&gt;=1.35.91 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: numpy&gt;=2.0.2 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.3.3)\r\nRequirement already satisfied: polars&gt;=1.30.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.34.0)\r\nRequirement already satisfied: psycopg2-binary==2.9.10 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.9.10)\r\nRequirement already satisfied: pyarrow&gt;=20.0.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (21.0.0)\r\nRequirement already satisfied: pandas in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (2.3.3)\r\nRequirement already satisfied: scipy in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (1.16.2)\r\nRequirement already satisfied: tqdm in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (4.67.1)\r\nRequirement already satisfied: botocore&lt;1.41.0,&gt;=1.40.51 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.0.1)\r\nRequirement already satisfied: s3transfer&lt;0.15.0,&gt;=0.14.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (0.14.0)\r\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.5.0)\r\nRequirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.17.0)\r\nRequirement already satisfied: polars-runtime-32==1.34.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from polars&gt;=1.30.0-&gt;mesa_frames==0.1.1.dev0) (1.34.0)\r\n</pre> <pre>Requirement already satisfied: pytz&gt;=2020.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\n</pre> In\u00a0[3]: Copied! <pre>from mesa_frames import Model, AgentSet, DataCollector\n\n\nclass MoneyModel(Model):\n    def __init__(self, N: int, agents_cls):\n        super().__init__()\n        self.n_agents = N\n        self.sets += agents_cls(N, self)\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum()\n            },\n            agent_reporters={\"wealth\": \"wealth\"},\n            storage=\"csv\",\n            storage_uri=\"./data\",\n            trigger=lambda m: m.schedule.steps % 2 == 0,\n        )\n\n    def step(self):\n        # Executes the step method for every agentset in self.sets\n        self.sets.do(\"step\")\n\n    def run_model(self, n):\n        for _ in range(n):\n            self.step()\n            self.datacollector.conditional_collect\n        self.datacollector.flush()\n</pre> from mesa_frames import Model, AgentSet, DataCollector   class MoneyModel(Model):     def __init__(self, N: int, agents_cls):         super().__init__()         self.n_agents = N         self.sets += agents_cls(N, self)         self.datacollector = DataCollector(             model=self,             model_reporters={                 \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum()             },             agent_reporters={\"wealth\": \"wealth\"},             storage=\"csv\",             storage_uri=\"./data\",             trigger=lambda m: m.schedule.steps % 2 == 0,         )      def step(self):         # Executes the step method for every agentset in self.sets         self.sets.do(\"step\")      def run_model(self, n):         for _ in range(n):             self.step()             self.datacollector.conditional_collect         self.datacollector.flush() In\u00a0[4]: Copied! <pre>import polars as pl\n\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.do(\"give_money\")\n\n    def give_money(self):\n        self.select(self.wealth &gt; 0)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n        self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"len\"]\n</pre> import polars as pl   class MoneyAgents(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.do(\"give_money\")      def give_money(self):         self.select(self.wealth &gt; 0)         other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)         self[\"active\", \"wealth\"] -= 1         new_wealth = other_agents.group_by(\"unique_id\").len()         self[new_wealth[\"unique_id\"], \"wealth\"] += new_wealth[\"len\"] In\u00a0[5]: Copied! <pre># Create and run the model\nmodel = MoneyModel(1000, MoneyAgents)\nmodel.run_model(100)\n\nwealth_dist = list(model.sets.df.values())[0]\n\n# Print the final wealth distribution\nprint(wealth_dist.select(pl.col(\"wealth\")).describe())\n</pre> # Create and run the model model = MoneyModel(1000, MoneyAgents) model.run_model(100)  wealth_dist = list(model.sets.df.values())[0]  # Print the final wealth distribution print(wealth_dist.select(pl.col(\"wealth\")).describe()) <pre>shape: (9, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 statistic  \u2506 wealth   \u2502\n\u2502 ---        \u2506 ---      \u2502\n\u2502 str        \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 count      \u2506 1000.0   \u2502\n\u2502 null_count \u2506 0.0      \u2502\n\u2502 mean       \u2506 1.0      \u2502\n\u2502 std        \u2506 1.169345 \u2502\n\u2502 min        \u2506 0.0      \u2502\n\u2502 25%        \u2506 0.0      \u2502\n\u2502 50%        \u2506 1.0      \u2502\n\u2502 75%        \u2506 1.0      \u2502\n\u2502 max        \u2506 7.0      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>This output shows the statistical summary of the wealth distribution after 100 steps of the simulation with 1000 agents.</p> In\u00a0[6]: Copied! <pre>class MoneyAgentsConcise(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        ## Adding the agents to the agent set\n        # 1. Changing the df attribute directly (not recommended, if other agents were added before, they will be lost)\n        \"\"\"self.df = pl.DataFrame(\n            {\"wealth\": pl.ones(n, eager=True)}\n        )\"\"\"\n        # 2. Adding the dataframe with add\n        \"\"\"self.add(\n            pl.DataFrame(\n                {\n                    \"wealth\": pl.ones(n, eager=True),\n                }\n            )\n        )\"\"\"\n        # 3. Adding the dataframe with __iadd__\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        # The give_money method is called\n        # self.give_money()\n        self.do(\"give_money\")\n\n    def give_money(self):\n        ## Active agents are changed to wealthy agents\n        # 1. Using the __getitem__ method\n        # self.select(self[\"wealth\"] &gt; 0)\n        # 2. Using the fallback __getattr__ method\n        self.select(self.wealth &gt; 0)\n\n        # Receiving agents are sampled (only native expressions currently supported)\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n\n        # Wealth of wealthy is decreased by 1\n        # 1. Using the __setitem__ method with self.active_agents mask\n        # self[self.active_agents, \"wealth\"] -= 1\n        # 2. Using the __setitem__ method with \"active\" mask\n        self[\"active\", \"wealth\"] -= 1\n\n        # Compute the income of the other agents (only native expressions currently supported)\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        # 1. Using the set method\n        \"\"\"self.set(\n            attr_names=\"wealth\",\n            values=pl.col(\"wealth\") + new_wealth[\"len\"],\n            mask=new_wealth,\n        )\"\"\"\n\n        # 2. Using the __setitem__ method\n        self[new_wealth, \"wealth\"] += new_wealth[\"len\"]\n\n\nclass MoneyAgentsNative(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.do(\"give_money\")\n\n    def give_money(self):\n        ## Active agents are changed to wealthy agents\n        self.select(pl.col(\"wealth\") &gt; 0)\n\n        other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)\n\n        # Wealth of wealthy is decreased by 1\n        self.df = self.df.with_columns(\n            wealth=pl.when(\n                pl.col(\"unique_id\").is_in(self.active_agents[\"unique_id\"].implode())\n            )\n            .then(pl.col(\"wealth\") - 1)\n            .otherwise(pl.col(\"wealth\"))\n        )\n\n        new_wealth = other_agents.group_by(\"unique_id\").len()\n\n        # Add the income to the other agents\n        self.df = (\n            self.df.join(new_wealth, on=\"unique_id\", how=\"left\")\n            .fill_null(0)\n            .with_columns(wealth=pl.col(\"wealth\") + pl.col(\"len\"))\n            .drop(\"len\")\n        )\n</pre> class MoneyAgentsConcise(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         ## Adding the agents to the agent set         # 1. Changing the df attribute directly (not recommended, if other agents were added before, they will be lost)         \"\"\"self.df = pl.DataFrame(             {\"wealth\": pl.ones(n, eager=True)}         )\"\"\"         # 2. Adding the dataframe with add         \"\"\"self.add(             pl.DataFrame(                 {                     \"wealth\": pl.ones(n, eager=True),                 }             )         )\"\"\"         # 3. Adding the dataframe with __iadd__         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         # The give_money method is called         # self.give_money()         self.do(\"give_money\")      def give_money(self):         ## Active agents are changed to wealthy agents         # 1. Using the __getitem__ method         # self.select(self[\"wealth\"] &gt; 0)         # 2. Using the fallback __getattr__ method         self.select(self.wealth &gt; 0)          # Receiving agents are sampled (only native expressions currently supported)         other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)          # Wealth of wealthy is decreased by 1         # 1. Using the __setitem__ method with self.active_agents mask         # self[self.active_agents, \"wealth\"] -= 1         # 2. Using the __setitem__ method with \"active\" mask         self[\"active\", \"wealth\"] -= 1          # Compute the income of the other agents (only native expressions currently supported)         new_wealth = other_agents.group_by(\"unique_id\").len()          # Add the income to the other agents         # 1. Using the set method         \"\"\"self.set(             attr_names=\"wealth\",             values=pl.col(\"wealth\") + new_wealth[\"len\"],             mask=new_wealth,         )\"\"\"          # 2. Using the __setitem__ method         self[new_wealth, \"wealth\"] += new_wealth[\"len\"]   class MoneyAgentsNative(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.do(\"give_money\")      def give_money(self):         ## Active agents are changed to wealthy agents         self.select(pl.col(\"wealth\") &gt; 0)          other_agents = self.df.sample(n=len(self.active_agents), with_replacement=True)          # Wealth of wealthy is decreased by 1         self.df = self.df.with_columns(             wealth=pl.when(                 pl.col(\"unique_id\").is_in(self.active_agents[\"unique_id\"].implode())             )             .then(pl.col(\"wealth\") - 1)             .otherwise(pl.col(\"wealth\"))         )          new_wealth = other_agents.group_by(\"unique_id\").len()          # Add the income to the other agents         self.df = (             self.df.join(new_wealth, on=\"unique_id\", how=\"left\")             .fill_null(0)             .with_columns(wealth=pl.col(\"wealth\") + pl.col(\"len\"))             .drop(\"len\")         ) <p>Add Mesa implementation of MoneyAgent and MoneyModel classes to test Mesa performance</p> In\u00a0[7]: Copied! <pre>import mesa\n\n\nclass MesaMoneyAgent(mesa.Agent):\n    \"\"\"An agent with fixed initial wealth.\"\"\"\n\n    def __init__(self, model):\n        # Pass the parameters to the parent class.\n        super().__init__(model)\n\n        # Create the agent's variable and set the initial values.\n        self.wealth = 1\n\n    def step(self):\n        # Verify agent has some wealth\n        if self.wealth &gt; 0:\n            other_agent: MesaMoneyAgent = self.model.random.choice(self.model.agents)\n            if other_agent is not None:\n                other_agent.wealth += 1\n                self.wealth -= 1\n\n\nclass MesaMoneyModel(mesa.Model):\n    \"\"\"A model with some number of agents.\"\"\"\n\n    def __init__(self, N: int):\n        super().__init__()\n        self.num_agents = N\n        for _ in range(N):\n            self.agents.add(MesaMoneyAgent(self))\n\n    def step(self):\n        \"\"\"Advance the model by one step.\"\"\"\n        self.agents.shuffle_do(\"step\")\n\n    def run_model(self, n_steps) -&gt; None:\n        for _ in range(n_steps):\n            self.step()\n</pre> import mesa   class MesaMoneyAgent(mesa.Agent):     \"\"\"An agent with fixed initial wealth.\"\"\"      def __init__(self, model):         # Pass the parameters to the parent class.         super().__init__(model)          # Create the agent's variable and set the initial values.         self.wealth = 1      def step(self):         # Verify agent has some wealth         if self.wealth &gt; 0:             other_agent: MesaMoneyAgent = self.model.random.choice(self.model.agents)             if other_agent is not None:                 other_agent.wealth += 1                 self.wealth -= 1   class MesaMoneyModel(mesa.Model):     \"\"\"A model with some number of agents.\"\"\"      def __init__(self, N: int):         super().__init__()         self.num_agents = N         for _ in range(N):             self.agents.add(MesaMoneyAgent(self))      def step(self):         \"\"\"Advance the model by one step.\"\"\"         self.agents.shuffle_do(\"step\")      def run_model(self, n_steps) -&gt; None:         for _ in range(n_steps):             self.step() <pre>/home/runner/work/mesa-frames/mesa-frames/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[8]: Copied! <pre>import time\n\n\ndef run_simulation(model: MesaMoneyModel | MoneyModel, n_steps: int):\n    start_time = time.time()\n    model.run_model(n_steps)\n    end_time = time.time()\n    return end_time - start_time\n\n\n# Compare mesa and mesa-frames implementations\nn_agents_list = [10**2, 10**3 + 1, 2 * 10**3]\nn_steps = 100\nprint(\"Execution times:\")\nfor implementation in [\n    \"mesa\",\n    \"mesa-frames (pl concise)\",\n    \"mesa-frames (pl native)\",\n]:\n    print(f\"---------------\\n{implementation}:\")\n    for n_agents in n_agents_list:\n        if implementation == \"mesa\":\n            ntime = run_simulation(MesaMoneyModel(n_agents), n_steps)\n        elif implementation == \"mesa-frames (pl concise)\":\n            ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsConcise), n_steps)\n        elif implementation == \"mesa-frames (pl native)\":\n            ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsNative), n_steps)\n\n        print(f\"  Number of agents: {n_agents}, Time: {ntime:.2f} seconds\")\n    print(\"---------------\")\n</pre> import time   def run_simulation(model: MesaMoneyModel | MoneyModel, n_steps: int):     start_time = time.time()     model.run_model(n_steps)     end_time = time.time()     return end_time - start_time   # Compare mesa and mesa-frames implementations n_agents_list = [10**2, 10**3 + 1, 2 * 10**3] n_steps = 100 print(\"Execution times:\") for implementation in [     \"mesa\",     \"mesa-frames (pl concise)\",     \"mesa-frames (pl native)\", ]:     print(f\"---------------\\n{implementation}:\")     for n_agents in n_agents_list:         if implementation == \"mesa\":             ntime = run_simulation(MesaMoneyModel(n_agents), n_steps)         elif implementation == \"mesa-frames (pl concise)\":             ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsConcise), n_steps)         elif implementation == \"mesa-frames (pl native)\":             ntime = run_simulation(MoneyModel(n_agents, MoneyAgentsNative), n_steps)          print(f\"  Number of agents: {n_agents}, Time: {ntime:.2f} seconds\")     print(\"---------------\") <pre>Execution times:\n---------------\nmesa:\n  Number of agents: 100, Time: 0.05 seconds\n</pre> <pre>  Number of agents: 1001, Time: 3.61 seconds\n</pre> <pre>  Number of agents: 2000, Time: 14.08 seconds\n---------------\n---------------\nmesa-frames (pl concise):\n</pre> <pre>  Number of agents: 100, Time: 0.32 seconds\n</pre> <pre>  Number of agents: 1001, Time: 0.35 seconds\n</pre> <pre>  Number of agents: 2000, Time: 0.37 seconds\n---------------\n---------------\nmesa-frames (pl native):\n  Number of agents: 100, Time: 0.14 seconds\n</pre> <pre>  Number of agents: 1001, Time: 0.14 seconds\n  Number of agents: 2000, Time: 0.16 seconds\n---------------\n</pre>"},{"location":"user-guide/2_introductory_tutorial/#installation-if-running-in-colab","title":"Installation (if running in Colab)\u00b6","text":"<p>Run the following cell to install <code>mesa-frames</code> if you are using Google Colab.</p>"},{"location":"user-guide/2_introductory_tutorial/#introductory-tutorial-boltzmann-wealth-model-with-mesa-frames","title":"Introductory Tutorial: Boltzmann Wealth Model with mesa-frames \ud83d\udcb0\ud83d\ude80\u00b6","text":"<p>In this tutorial, we'll implement the Boltzmann Wealth Model using mesa-frames. This model simulates the distribution of wealth among agents, where agents randomly give money to each other.</p>"},{"location":"user-guide/2_introductory_tutorial/#setting-up-the-model","title":"Setting Up the Model \ud83c\udfd7\ufe0f\u00b6","text":"<p>First, let's import the necessary modules and set up our model class:</p>"},{"location":"user-guide/2_introductory_tutorial/#implementing-the-agentset","title":"Implementing the AgentSet \ud83d\udc65\u00b6","text":"<p>Now, let's implement our <code>MoneyAgents</code> using polars backends.</p>"},{"location":"user-guide/2_introductory_tutorial/#running-the-model","title":"Running the Model \u25b6\ufe0f\u00b6","text":"<p>Now that we have our model and agent set defined, let's run a simulation:</p>"},{"location":"user-guide/2_introductory_tutorial/#performance-comparison","title":"Performance Comparison \ud83c\udfce\ufe0f\ud83d\udca8\u00b6","text":"<p>One of the key advantages of mesa-frames is its performance with large numbers of agents. Let's compare the performance of mesa and polars:</p>"},{"location":"user-guide/2_introductory_tutorial/#conclusion","title":"Conclusion \ud83c\udf89\u00b6","text":"<ul> <li>All mesa-frames implementations significantly outperform the original mesa implementation. \ud83c\udfc6</li> <li>The native implementation for Polars shows better performance than their concise counterparts. \ud83d\udcaa</li> <li>The Polars native implementation shows the most impressive speed-up, ranging from 10.86x to 17.60x faster than mesa! \ud83d\ude80\ud83d\ude80\ud83d\ude80</li> <li>The performance advantage of mesa-frames becomes more pronounced as the number of agents increases. \ud83d\udcc8</li> </ul>"},{"location":"user-guide/3_advanced_tutorial/","title":"Advanced Tutorial \u2014 Rebuilding Sugarscape with mesa-frames","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations <p>First, let's install and import the necessary packages.</p> <p>If you're running this tutorial on Google Colab or another fresh environment, uncomment the cell below to install the required dependencies.</p> In\u00a0[2]: Copied! <pre>!pip install git+https://github.com/projectmesa/mesa-frames polars numba numpy\n</pre> !pip install git+https://github.com/projectmesa/mesa-frames polars numba numpy <pre>Collecting git+https://github.com/projectmesa/mesa-frames\r\n  Cloning https://github.com/projectmesa/mesa-frames to /tmp/pip-req-build-wyzwi47v\r\n  Running command git clone --filter=blob:none --quiet https://github.com/projectmesa/mesa-frames /tmp/pip-req-build-wyzwi47v\r\n</pre> <pre>  Resolved https://github.com/projectmesa/mesa-frames to commit 33555b4b4cb6b95c69120b04bccf948a6da808eb\r\n</pre> <pre>  Installing build dependencies ... -</pre> <pre>\b \b\\</pre> <pre>\b \bdone\r\n</pre> <pre>  Getting requirements to build wheel ... done\r\n</pre> <pre>  Preparing metadata (pyproject.toml) ... done\r\n</pre> <pre>Requirement already satisfied: polars in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (1.34.0)\r\n</pre> <pre>Collecting numba\r\n</pre> <pre>  Downloading numba-0.62.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\r\nRequirement already satisfied: numpy in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (2.3.3)\r\nRequirement already satisfied: boto3&gt;=1.35.91 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: psycopg2-binary==2.9.10 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.9.10)\r\nRequirement already satisfied: pyarrow&gt;=20.0.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (21.0.0)\r\nRequirement already satisfied: polars-runtime-32==1.34.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from polars) (1.34.0)\r\n</pre> <pre>Collecting llvmlite&lt;0.46,&gt;=0.45.0dev0 (from numba)\r\n</pre> <pre>  Downloading llvmlite-0.45.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\r\nRequirement already satisfied: botocore&lt;1.41.0,&gt;=1.40.51 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.0.1)\r\nRequirement already satisfied: s3transfer&lt;0.15.0,&gt;=0.14.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (0.14.0)\r\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.5.0)\r\nRequirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.17.0)\r\n</pre> <pre>Downloading numba-0.62.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\r\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0.0/3.8 MB ? eta -:--:--</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.8/3.8 MB 48.0 MB/s  0:00:00\r\n</pre> <pre>Downloading llvmlite-0.45.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\r\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0.0/56.3 MB ? eta -:--:--</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40.9/56.3 MB 219.8 MB/s eta 0:00:01</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40.9/56.3 MB 219.8 MB/s eta 0:00:01</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2578 56.1/56.3 MB 95.4 MB/s eta 0:00:01</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.3/56.3 MB 85.2 MB/s  0:00:00\r\n</pre> <pre>Installing collected packages: llvmlite, numba\r\n</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0/2 [llvmlite]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0/2 [llvmlite]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0/2 [llvmlite]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0/2 [llvmlite]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 [numba]</pre> <pre>\r   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2/2 [numba]\r\n\r</pre> <pre>Successfully installed llvmlite-0.45.1 numba-0.62.1\r\n</pre> In\u00a0[3]: Copied! <pre>from time import perf_counter\n\nimport numpy as np\nimport polars as pl\nfrom numba import njit\n\nfrom mesa_frames import AgentSet, DataCollector, Grid, Model\n</pre> from time import perf_counter  import numpy as np import polars as pl from numba import njit  from mesa_frames import AgentSet, DataCollector, Grid, Model In\u00a0[4]: Copied! <pre># Model-level reporters\n\n\ndef gini(model: Model) -&gt; float:\n    \"\"\"Compute the Gini coefficient of agent sugar holdings.\n\n    The function reads the primary agent set from ``model.sets[0]`` and\n    computes the population Gini coefficient on the ``sugar`` column. The\n    implementation is robust to empty sets and zero-total sugar.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and to expose a Polars DataFrame\n        under ``.df`` with a ``sugar`` column.\n\n    Returns\n    -------\n    float\n        Gini coefficient in the range [0, 1] if defined, ``0.0`` when the\n        total sugar is zero, and ``nan`` when the agent set is empty or too\n        small to measure.\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    sugar = primary_set.df[\"sugar\"].to_numpy().astype(np.float64)\n\n    if sugar.size == 0:\n        return float(\"nan\")\n    sorted_vals = np.sort(sugar.astype(np.float64))\n    n = sorted_vals.size\n    if n == 0:\n        return float(\"nan\")\n    cumulative = np.cumsum(sorted_vals)\n    total = cumulative[-1]\n    if total == 0:\n        return 0.0\n    index = np.arange(1, n + 1, dtype=np.float64)\n    return float((2.0 * np.dot(index, sorted_vals) / (n * total)) - (n + 1) / n)\n\n\ndef corr_sugar_metabolism(model: Model) -&gt; float:\n    \"\"\"Pearson correlation between agent sugar and metabolism.\n\n    This reporter extracts the ``sugar`` and ``metabolism`` columns from the\n    primary agent set and returns their Pearson correlation coefficient. When\n    the agent set is empty or contains insufficient variation the function\n    returns ``nan``.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and provide a Polars DataFrame\n        with ``sugar`` and ``metabolism`` columns.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient between sugar and metabolism, or\n        ``nan`` when the correlation is undefined (empty set or constant\n        values).\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    agent_df = primary_set.df\n    sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)\n    metabolism = agent_df[\"metabolism\"].to_numpy().astype(np.float64)\n    return _safe_corr(sugar, metabolism)\n\n\ndef corr_sugar_vision(model: Model) -&gt; float:\n    \"\"\"Pearson correlation between agent sugar and vision.\n\n    Extracts the ``sugar`` and ``vision`` columns from the primary agent set\n    and returns their Pearson correlation coefficient. If the reporter cannot\n    compute a meaningful correlation (for example, when the agent set is\n    empty or values are constant) it returns ``nan``.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and provide a Polars DataFrame\n        with ``sugar`` and ``vision`` columns.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient between sugar and vision, or ``nan``\n        when the correlation is undefined.\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    agent_df = primary_set.df\n    sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)\n    vision = agent_df[\"vision\"].to_numpy().astype(np.float64)\n    return _safe_corr(sugar, vision)\n\n\ndef _safe_corr(x: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Safely compute Pearson correlation between two 1-D arrays.\n\n    This helper guards against degenerate inputs (too few observations or\n    constant arrays) which would make the Pearson correlation undefined or\n    numerically unstable. When a valid correlation can be computed the\n    function returns a Python float.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        One-dimensional numeric array containing the first variable to\n        correlate.\n    y : np.ndarray\n        One-dimensional numeric array containing the second variable to\n        correlate.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient as a Python float, or ``nan`` if the\n        correlation is undefined (fewer than 2 observations or constant\n        inputs).\n    \"\"\"\n    if x.size &lt; 2 or y.size &lt; 2:\n        return float(\"nan\")\n    if np.allclose(x, x[0]) or np.allclose(y, y[0]):\n        return float(\"nan\")\n    return float(np.corrcoef(x, y)[0, 1])\n\n\nclass Sugarscape(Model):\n    \"\"\"Minimal Sugarscape model used throughout the tutorial.\n\n    This class wires together a grid that stores ``sugar`` per cell, an\n    agent set implementation (passed in as ``agent_type``), and a\n    data collector that records model- and agent-level statistics.\n\n    The model's responsibilities are to:\n    - create the sugar landscape (cells with current and maximum sugar)\n    - create and place agents on the grid\n    - advance the sugar regrowth rule each step\n    - run the model for a fixed number of steps and collect data\n\n    Parameters\n    ----------\n    agent_type : type[AntsBase]\n        The :class:`AgentSet` subclass implementing the movement rules\n        (sequential, numba-accelerated, or parallel).\n    n_agents : int\n        Number of agents to create and place on the grid.\n    width : int\n        Grid width (number of columns).\n    height : int\n        Grid height (number of rows).\n    max_sugar : int, optional\n        Upper bound for the randomly initialised sugar values on the grid,\n        by default 4.\n    seed : int | None, optional\n        RNG seed to make runs reproducible across variants, by default None.\n\n    Notes\n    -----\n    The grid uses a von Neumann neighbourhood and capacity 1 (at most one\n    agent per cell). Both the sugar landscape and initial agent traits are\n    drawn from ``self.random`` so different movement variants can be\n    instantiated with identical initial conditions by passing the same seed.\n    \"\"\"\n\n    def __init__(\n        self,\n        agent_type: type[AntsBase],\n        n_agents: int,\n        *,\n        width: int,\n        height: int,\n        max_sugar: int = 4,\n        seed: int | None = None,\n    ) -&gt; None:\n        if n_agents &gt; width * height:\n            raise ValueError(\n                \"Cannot place more agents than grid cells when capacity is 1.\"\n            )\n        super().__init__(seed)\n\n        # 1. Let's create the sugar grid and set up the space\n\n        sugar_grid_df = self._generate_sugar_grid(width, height, max_sugar)\n        self.space = Grid(\n            self, [width, height], neighborhood_type=\"von_neumann\", capacity=1\n        )\n        self.space.set_cells(sugar_grid_df)\n        self._max_sugar = sugar_grid_df.select([\"dim_0\", \"dim_1\", \"max_sugar\"])\n\n        # 2. Now we create the agents and place them on the grid\n\n        agent_frame = self._generate_agent_frame(n_agents)\n        main_set = agent_type(self, agent_frame)\n        self.sets += main_set\n        self.space.place_to_empty(self.sets)\n\n        # 3. Finally we set up the data collector\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"mean_sugar\": lambda m: 0.0\n                if len(m.sets[0]) == 0\n                else float(m.sets[0].df[\"sugar\"].mean()),\n                \"total_sugar\": lambda m: float(m.sets[0].df[\"sugar\"].sum())\n                if len(m.sets[0])\n                else 0.0,\n                \"agents_alive\": lambda m: float(len(m.sets[0])) if len(m.sets) else 0.0,\n                \"gini\": gini,\n                \"corr_sugar_metabolism\": corr_sugar_metabolism,\n                \"corr_sugar_vision\": corr_sugar_vision,\n            },\n            agent_reporters={\"traits\": [\"sugar\", \"metabolism\", \"vision\"]},\n        )\n        self.datacollector.collect()\n\n    def _generate_sugar_grid(\n        self, width: int, height: int, max_sugar: int\n    ) -&gt; pl.DataFrame:\n        \"\"\"Generate a random sugar grid.\n\n        Parameters\n        ----------\n        width : int\n            Grid width (number of columns).\n        height : int\n            Grid height (number of rows).\n        max_sugar : int\n            Maximum sugar value (inclusive) for each cell.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``dim_0``, ``dim_1``, ``sugar`` (current\n            amount) and ``max_sugar`` (regrowth target).\n        \"\"\"\n        sugar_vals = self.random.integers(\n            0, max_sugar + 1, size=(width, height), dtype=np.int64\n        )\n        dim_0 = pl.Series(\"dim_0\", pl.arange(width, eager=True)).to_frame()\n        dim_1 = pl.Series(\"dim_1\", pl.arange(height, eager=True)).to_frame()\n        return dim_0.join(dim_1, how=\"cross\").with_columns(\n            sugar=sugar_vals.flatten(), max_sugar=sugar_vals.flatten()\n        )\n\n    def _generate_agent_frame(self, n_agents: int) -&gt; pl.DataFrame:\n        \"\"\"Create the initial agent frame populated with agent traits.\n\n        Parameters\n        ----------\n        n_agents : int\n            Number of agents to create.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``sugar``, ``metabolism`` and ``vision``\n            (integer values) for each agent.\n        \"\"\"\n        rng = self.random\n        return pl.DataFrame(\n            {\n                \"sugar\": rng.integers(6, 25, size=n_agents, dtype=np.int64),\n                \"metabolism\": rng.integers(2, 5, size=n_agents, dtype=np.int64),\n                \"vision\": rng.integers(1, 6, size=n_agents, dtype=np.int64),\n            }\n        )\n\n    def step(self) -&gt; None:\n        \"\"\"Advance the model by one step.\n\n        Notes\n        -----\n        The per-step ordering is important and this tutorial implements the\n        classic Sugarscape \"instant growback\": agents move and eat first,\n        and then empty cells are refilled immediately (move -&gt; eat -&gt; regrow\n        -&gt; collect).\n        \"\"\"\n        if len(self.sets[0]) == 0:\n            self.running = False\n            return\n        self.sets[0].step()\n        self._advance_sugar_field()\n        self.datacollector.collect()\n        if len(self.sets[0]) == 0:\n            self.running = False\n\n    def run(self, steps: int) -&gt; None:\n        \"\"\"Run the model for a fixed number of steps.\n\n        Parameters\n        ----------\n        steps : int\n            Maximum number of steps to run. The model may terminate earlier if\n            ``self.running`` is set to ``False`` (for example, when all agents\n            have died).\n        \"\"\"\n        for _ in range(steps):\n            if not self.running:\n                break\n            self.step()\n\n    def _advance_sugar_field(self) -&gt; None:\n        \"\"\"Apply the instant-growback sugar regrowth rule.\n\n        Empty cells (no agent present) are refilled to their ``max_sugar``\n        value. Cells that are occupied are set to zero because agents harvest\n        the sugar when they eat. The method uses vectorised DataFrame joins\n        and writes to keep the operation efficient.\n        \"\"\"\n        empty_cells = self.space.empty_cells\n        if not empty_cells.is_empty():\n            # Look up the maximum sugar for each empty cell and restore it.\n            refresh = empty_cells.join(\n                self._max_sugar, on=[\"dim_0\", \"dim_1\"], how=\"left\"\n            )\n            self.space.set_cells(empty_cells, {\"sugar\": refresh[\"max_sugar\"]})\n        full_cells = self.space.full_cells\n        if not full_cells.is_empty():\n            # Occupied cells have just been harvested; set their sugar to 0.\n            zeros = pl.Series(np.zeros(len(full_cells), dtype=np.int64))\n            self.space.set_cells(full_cells, {\"sugar\": zeros})\n</pre>  # Model-level reporters   def gini(model: Model) -&gt; float:     \"\"\"Compute the Gini coefficient of agent sugar holdings.      The function reads the primary agent set from ``model.sets[0]`` and     computes the population Gini coefficient on the ``sugar`` column. The     implementation is robust to empty sets and zero-total sugar.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and to expose a Polars DataFrame         under ``.df`` with a ``sugar`` column.      Returns     -------     float         Gini coefficient in the range [0, 1] if defined, ``0.0`` when the         total sugar is zero, and ``nan`` when the agent set is empty or too         small to measure.     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      sugar = primary_set.df[\"sugar\"].to_numpy().astype(np.float64)      if sugar.size == 0:         return float(\"nan\")     sorted_vals = np.sort(sugar.astype(np.float64))     n = sorted_vals.size     if n == 0:         return float(\"nan\")     cumulative = np.cumsum(sorted_vals)     total = cumulative[-1]     if total == 0:         return 0.0     index = np.arange(1, n + 1, dtype=np.float64)     return float((2.0 * np.dot(index, sorted_vals) / (n * total)) - (n + 1) / n)   def corr_sugar_metabolism(model: Model) -&gt; float:     \"\"\"Pearson correlation between agent sugar and metabolism.      This reporter extracts the ``sugar`` and ``metabolism`` columns from the     primary agent set and returns their Pearson correlation coefficient. When     the agent set is empty or contains insufficient variation the function     returns ``nan``.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and provide a Polars DataFrame         with ``sugar`` and ``metabolism`` columns.      Returns     -------     float         Pearson correlation coefficient between sugar and metabolism, or         ``nan`` when the correlation is undefined (empty set or constant         values).     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      agent_df = primary_set.df     sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)     metabolism = agent_df[\"metabolism\"].to_numpy().astype(np.float64)     return _safe_corr(sugar, metabolism)   def corr_sugar_vision(model: Model) -&gt; float:     \"\"\"Pearson correlation between agent sugar and vision.      Extracts the ``sugar`` and ``vision`` columns from the primary agent set     and returns their Pearson correlation coefficient. If the reporter cannot     compute a meaningful correlation (for example, when the agent set is     empty or values are constant) it returns ``nan``.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and provide a Polars DataFrame         with ``sugar`` and ``vision`` columns.      Returns     -------     float         Pearson correlation coefficient between sugar and vision, or ``nan``         when the correlation is undefined.     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      agent_df = primary_set.df     sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)     vision = agent_df[\"vision\"].to_numpy().astype(np.float64)     return _safe_corr(sugar, vision)   def _safe_corr(x: np.ndarray, y: np.ndarray) -&gt; float:     \"\"\"Safely compute Pearson correlation between two 1-D arrays.      This helper guards against degenerate inputs (too few observations or     constant arrays) which would make the Pearson correlation undefined or     numerically unstable. When a valid correlation can be computed the     function returns a Python float.      Parameters     ----------     x : np.ndarray         One-dimensional numeric array containing the first variable to         correlate.     y : np.ndarray         One-dimensional numeric array containing the second variable to         correlate.      Returns     -------     float         Pearson correlation coefficient as a Python float, or ``nan`` if the         correlation is undefined (fewer than 2 observations or constant         inputs).     \"\"\"     if x.size &lt; 2 or y.size &lt; 2:         return float(\"nan\")     if np.allclose(x, x[0]) or np.allclose(y, y[0]):         return float(\"nan\")     return float(np.corrcoef(x, y)[0, 1])   class Sugarscape(Model):     \"\"\"Minimal Sugarscape model used throughout the tutorial.      This class wires together a grid that stores ``sugar`` per cell, an     agent set implementation (passed in as ``agent_type``), and a     data collector that records model- and agent-level statistics.      The model's responsibilities are to:     - create the sugar landscape (cells with current and maximum sugar)     - create and place agents on the grid     - advance the sugar regrowth rule each step     - run the model for a fixed number of steps and collect data      Parameters     ----------     agent_type : type[AntsBase]         The :class:`AgentSet` subclass implementing the movement rules         (sequential, numba-accelerated, or parallel).     n_agents : int         Number of agents to create and place on the grid.     width : int         Grid width (number of columns).     height : int         Grid height (number of rows).     max_sugar : int, optional         Upper bound for the randomly initialised sugar values on the grid,         by default 4.     seed : int | None, optional         RNG seed to make runs reproducible across variants, by default None.      Notes     -----     The grid uses a von Neumann neighbourhood and capacity 1 (at most one     agent per cell). Both the sugar landscape and initial agent traits are     drawn from ``self.random`` so different movement variants can be     instantiated with identical initial conditions by passing the same seed.     \"\"\"      def __init__(         self,         agent_type: type[AntsBase],         n_agents: int,         *,         width: int,         height: int,         max_sugar: int = 4,         seed: int | None = None,     ) -&gt; None:         if n_agents &gt; width * height:             raise ValueError(                 \"Cannot place more agents than grid cells when capacity is 1.\"             )         super().__init__(seed)          # 1. Let's create the sugar grid and set up the space          sugar_grid_df = self._generate_sugar_grid(width, height, max_sugar)         self.space = Grid(             self, [width, height], neighborhood_type=\"von_neumann\", capacity=1         )         self.space.set_cells(sugar_grid_df)         self._max_sugar = sugar_grid_df.select([\"dim_0\", \"dim_1\", \"max_sugar\"])          # 2. Now we create the agents and place them on the grid          agent_frame = self._generate_agent_frame(n_agents)         main_set = agent_type(self, agent_frame)         self.sets += main_set         self.space.place_to_empty(self.sets)          # 3. Finally we set up the data collector         self.datacollector = DataCollector(             model=self,             model_reporters={                 \"mean_sugar\": lambda m: 0.0                 if len(m.sets[0]) == 0                 else float(m.sets[0].df[\"sugar\"].mean()),                 \"total_sugar\": lambda m: float(m.sets[0].df[\"sugar\"].sum())                 if len(m.sets[0])                 else 0.0,                 \"agents_alive\": lambda m: float(len(m.sets[0])) if len(m.sets) else 0.0,                 \"gini\": gini,                 \"corr_sugar_metabolism\": corr_sugar_metabolism,                 \"corr_sugar_vision\": corr_sugar_vision,             },             agent_reporters={\"traits\": [\"sugar\", \"metabolism\", \"vision\"]},         )         self.datacollector.collect()      def _generate_sugar_grid(         self, width: int, height: int, max_sugar: int     ) -&gt; pl.DataFrame:         \"\"\"Generate a random sugar grid.          Parameters         ----------         width : int             Grid width (number of columns).         height : int             Grid height (number of rows).         max_sugar : int             Maximum sugar value (inclusive) for each cell.          Returns         -------         pl.DataFrame             DataFrame with columns ``dim_0``, ``dim_1``, ``sugar`` (current             amount) and ``max_sugar`` (regrowth target).         \"\"\"         sugar_vals = self.random.integers(             0, max_sugar + 1, size=(width, height), dtype=np.int64         )         dim_0 = pl.Series(\"dim_0\", pl.arange(width, eager=True)).to_frame()         dim_1 = pl.Series(\"dim_1\", pl.arange(height, eager=True)).to_frame()         return dim_0.join(dim_1, how=\"cross\").with_columns(             sugar=sugar_vals.flatten(), max_sugar=sugar_vals.flatten()         )      def _generate_agent_frame(self, n_agents: int) -&gt; pl.DataFrame:         \"\"\"Create the initial agent frame populated with agent traits.          Parameters         ----------         n_agents : int             Number of agents to create.          Returns         -------         pl.DataFrame             DataFrame with columns ``sugar``, ``metabolism`` and ``vision``             (integer values) for each agent.         \"\"\"         rng = self.random         return pl.DataFrame(             {                 \"sugar\": rng.integers(6, 25, size=n_agents, dtype=np.int64),                 \"metabolism\": rng.integers(2, 5, size=n_agents, dtype=np.int64),                 \"vision\": rng.integers(1, 6, size=n_agents, dtype=np.int64),             }         )      def step(self) -&gt; None:         \"\"\"Advance the model by one step.          Notes         -----         The per-step ordering is important and this tutorial implements the         classic Sugarscape \"instant growback\": agents move and eat first,         and then empty cells are refilled immediately (move -&gt; eat -&gt; regrow         -&gt; collect).         \"\"\"         if len(self.sets[0]) == 0:             self.running = False             return         self.sets[0].step()         self._advance_sugar_field()         self.datacollector.collect()         if len(self.sets[0]) == 0:             self.running = False      def run(self, steps: int) -&gt; None:         \"\"\"Run the model for a fixed number of steps.          Parameters         ----------         steps : int             Maximum number of steps to run. The model may terminate earlier if             ``self.running`` is set to ``False`` (for example, when all agents             have died).         \"\"\"         for _ in range(steps):             if not self.running:                 break             self.step()      def _advance_sugar_field(self) -&gt; None:         \"\"\"Apply the instant-growback sugar regrowth rule.          Empty cells (no agent present) are refilled to their ``max_sugar``         value. Cells that are occupied are set to zero because agents harvest         the sugar when they eat. The method uses vectorised DataFrame joins         and writes to keep the operation efficient.         \"\"\"         empty_cells = self.space.empty_cells         if not empty_cells.is_empty():             # Look up the maximum sugar for each empty cell and restore it.             refresh = empty_cells.join(                 self._max_sugar, on=[\"dim_0\", \"dim_1\"], how=\"left\"             )             self.space.set_cells(empty_cells, {\"sugar\": refresh[\"max_sugar\"]})         full_cells = self.space.full_cells         if not full_cells.is_empty():             # Occupied cells have just been harvested; set their sugar to 0.             zeros = pl.Series(np.zeros(len(full_cells), dtype=np.int64))             self.space.set_cells(full_cells, {\"sugar\": zeros}) In\u00a0[5]: Copied! <pre>class AntsBase(AgentSet):\n    \"\"\"Base agent set for the Sugarscape tutorial.\n\n    This class implements the common behaviour shared by all agent\n    movement variants (sequential, numba-accelerated and parallel).\n\n    Notes\n    -----\n    - Agents are expected to have integer traits: ``sugar``, ``metabolism``\n      and ``vision``. These are validated in :meth:`__init__`.\n    - Subclasses must implement :meth:`move` which changes agent positions\n      on the grid (via :meth:`mesa_frames.Grid` helpers).\n    \"\"\"\n\n    def __init__(self, model: Model, agent_frame: pl.DataFrame) -&gt; None:\n        \"\"\"Initialise the agent set and validate required trait columns.\n\n        Parameters\n        ----------\n        model : Model\n            The parent model which provides RNG and space.\n        agent_frame : pl.DataFrame\n            A Polars DataFrame with at least the columns ``sugar``,\n            ``metabolism`` and ``vision`` for each agent.\n\n        Raises\n        ------\n        ValueError\n            If required trait columns are missing from ``agent_frame``.\n        \"\"\"\n        super().__init__(model)\n        required = {\"sugar\", \"metabolism\", \"vision\"}\n        missing = required.difference(agent_frame.columns)\n        if missing:\n            raise ValueError(\n                f\"Initial agent frame must include columns {sorted(required)}; missing {sorted(missing)}.\"\n            )\n        self.add(agent_frame.clone())\n\n    def step(self) -&gt; None:\n        \"\"\"Advance the agent set by one time step.\n\n        The update order is important: agents are first shuffled to randomise\n        move order (this is important only for sequential variants), then they move, harvest sugar\n        from their occupied cells, and finally any agents whose sugar falls\n        to zero or below are removed.\n        \"\"\"\n        # Randomise ordering for movement decisions when required by the\n        # implementation (e.g. sequential update uses this shuffle).\n        self.shuffle(inplace=True)\n        # Movement policy implemented by subclasses.\n        self.move()\n        # Agents harvest sugar on their occupied cells.\n        self.eat()\n        # Remove agents that starved after eating.\n        self._remove_starved()\n\n    def move(self) -&gt; None:  # pragma: no cover\n        \"\"\"Abstract movement method.\n\n        Subclasses must override this method to update agent positions on the\n        grid. Implementations should use :meth:`mesa_frames.Grid.move_agents`\n        or similar helpers provided by the space API.\n        \"\"\"\n        raise NotImplementedError\n\n    def eat(self) -&gt; None:\n        \"\"\"Agents harvest sugar from the cells they currently occupy.\n\n        Behaviour:\n        - Look up the set of occupied cells (cells that reference an agent\n          id).\n        - For each occupied cell, add the cell sugar to the agent's sugar\n          stock and subtract the agent's metabolism cost.\n        - After agents harvest, set the sugar on those cells to zero (they\n          were consumed).\n        \"\"\"\n        # Map of currently occupied agent ids on the grid.\n        occupied_ids = self.index\n        # `occupied_ids` is a Polars Series; calling `is_in` with a Series\n        # of the same datatype is ambiguous in newer Polars. Use `implode`\n        # to collapse the Series into a list-like value for membership checks.\n        occupied_cells = self.space.cells.filter(\n            pl.col(\"agent_id\").is_in(occupied_ids.implode())\n        )\n        if occupied_cells.is_empty():\n            return\n        # The agent ordering here uses the agent_id values stored in the\n        # occupied cells frame; indexing the agent set with that vector updates\n        # the matching agents' sugar values in one vectorised write.\n        agent_ids = occupied_cells[\"agent_id\"]\n        self[agent_ids, \"sugar\"] = (\n            self[agent_ids, \"sugar\"]\n            + occupied_cells[\"sugar\"]\n            - self[agent_ids, \"metabolism\"]\n        )\n        # After harvesting, occupied cells have zero sugar.\n        self.space.set_cells(\n            occupied_cells.select([\"dim_0\", \"dim_1\"]),\n            {\"sugar\": pl.Series(np.zeros(len(occupied_cells), dtype=np.int64))},\n        )\n\n    def _remove_starved(self) -&gt; None:\n        \"\"\"Discard agents whose sugar stock has fallen to zero or below.\n\n        This method performs a vectorised filter on the agent frame and\n        removes any matching rows from the set.\n        \"\"\"\n        starved = self.df.filter(pl.col(\"sugar\") &lt;= 0)\n        if not starved.is_empty():\n            # ``discard`` accepts a DataFrame of agents to remove.\n            self.discard(starved)\n</pre>   class AntsBase(AgentSet):     \"\"\"Base agent set for the Sugarscape tutorial.      This class implements the common behaviour shared by all agent     movement variants (sequential, numba-accelerated and parallel).      Notes     -----     - Agents are expected to have integer traits: ``sugar``, ``metabolism``       and ``vision``. These are validated in :meth:`__init__`.     - Subclasses must implement :meth:`move` which changes agent positions       on the grid (via :meth:`mesa_frames.Grid` helpers).     \"\"\"      def __init__(self, model: Model, agent_frame: pl.DataFrame) -&gt; None:         \"\"\"Initialise the agent set and validate required trait columns.          Parameters         ----------         model : Model             The parent model which provides RNG and space.         agent_frame : pl.DataFrame             A Polars DataFrame with at least the columns ``sugar``,             ``metabolism`` and ``vision`` for each agent.          Raises         ------         ValueError             If required trait columns are missing from ``agent_frame``.         \"\"\"         super().__init__(model)         required = {\"sugar\", \"metabolism\", \"vision\"}         missing = required.difference(agent_frame.columns)         if missing:             raise ValueError(                 f\"Initial agent frame must include columns {sorted(required)}; missing {sorted(missing)}.\"             )         self.add(agent_frame.clone())      def step(self) -&gt; None:         \"\"\"Advance the agent set by one time step.          The update order is important: agents are first shuffled to randomise         move order (this is important only for sequential variants), then they move, harvest sugar         from their occupied cells, and finally any agents whose sugar falls         to zero or below are removed.         \"\"\"         # Randomise ordering for movement decisions when required by the         # implementation (e.g. sequential update uses this shuffle).         self.shuffle(inplace=True)         # Movement policy implemented by subclasses.         self.move()         # Agents harvest sugar on their occupied cells.         self.eat()         # Remove agents that starved after eating.         self._remove_starved()      def move(self) -&gt; None:  # pragma: no cover         \"\"\"Abstract movement method.          Subclasses must override this method to update agent positions on the         grid. Implementations should use :meth:`mesa_frames.Grid.move_agents`         or similar helpers provided by the space API.         \"\"\"         raise NotImplementedError      def eat(self) -&gt; None:         \"\"\"Agents harvest sugar from the cells they currently occupy.          Behaviour:         - Look up the set of occupied cells (cells that reference an agent           id).         - For each occupied cell, add the cell sugar to the agent's sugar           stock and subtract the agent's metabolism cost.         - After agents harvest, set the sugar on those cells to zero (they           were consumed).         \"\"\"         # Map of currently occupied agent ids on the grid.         occupied_ids = self.index         # `occupied_ids` is a Polars Series; calling `is_in` with a Series         # of the same datatype is ambiguous in newer Polars. Use `implode`         # to collapse the Series into a list-like value for membership checks.         occupied_cells = self.space.cells.filter(             pl.col(\"agent_id\").is_in(occupied_ids.implode())         )         if occupied_cells.is_empty():             return         # The agent ordering here uses the agent_id values stored in the         # occupied cells frame; indexing the agent set with that vector updates         # the matching agents' sugar values in one vectorised write.         agent_ids = occupied_cells[\"agent_id\"]         self[agent_ids, \"sugar\"] = (             self[agent_ids, \"sugar\"]             + occupied_cells[\"sugar\"]             - self[agent_ids, \"metabolism\"]         )         # After harvesting, occupied cells have zero sugar.         self.space.set_cells(             occupied_cells.select([\"dim_0\", \"dim_1\"]),             {\"sugar\": pl.Series(np.zeros(len(occupied_cells), dtype=np.int64))},         )      def _remove_starved(self) -&gt; None:         \"\"\"Discard agents whose sugar stock has fallen to zero or below.          This method performs a vectorised filter on the agent frame and         removes any matching rows from the set.         \"\"\"         starved = self.df.filter(pl.col(\"sugar\") &lt;= 0)         if not starved.is_empty():             # ``discard`` accepts a DataFrame of agents to remove.             self.discard(starved) In\u00a0[6]: Copied! <pre>class AntsSequential(AntsBase):\n    def _visible_cells(\n        self, origin: tuple[int, int], vision: int\n    ) -&gt; list[tuple[int, int]]:\n        \"\"\"List cells visible from an origin along the four cardinal axes.\n\n        The visibility set includes the origin cell itself and cells at\n        Manhattan distances 1..vision along the four cardinal directions\n        (up, down, left, right), clipped to the grid bounds.\n\n        Parameters\n        ----------\n        origin : tuple[int, int]\n            The agent's current coordinate ``(x, y)``.\n        vision : int\n            Maximum Manhattan radius to consider along each axis.\n\n        Returns\n        -------\n        list[tuple[int, int]]\n            Ordered list of visible cells (origin first, then increasing\n            step distance along each axis).\n        \"\"\"\n        x0, y0 = origin\n        width, height = self.space.dimensions\n        cells: list[tuple[int, int]] = [origin]\n        # Look outward one step at a time in the four cardinal directions.\n        for step in range(1, vision + 1):\n            if x0 + step &lt; width:\n                cells.append((x0 + step, y0))\n            if x0 - step &gt;= 0:\n                cells.append((x0 - step, y0))\n            if y0 + step &lt; height:\n                cells.append((x0, y0 + step))\n            if y0 - step &gt;= 0:\n                cells.append((x0, y0 - step))\n        return cells\n\n    def _choose_best_cell(\n        self,\n        origin: tuple[int, int],\n        vision: int,\n        sugar_map: dict[tuple[int, int], int],\n        blocked: set[tuple[int, int]] | None,\n    ) -&gt; tuple[int, int]:\n        \"\"\"Select the best visible cell according to the movement rules.\n\n        Tie-break rules (in order):\n        1. Prefer cells with strictly greater sugar.\n        2. If equal sugar, prefer the cell with smaller distance from the\n           origin (measured with the Frobenius norm returned by\n           ``space.get_distances``).\n        3. If still tied, prefer the cell with smaller coordinates (lexicographic\n           ordering of the ``(x, y)`` tuple).\n\n        Parameters\n        ----------\n        origin : tuple[int, int]\n            Agent's current coordinate.\n        vision : int\n            Maximum vision radius along cardinal axes.\n        sugar_map : dict[tuple[int, int], int]\n            Mapping from ``(x, y)`` to sugar amount.\n        blocked : set[tuple[int, int]] | None\n            Optional set of coordinates that should be considered occupied and\n            therefore skipped (except the origin which is always allowed).\n\n        Returns\n        -------\n        tuple[int, int]\n            Chosen target coordinate (may be the origin if no better cell is\n            available).\n        \"\"\"\n        best_cell = origin\n        best_sugar = sugar_map.get(origin, 0)\n        best_distance = 0\n        ox, oy = origin\n        for candidate in self._visible_cells(origin, vision):\n            # Skip blocked cells (occupied by other agents) unless it's the\n            # agent's current cell which we always consider.\n            if blocked and candidate != origin and candidate in blocked:\n                continue\n            sugar_here = sugar_map.get(candidate, 0)\n            # Use step-based Manhattan distance (number of steps along cardinal\n            # axes) which is the same metric used by the Numba path. This avoids\n            # calling the heavier `space.get_distances` per candidate.\n            cx, cy = candidate\n            distance = abs(cx - ox) + abs(cy - oy)\n            better = False\n            # Primary criterion: strictly more sugar.\n            if sugar_here &gt; best_sugar:\n                better = True\n            elif sugar_here == best_sugar:\n                # Secondary: closer distance.\n                if distance &lt; best_distance:\n                    better = True\n                # Tertiary: lexicographic tie-break on coordinates.\n                elif distance == best_distance and candidate &lt; best_cell:\n                    better = True\n            if better:\n                best_cell = candidate\n                best_sugar = sugar_here\n                best_distance = distance\n        return best_cell\n\n    def _current_sugar_map(self) -&gt; dict[tuple[int, int], int]:\n        \"\"\"Return a mapping from grid coordinates to the current sugar value.\n\n        Returns\n        -------\n        dict[tuple[int, int], int]\n            Keys are ``(x, y)`` tuples and values are the integer sugar amount\n            on that cell (zero if missing/None).\n        \"\"\"\n        cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])\n        # Build a plain Python dict for fast lookups in the movement code.\n        return {\n            (int(x), int(y)): 0 if sugar is None else int(sugar)\n            for x, y, sugar in cells.iter_rows()\n        }\n\n    def move(self) -&gt; None:\n        sugar_map = self._current_sugar_map()\n        state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")\n        positions = {\n            int(row[\"unique_id\"]): (int(row[\"dim_0\"]), int(row[\"dim_1\"]))\n            for row in state.iter_rows(named=True)\n        }\n        taken: set[tuple[int, int]] = set(positions.values())\n\n        for row in state.iter_rows(named=True):\n            agent_id = int(row[\"unique_id\"])\n            vision = int(row[\"vision\"])\n            current = positions[agent_id]\n            taken.discard(current)\n            target = self._choose_best_cell(current, vision, sugar_map, taken)\n            taken.add(target)\n            positions[agent_id] = target\n            if target != current:\n                self.space.move_agents(agent_id, target)\n</pre>   class AntsSequential(AntsBase):     def _visible_cells(         self, origin: tuple[int, int], vision: int     ) -&gt; list[tuple[int, int]]:         \"\"\"List cells visible from an origin along the four cardinal axes.          The visibility set includes the origin cell itself and cells at         Manhattan distances 1..vision along the four cardinal directions         (up, down, left, right), clipped to the grid bounds.          Parameters         ----------         origin : tuple[int, int]             The agent's current coordinate ``(x, y)``.         vision : int             Maximum Manhattan radius to consider along each axis.          Returns         -------         list[tuple[int, int]]             Ordered list of visible cells (origin first, then increasing             step distance along each axis).         \"\"\"         x0, y0 = origin         width, height = self.space.dimensions         cells: list[tuple[int, int]] = [origin]         # Look outward one step at a time in the four cardinal directions.         for step in range(1, vision + 1):             if x0 + step &lt; width:                 cells.append((x0 + step, y0))             if x0 - step &gt;= 0:                 cells.append((x0 - step, y0))             if y0 + step &lt; height:                 cells.append((x0, y0 + step))             if y0 - step &gt;= 0:                 cells.append((x0, y0 - step))         return cells      def _choose_best_cell(         self,         origin: tuple[int, int],         vision: int,         sugar_map: dict[tuple[int, int], int],         blocked: set[tuple[int, int]] | None,     ) -&gt; tuple[int, int]:         \"\"\"Select the best visible cell according to the movement rules.          Tie-break rules (in order):         1. Prefer cells with strictly greater sugar.         2. If equal sugar, prefer the cell with smaller distance from the            origin (measured with the Frobenius norm returned by            ``space.get_distances``).         3. If still tied, prefer the cell with smaller coordinates (lexicographic            ordering of the ``(x, y)`` tuple).          Parameters         ----------         origin : tuple[int, int]             Agent's current coordinate.         vision : int             Maximum vision radius along cardinal axes.         sugar_map : dict[tuple[int, int], int]             Mapping from ``(x, y)`` to sugar amount.         blocked : set[tuple[int, int]] | None             Optional set of coordinates that should be considered occupied and             therefore skipped (except the origin which is always allowed).          Returns         -------         tuple[int, int]             Chosen target coordinate (may be the origin if no better cell is             available).         \"\"\"         best_cell = origin         best_sugar = sugar_map.get(origin, 0)         best_distance = 0         ox, oy = origin         for candidate in self._visible_cells(origin, vision):             # Skip blocked cells (occupied by other agents) unless it's the             # agent's current cell which we always consider.             if blocked and candidate != origin and candidate in blocked:                 continue             sugar_here = sugar_map.get(candidate, 0)             # Use step-based Manhattan distance (number of steps along cardinal             # axes) which is the same metric used by the Numba path. This avoids             # calling the heavier `space.get_distances` per candidate.             cx, cy = candidate             distance = abs(cx - ox) + abs(cy - oy)             better = False             # Primary criterion: strictly more sugar.             if sugar_here &gt; best_sugar:                 better = True             elif sugar_here == best_sugar:                 # Secondary: closer distance.                 if distance &lt; best_distance:                     better = True                 # Tertiary: lexicographic tie-break on coordinates.                 elif distance == best_distance and candidate &lt; best_cell:                     better = True             if better:                 best_cell = candidate                 best_sugar = sugar_here                 best_distance = distance         return best_cell      def _current_sugar_map(self) -&gt; dict[tuple[int, int], int]:         \"\"\"Return a mapping from grid coordinates to the current sugar value.          Returns         -------         dict[tuple[int, int], int]             Keys are ``(x, y)`` tuples and values are the integer sugar amount             on that cell (zero if missing/None).         \"\"\"         cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])         # Build a plain Python dict for fast lookups in the movement code.         return {             (int(x), int(y)): 0 if sugar is None else int(sugar)             for x, y, sugar in cells.iter_rows()         }      def move(self) -&gt; None:         sugar_map = self._current_sugar_map()         state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")         positions = {             int(row[\"unique_id\"]): (int(row[\"dim_0\"]), int(row[\"dim_1\"]))             for row in state.iter_rows(named=True)         }         taken: set[tuple[int, int]] = set(positions.values())          for row in state.iter_rows(named=True):             agent_id = int(row[\"unique_id\"])             vision = int(row[\"vision\"])             current = positions[agent_id]             taken.discard(current)             target = self._choose_best_cell(current, vision, sugar_map, taken)             taken.add(target)             positions[agent_id] = target             if target != current:                 self.space.move_agents(agent_id, target) In\u00a0[7]: Copied! <pre>@njit(cache=True)\ndef _numba_should_replace(\n    best_sugar: int,\n    best_distance: int,\n    best_x: int,\n    best_y: int,\n    candidate_sugar: int,\n    candidate_distance: int,\n    candidate_x: int,\n    candidate_y: int,\n) -&gt; bool:\n    \"\"\"Numba helper: decide whether a candidate cell should replace the\n    current best cell according to the movement tie-break rules.\n\n    This implements the same ordering used in :meth:`_choose_best_cell` but\n    in a tightly-typed, compiled form suitable for Numba loops.\n\n    Parameters\n    ----------\n    best_sugar : int\n        Sugar at the current best cell.\n    best_distance : int\n        Manhattan distance from the origin to the current best cell.\n    best_x : int\n        X coordinate of the current best cell.\n    best_y : int\n        Y coordinate of the current best cell.\n    candidate_sugar : int\n        Sugar at the candidate cell.\n    candidate_distance : int\n        Manhattan distance from the origin to the candidate cell.\n    candidate_x : int\n        X coordinate of the candidate cell.\n    candidate_y : int\n        Y coordinate of the candidate cell.\n\n    Returns\n    -------\n    bool\n        True if the candidate should replace the current best cell.\n    \"\"\"\n    # Primary criterion: prefer strictly greater sugar.\n    if candidate_sugar &gt; best_sugar:\n        return True\n    # If sugar ties, prefer the closer cell.\n    if candidate_sugar == best_sugar:\n        if candidate_distance &lt; best_distance:\n            return True\n        # If distance ties as well, compare coordinates lexicographically.\n        if candidate_distance == best_distance:\n            if candidate_x &lt; best_x:\n                return True\n            if candidate_x == best_x and candidate_y &lt; best_y:\n                return True\n    return False\n\n\n@njit(cache=True)\ndef _numba_find_best_cell(\n    x0: int,\n    y0: int,\n    vision: int,\n    sugar_array: np.ndarray,\n    occupied: np.ndarray,\n) -&gt; tuple[int, int]:\n    width, height = sugar_array.shape\n    best_x = x0\n    best_y = y0\n    best_sugar = sugar_array[x0, y0]\n    best_distance = 0\n\n    # Examine visible cells along the four cardinal directions, increasing\n    # step by step. The 'occupied' array marks cells that are currently\n    # unavailable (True = occupied). The origin cell is allowed as the\n    # default; callers typically clear the origin before searching.\n    for step in range(1, vision + 1):\n        nx = x0 + step\n        if nx &lt; width and not occupied[nx, y0]:\n            sugar_here = sugar_array[nx, y0]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0\n            ):\n                best_x = nx\n                best_y = y0\n                best_sugar = sugar_here\n                best_distance = step\n\n        nx = x0 - step\n        if nx &gt;= 0 and not occupied[nx, y0]:\n            sugar_here = sugar_array[nx, y0]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0\n            ):\n                best_x = nx\n                best_y = y0\n                best_sugar = sugar_here\n                best_distance = step\n\n        ny = y0 + step\n        if ny &lt; height and not occupied[x0, ny]:\n            sugar_here = sugar_array[x0, ny]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny\n            ):\n                best_x = x0\n                best_y = ny\n                best_sugar = sugar_here\n                best_distance = step\n\n        ny = y0 - step\n        if ny &gt;= 0 and not occupied[x0, ny]:\n            sugar_here = sugar_array[x0, ny]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny\n            ):\n                best_x = x0\n                best_y = ny\n                best_sugar = sugar_here\n                best_distance = step\n\n    return best_x, best_y\n\n\n@njit(cache=True)\ndef sequential_move_numba(\n    dim0: np.ndarray,\n    dim1: np.ndarray,\n    vision: np.ndarray,\n    sugar_array: np.ndarray,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Numba-accelerated sequential movement helper.\n\n    This function emulates the traditional asynchronous (sequential) update\n    where agents move one at a time in the current ordering. It accepts\n    numpy arrays describing agent positions and vision ranges, and a 2D\n    sugar array for lookup.\n\n    Parameters\n    ----------\n    dim0 : np.ndarray\n        1D integer array of length n_agents containing the x coordinates\n        for each agent.\n    dim1 : np.ndarray\n        1D integer array of length n_agents containing the y coordinates\n        for each agent.\n    vision : np.ndarray\n        1D integer array of vision radii for each agent.\n    sugar_array : np.ndarray\n        2D array shaped (width, height) containing per-cell sugar values.\n\n    Returns\n    -------\n    tuple[np.ndarray, np.ndarray]\n        Updated arrays of x and y coordinates after sequential movement.\n    \"\"\"\n    n_agents = dim0.shape[0]\n    width, height = sugar_array.shape\n    # Copy inputs to avoid mutating caller arrays in-place.\n    new_dim0 = dim0.copy()\n    new_dim1 = dim1.copy()\n    # Occupancy grid: True when a cell is currently occupied by an agent.\n    occupied = np.zeros((width, height), dtype=np.bool_)\n\n    # Mark initial occupancy.\n    for i in range(n_agents):\n        occupied[new_dim0[i], new_dim1[i]] = True\n\n    # Process agents in order. For each agent we clear its current cell in\n    # the occupancy grid (so it can consider moving into it), search for the\n    # best unoccupied visible cell, and mark the chosen destination as\n    # occupied. This models agents moving one-by-one.\n    for i in range(n_agents):\n        x0 = new_dim0[i]\n        y0 = new_dim1[i]\n        # Free the agent's current cell so it is considered available during\n        # the search (agents may choose to stay, in which case we'll re-mark\n        # it below).\n        occupied[x0, y0] = False\n        best_x, best_y = _numba_find_best_cell(\n            x0, y0, int(vision[i]), sugar_array, occupied\n        )\n        # Claim the chosen destination.\n        occupied[best_x, best_y] = True\n        new_dim0[i] = best_x\n        new_dim1[i] = best_y\n\n    return new_dim0, new_dim1\n\n\nclass AntsNumba(AntsBase):\n    def move(self) -&gt; None:\n        state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")\n        if state.is_empty():\n            return\n        agent_ids = state[\"unique_id\"]\n        dim0 = state[\"dim_0\"].to_numpy().astype(np.int64)\n        dim1 = state[\"dim_1\"].to_numpy().astype(np.int64)\n        vision = state[\"vision\"].to_numpy().astype(np.int64)\n\n        sugar_array = (\n            self.space.cells.sort([\"dim_0\", \"dim_1\"])\n            .with_columns(pl.col(\"sugar\").fill_null(0))[\"sugar\"]\n            .to_numpy()\n            .reshape(self.space.dimensions)\n        )\n\n        new_dim0, new_dim1 = sequential_move_numba(dim0, dim1, vision, sugar_array)\n        coords = pl.DataFrame({\"dim_0\": new_dim0.tolist(), \"dim_1\": new_dim1.tolist()})\n        self.space.move_agents(agent_ids, coords)\n</pre> @njit(cache=True) def _numba_should_replace(     best_sugar: int,     best_distance: int,     best_x: int,     best_y: int,     candidate_sugar: int,     candidate_distance: int,     candidate_x: int,     candidate_y: int, ) -&gt; bool:     \"\"\"Numba helper: decide whether a candidate cell should replace the     current best cell according to the movement tie-break rules.      This implements the same ordering used in :meth:`_choose_best_cell` but     in a tightly-typed, compiled form suitable for Numba loops.      Parameters     ----------     best_sugar : int         Sugar at the current best cell.     best_distance : int         Manhattan distance from the origin to the current best cell.     best_x : int         X coordinate of the current best cell.     best_y : int         Y coordinate of the current best cell.     candidate_sugar : int         Sugar at the candidate cell.     candidate_distance : int         Manhattan distance from the origin to the candidate cell.     candidate_x : int         X coordinate of the candidate cell.     candidate_y : int         Y coordinate of the candidate cell.      Returns     -------     bool         True if the candidate should replace the current best cell.     \"\"\"     # Primary criterion: prefer strictly greater sugar.     if candidate_sugar &gt; best_sugar:         return True     # If sugar ties, prefer the closer cell.     if candidate_sugar == best_sugar:         if candidate_distance &lt; best_distance:             return True         # If distance ties as well, compare coordinates lexicographically.         if candidate_distance == best_distance:             if candidate_x &lt; best_x:                 return True             if candidate_x == best_x and candidate_y &lt; best_y:                 return True     return False   @njit(cache=True) def _numba_find_best_cell(     x0: int,     y0: int,     vision: int,     sugar_array: np.ndarray,     occupied: np.ndarray, ) -&gt; tuple[int, int]:     width, height = sugar_array.shape     best_x = x0     best_y = y0     best_sugar = sugar_array[x0, y0]     best_distance = 0      # Examine visible cells along the four cardinal directions, increasing     # step by step. The 'occupied' array marks cells that are currently     # unavailable (True = occupied). The origin cell is allowed as the     # default; callers typically clear the origin before searching.     for step in range(1, vision + 1):         nx = x0 + step         if nx &lt; width and not occupied[nx, y0]:             sugar_here = sugar_array[nx, y0]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0             ):                 best_x = nx                 best_y = y0                 best_sugar = sugar_here                 best_distance = step          nx = x0 - step         if nx &gt;= 0 and not occupied[nx, y0]:             sugar_here = sugar_array[nx, y0]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0             ):                 best_x = nx                 best_y = y0                 best_sugar = sugar_here                 best_distance = step          ny = y0 + step         if ny &lt; height and not occupied[x0, ny]:             sugar_here = sugar_array[x0, ny]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny             ):                 best_x = x0                 best_y = ny                 best_sugar = sugar_here                 best_distance = step          ny = y0 - step         if ny &gt;= 0 and not occupied[x0, ny]:             sugar_here = sugar_array[x0, ny]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny             ):                 best_x = x0                 best_y = ny                 best_sugar = sugar_here                 best_distance = step      return best_x, best_y   @njit(cache=True) def sequential_move_numba(     dim0: np.ndarray,     dim1: np.ndarray,     vision: np.ndarray,     sugar_array: np.ndarray, ) -&gt; tuple[np.ndarray, np.ndarray]:     \"\"\"Numba-accelerated sequential movement helper.      This function emulates the traditional asynchronous (sequential) update     where agents move one at a time in the current ordering. It accepts     numpy arrays describing agent positions and vision ranges, and a 2D     sugar array for lookup.      Parameters     ----------     dim0 : np.ndarray         1D integer array of length n_agents containing the x coordinates         for each agent.     dim1 : np.ndarray         1D integer array of length n_agents containing the y coordinates         for each agent.     vision : np.ndarray         1D integer array of vision radii for each agent.     sugar_array : np.ndarray         2D array shaped (width, height) containing per-cell sugar values.      Returns     -------     tuple[np.ndarray, np.ndarray]         Updated arrays of x and y coordinates after sequential movement.     \"\"\"     n_agents = dim0.shape[0]     width, height = sugar_array.shape     # Copy inputs to avoid mutating caller arrays in-place.     new_dim0 = dim0.copy()     new_dim1 = dim1.copy()     # Occupancy grid: True when a cell is currently occupied by an agent.     occupied = np.zeros((width, height), dtype=np.bool_)      # Mark initial occupancy.     for i in range(n_agents):         occupied[new_dim0[i], new_dim1[i]] = True      # Process agents in order. For each agent we clear its current cell in     # the occupancy grid (so it can consider moving into it), search for the     # best unoccupied visible cell, and mark the chosen destination as     # occupied. This models agents moving one-by-one.     for i in range(n_agents):         x0 = new_dim0[i]         y0 = new_dim1[i]         # Free the agent's current cell so it is considered available during         # the search (agents may choose to stay, in which case we'll re-mark         # it below).         occupied[x0, y0] = False         best_x, best_y = _numba_find_best_cell(             x0, y0, int(vision[i]), sugar_array, occupied         )         # Claim the chosen destination.         occupied[best_x, best_y] = True         new_dim0[i] = best_x         new_dim1[i] = best_y      return new_dim0, new_dim1   class AntsNumba(AntsBase):     def move(self) -&gt; None:         state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")         if state.is_empty():             return         agent_ids = state[\"unique_id\"]         dim0 = state[\"dim_0\"].to_numpy().astype(np.int64)         dim1 = state[\"dim_1\"].to_numpy().astype(np.int64)         vision = state[\"vision\"].to_numpy().astype(np.int64)          sugar_array = (             self.space.cells.sort([\"dim_0\", \"dim_1\"])             .with_columns(pl.col(\"sugar\").fill_null(0))[\"sugar\"]             .to_numpy()             .reshape(self.space.dimensions)         )          new_dim0, new_dim1 = sequential_move_numba(dim0, dim1, vision, sugar_array)         coords = pl.DataFrame({\"dim_0\": new_dim0.tolist(), \"dim_1\": new_dim1.tolist()})         self.space.move_agents(agent_ids, coords) In\u00a0[8]: Copied! <pre>class AntsParallel(AntsBase):\n    def move(self) -&gt; None:\n        \"\"\"Move agents in parallel by ranking visible cells and resolving conflicts.\n\n        Declarative mental model: express *what* each agent wants (ranked candidates),\n        then use dataframe ops to *allocate* (joins, group_by with a lottery).\n        Performance is handled by Polars/LazyFrames; avoid premature micro-optimisations.\n\n        Returns\n        -------\n        None\n            Movement updates happen in-place on the underlying space.\n        \"\"\"\n        # Early exit if there are no agents.\n        if len(self.df) == 0:\n            return\n\n        # current_pos columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_center   \u2506 dim_1_center   \u2502\n        # \u2502 ---      \u2506 ---            \u2506 ---            \u2502\n        # \u2502 u64      \u2506 i64            \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        current_pos = self.pos.select(\n            [\n                pl.col(\"unique_id\").alias(\"agent_id\"),\n                pl.col(\"dim_0\").alias(\"dim_0_center\"),\n                pl.col(\"dim_1\").alias(\"dim_1_center\"),\n            ]\n        )\n\n        neighborhood = self._build_neighborhood_frame(current_pos)\n        choices, origins, max_rank = self._rank_candidates(neighborhood, current_pos)\n        if choices.is_empty():\n            return\n\n        assigned = self._resolve_conflicts_in_rounds(choices, origins, max_rank)\n        if assigned.is_empty():\n            return\n\n        # move_df columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 unique_id  \u2506 dim_0      \u2506 dim_1      \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---        \u2502\n        # \u2502 u64        \u2506 i64        \u2506 i64        \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        move_df = pl.DataFrame(\n            {\n                \"unique_id\": assigned[\"agent_id\"],\n                \"dim_0\": assigned[\"dim_0_candidate\"],\n                \"dim_1\": assigned[\"dim_1_candidate\"],\n            }\n        )\n        # `move_agents` accepts IdsLike and SpaceCoordinates (Polars Series/DataFrame),\n        # so pass Series/DataFrame directly rather than converting to Python lists.\n        self.space.move_agents(move_df[\"unique_id\"], move_df.select([\"dim_0\", \"dim_1\"]))\n\n    def _build_neighborhood_frame(self, current_pos: pl.DataFrame) -&gt; pl.DataFrame:\n        \"\"\"Assemble the sugar-weighted neighbourhood for each sensing agent.\n\n        Parameters\n        ----------\n        current_pos : pl.DataFrame\n            DataFrame with columns ``agent_id``, ``dim_0_center`` and\n            ``dim_1_center`` describing the current position of each agent.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``agent_id``, ``radius``, ``dim_0_candidate``,\n            ``dim_1_candidate`` and ``sugar`` describing the visible cells for\n            each agent.\n        \"\"\"\n        # Build a neighbourhood frame: for each agent and visible cell we\n        # attach the cell sugar. The raw offsets contain the candidate\n        # cell coordinates and the center coordinates for the sensing agent.\n        # Raw neighborhood columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0      \u2506 dim_1      \u2506 radius \u2506 dim_0_center   \u2506 dim_1_center   \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---    \u2506 ---            \u2506 ---            \u2502\n        # \u2502 i64        \u2506 i64        \u2506 i64    \u2506 i64            \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        neighborhood_cells = self.space.get_neighborhood(\n            radius=self[\"vision\"], agents=self, include_center=True\n        )\n\n        # sugar_cells columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0      \u2506 dim_1      \u2506 sugar  \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---    \u2502\n        # \u2502 i64        \u2506 i64        \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\n        sugar_cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])\n\n        neighborhood_cells = (\n            neighborhood_cells.join(sugar_cells, on=[\"dim_0\", \"dim_1\"], how=\"left\")\n            .with_columns(pl.col(\"sugar\").fill_null(0))\n            .rename({\"dim_0\": \"dim_0_candidate\", \"dim_1\": \"dim_1_candidate\"})\n        )\n\n        neighborhood_cells = neighborhood_cells.join(\n            current_pos,\n            left_on=[\"dim_0_center\", \"dim_1_center\"],\n            right_on=[\"dim_0_center\", \"dim_1_center\"],\n            how=\"left\",\n        )\n\n        # Final neighborhood columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 radius \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2502\n        # \u2502 ---      \u2506 ---    \u2506 ---              \u2506 ---              \u2506 ---    \u2502\n        # \u2502 u64      \u2506 i64    \u2506 i64              \u2506 i64              \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        neighborhood_cells = neighborhood_cells.drop(\n            [\"dim_0_center\", \"dim_1_center\"]\n        ).select([\"agent_id\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\", \"sugar\"])\n\n        return neighborhood_cells\n\n    def _rank_candidates(\n        self,\n        neighborhood: pl.DataFrame,\n        current_pos: pl.DataFrame,\n    ) -&gt; tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n        \"\"\"Rank candidate destination cells for each agent.\n\n        Parameters\n        ----------\n        neighborhood : pl.DataFrame\n            Output of :meth:`_build_neighborhood_frame` with columns\n            ``agent_id``, ``radius``, ``dim_0_candidate``, ``dim_1_candidate``\n            and ``sugar``.\n        current_pos : pl.DataFrame\n            Frame with columns ``agent_id``, ``dim_0_center`` and\n            ``dim_1_center`` describing where each agent currently stands.\n\n        Returns\n        -------\n        choices : pl.DataFrame\n            Ranked candidates per agent with columns ``agent_id``,\n            ``dim_0_candidate``, ``dim_1_candidate``, ``sugar``, ``radius`` and\n            ``rank``.\n        origins : pl.DataFrame\n            Original coordinates per agent with columns ``agent_id``,\n            ``dim_0`` and ``dim_1``.\n        max_rank : pl.DataFrame\n            Maximum available rank per agent with columns ``agent_id`` and\n            ``max_rank``.\n        \"\"\"\n        # Create ranked choices per agent: sort by sugar (desc), radius\n        # (asc), then coordinates. Keep the first unique entry per cell.\n        # choices columns (after select):\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2502\n        # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2502\n        # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        choices = (\n            neighborhood.select(\n                [\n                    \"agent_id\",\n                    \"dim_0_candidate\",\n                    \"dim_1_candidate\",\n                    \"sugar\",\n                    \"radius\",\n                ]\n            )\n            .with_columns(pl.col(\"radius\"))\n            .sort(\n                [\"agent_id\", \"sugar\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\"],\n                descending=[False, True, False, False, False],\n            )\n            .unique(\n                subset=[\"agent_id\", \"dim_0_candidate\", \"dim_1_candidate\"],\n                keep=\"first\",\n                maintain_order=True,\n            )\n            .with_columns(pl.col(\"agent_id\").cum_count().over(\"agent_id\").alias(\"rank\"))\n        )\n\n        # Precompute per\u2011agent candidate rank once so conflict resolution can\n        # promote losers by incrementing a cheap `current_rank` counter,\n        # without re-sorting after each round. Alternative: drop taken cells\n        # and re-rank by sugar every round; simpler conceptually but requires\n        # repeated sorts and deduplication, which is heavier than filtering by\n        # `rank &gt;= current_rank`.\n\n        # Origins for fallback (if an agent exhausts candidates it stays put).\n        # origins columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2502\n        # \u2502 ---      \u2506 ---        \u2506 ---        \u2502\n        # \u2502 u64      \u2506 i64        \u2506 i64        \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        origins = current_pos.select(\n            [\n                \"agent_id\",\n                pl.col(\"dim_0_center\").alias(\"dim_0\"),\n                pl.col(\"dim_1_center\").alias(\"dim_1\"),\n            ]\n        )\n\n        # Track the maximum available rank per agent to clamp promotions.\n        # This bounds `current_rank`; once an agent reaches `max_rank` and\n        # cannot secure a cell, they fall back to origin cleanly instead of\n        # chasing nonexistent ranks.\n        # max_rank columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 max_rank \u2502\n        # \u2502 ---      \u2506 ---       \u2502\n        # \u2502 u64      \u2506 u32       \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        max_rank = choices.group_by(\"agent_id\").agg(\n            pl.col(\"rank\").max().alias(\"max_rank\")\n        )\n        return choices, origins, max_rank\n\n    def _resolve_conflicts_in_rounds(\n        self,\n        choices: pl.DataFrame,\n        origins: pl.DataFrame,\n        max_rank: pl.DataFrame,\n    ) -&gt; pl.DataFrame:\n        \"\"\"Resolve movement conflicts through iterative lottery rounds.\n\n        Parameters\n        ----------\n        choices : pl.DataFrame\n            Ranked candidate cells per agent with headers matching the\n            ``choices`` frame returned by :meth:`_rank_candidates`.\n        origins : pl.DataFrame\n            Agent origin coordinates with columns ``agent_id``, ``dim_0`` and\n            ``dim_1``.\n        max_rank : pl.DataFrame\n            Maximum rank offset per agent with columns ``agent_id`` and\n            ``max_rank``.\n\n        Returns\n        -------\n        pl.DataFrame\n            Allocated movements with columns ``agent_id``, ``dim_0_candidate``\n            and ``dim_1_candidate``; each row records the destination assigned\n            to an agent.\n        \"\"\"\n        # Prepare unresolved agents and working tables.\n        agent_ids = choices[\"agent_id\"].unique(maintain_order=True)\n\n        # unresolved columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 current_rank  \u2502\n        # \u2502 ---      \u2506 ---            \u2502\n        # \u2502 u64      \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        unresolved = pl.DataFrame(\n            {\n                \"agent_id\": agent_ids,\n                \"current_rank\": pl.Series(np.zeros(len(agent_ids), dtype=np.int64)),\n            }\n        )\n\n        # assigned columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2502\n        # \u2502 ---      \u2506 ---              \u2506 ---              \u2502\n        # \u2502 u64      \u2506 i64              \u2506 i64              \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        assigned = pl.DataFrame(\n            {\n                \"agent_id\": pl.Series(\n                    name=\"agent_id\", values=[], dtype=agent_ids.dtype\n                ),\n                \"dim_0_candidate\": pl.Series(\n                    name=\"dim_0_candidate\", values=[], dtype=pl.Int64\n                ),\n                \"dim_1_candidate\": pl.Series(\n                    name=\"dim_1_candidate\", values=[], dtype=pl.Int64\n                ),\n            }\n        )\n\n        # taken columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0_candidate  \u2506 dim_1_candidate  \u2502\n        # \u2502 ---              \u2506 ---              \u2502\n        # \u2502 i64              \u2506 i64              \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        taken = pl.DataFrame(\n            {\n                \"dim_0_candidate\": pl.Series(\n                    name=\"dim_0_candidate\", values=[], dtype=pl.Int64\n                ),\n                \"dim_1_candidate\": pl.Series(\n                    name=\"dim_1_candidate\", values=[], dtype=pl.Int64\n                ),\n            }\n        )\n\n        # Resolve in rounds: each unresolved agent proposes its current-ranked\n        # candidate; winners per-cell are selected at random and losers are\n        # promoted to their next choice.\n        while unresolved.height &gt; 0:\n            # Using precomputed `rank` lets us select candidates with\n            # `rank &gt;= current_rank` and avoid re-ranking after each round.\n            # Alternative: remove taken cells and re-sort remaining candidates\n            # by sugar/distance per round (heavier due to repeated sort/dedupe).\n            # candidate_pool columns (after join with unresolved):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            candidate_pool = choices.join(unresolved, on=\"agent_id\")\n            candidate_pool = candidate_pool.filter(\n                pl.col(\"rank\") &gt;= pl.col(\"current_rank\")\n            )\n            if not taken.is_empty():\n                candidate_pool = candidate_pool.join(\n                    taken,\n                    on=[\"dim_0_candidate\", \"dim_1_candidate\"],\n                    how=\"anti\",\n                )\n\n            if candidate_pool.is_empty():\n                # No available candidates \u2014 everyone falls back to origin.\n                # Note: this covers both agents with no visible cells left and\n                # the case where all remaining candidates are already taken.\n                # fallback columns:\n                # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2506 current_rank \u2502\n                # \u2502 ---      \u2506 ---        \u2506 ---        \u2506 ---          \u2502\n                # \u2502 u64      \u2506 i64        \u2506 i64        \u2506 i64          \u2502\n                # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n                fallback = unresolved.join(origins, on=\"agent_id\", how=\"left\")\n                assigned = pl.concat(\n                    [\n                        assigned,\n                        fallback.select(\n                            [\n                                \"agent_id\",\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                break\n\n            # best_candidates columns (per agent first choice):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            best_candidates = (\n                candidate_pool.sort([\"agent_id\", \"rank\"])\n                .group_by(\"agent_id\", maintain_order=True)\n                .first()\n            )\n\n            # Agents that had no candidate this round fall back to origin.\n            # missing columns:\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            missing = unresolved.join(\n                best_candidates.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n            )\n            if not missing.is_empty():\n                # fallback (missing) columns match fallback table above.\n                fallback = missing.join(origins, on=\"agent_id\", how=\"left\")\n                assigned = pl.concat(\n                    [\n                        assigned,\n                        fallback.select(\n                            [\n                                \"agent_id\",\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                taken = pl.concat(\n                    [\n                        taken,\n                        fallback.select(\n                            [\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                unresolved = unresolved.join(\n                    missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n                )\n                best_candidates = best_candidates.join(\n                    missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n                )\n                if unresolved.is_empty() or best_candidates.is_empty():\n                    continue\n\n            # Add a small random lottery to break ties deterministically for\n            # each candidate set.\n            lottery = pl.Series(\"lottery\", self.random.random(best_candidates.height))\n            best_candidates = best_candidates.with_columns(lottery)\n\n            # winners columns:\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502 lottery \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2506 ---     \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2506 f64     \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            winners = (\n                best_candidates.sort([\"dim_0_candidate\", \"dim_1_candidate\", \"lottery\"])\n                .group_by([\"dim_0_candidate\", \"dim_1_candidate\"], maintain_order=True)\n                .first()\n            )\n\n            assigned = pl.concat(\n                [\n                    assigned,\n                    winners.select(\n                        [\n                            \"agent_id\",\n                            pl.col(\"dim_0_candidate\"),\n                            pl.col(\"dim_1_candidate\"),\n                        ]\n                    ),\n                ],\n                how=\"vertical\",\n            )\n            taken = pl.concat(\n                [\n                    taken,\n                    winners.select([\"dim_0_candidate\", \"dim_1_candidate\"]),\n                ],\n                how=\"vertical\",\n            )\n\n            winner_ids = winners.select(\"agent_id\")\n            unresolved = unresolved.join(winner_ids, on=\"agent_id\", how=\"anti\")\n            if unresolved.is_empty():\n                break\n\n            # loser candidates columns mirror best_candidates (minus winners).\n            losers = best_candidates.join(winner_ids, on=\"agent_id\", how=\"anti\")\n            if losers.is_empty():\n                continue\n\n            # loser_updates columns (after select):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 next_rank \u2502\n            # \u2502 ---      \u2506 ---       \u2502\n            # \u2502 u64      \u2506 i64       \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            loser_updates = (\n                losers.select(\n                    \"agent_id\",\n                    (pl.col(\"rank\") + 1).cast(pl.Int64).alias(\"next_rank\"),\n                )\n                .join(max_rank, on=\"agent_id\", how=\"left\")\n                .with_columns(\n                    pl.min_horizontal(pl.col(\"next_rank\"), pl.col(\"max_rank\")).alias(\n                        \"next_rank\"\n                    )\n                )\n                .select([\"agent_id\", \"next_rank\"])\n            )\n\n            # Promote losers' current_rank (if any) and continue.\n            # unresolved (updated) retains columns agent_id/current_rank.\n            unresolved = (\n                unresolved.join(loser_updates, on=\"agent_id\", how=\"left\")\n                .with_columns(\n                    pl.when(pl.col(\"next_rank\").is_not_null())\n                    .then(pl.col(\"next_rank\"))\n                    .otherwise(pl.col(\"current_rank\"))\n                    .alias(\"current_rank\")\n                )\n                .drop(\"next_rank\")\n            )\n\n        return assigned\n</pre>   class AntsParallel(AntsBase):     def move(self) -&gt; None:         \"\"\"Move agents in parallel by ranking visible cells and resolving conflicts.          Declarative mental model: express *what* each agent wants (ranked candidates),         then use dataframe ops to *allocate* (joins, group_by with a lottery).         Performance is handled by Polars/LazyFrames; avoid premature micro-optimisations.          Returns         -------         None             Movement updates happen in-place on the underlying space.         \"\"\"         # Early exit if there are no agents.         if len(self.df) == 0:             return          # current_pos columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_center   \u2506 dim_1_center   \u2502         # \u2502 ---      \u2506 ---            \u2506 ---            \u2502         # \u2502 u64      \u2506 i64            \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         current_pos = self.pos.select(             [                 pl.col(\"unique_id\").alias(\"agent_id\"),                 pl.col(\"dim_0\").alias(\"dim_0_center\"),                 pl.col(\"dim_1\").alias(\"dim_1_center\"),             ]         )          neighborhood = self._build_neighborhood_frame(current_pos)         choices, origins, max_rank = self._rank_candidates(neighborhood, current_pos)         if choices.is_empty():             return          assigned = self._resolve_conflicts_in_rounds(choices, origins, max_rank)         if assigned.is_empty():             return          # move_df columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 unique_id  \u2506 dim_0      \u2506 dim_1      \u2502         # \u2502 ---        \u2506 ---        \u2506 ---        \u2502         # \u2502 u64        \u2506 i64        \u2506 i64        \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         move_df = pl.DataFrame(             {                 \"unique_id\": assigned[\"agent_id\"],                 \"dim_0\": assigned[\"dim_0_candidate\"],                 \"dim_1\": assigned[\"dim_1_candidate\"],             }         )         # `move_agents` accepts IdsLike and SpaceCoordinates (Polars Series/DataFrame),         # so pass Series/DataFrame directly rather than converting to Python lists.         self.space.move_agents(move_df[\"unique_id\"], move_df.select([\"dim_0\", \"dim_1\"]))      def _build_neighborhood_frame(self, current_pos: pl.DataFrame) -&gt; pl.DataFrame:         \"\"\"Assemble the sugar-weighted neighbourhood for each sensing agent.          Parameters         ----------         current_pos : pl.DataFrame             DataFrame with columns ``agent_id``, ``dim_0_center`` and             ``dim_1_center`` describing the current position of each agent.          Returns         -------         pl.DataFrame             DataFrame with columns ``agent_id``, ``radius``, ``dim_0_candidate``,             ``dim_1_candidate`` and ``sugar`` describing the visible cells for             each agent.         \"\"\"         # Build a neighbourhood frame: for each agent and visible cell we         # attach the cell sugar. The raw offsets contain the candidate         # cell coordinates and the center coordinates for the sensing agent.         # Raw neighborhood columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0      \u2506 dim_1      \u2506 radius \u2506 dim_0_center   \u2506 dim_1_center   \u2502         # \u2502 ---        \u2506 ---        \u2506 ---    \u2506 ---            \u2506 ---            \u2502         # \u2502 i64        \u2506 i64        \u2506 i64    \u2506 i64            \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         neighborhood_cells = self.space.get_neighborhood(             radius=self[\"vision\"], agents=self, include_center=True         )          # sugar_cells columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0      \u2506 dim_1      \u2506 sugar  \u2502         # \u2502 ---        \u2506 ---        \u2506 ---    \u2502         # \u2502 i64        \u2506 i64        \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561          sugar_cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])          neighborhood_cells = (             neighborhood_cells.join(sugar_cells, on=[\"dim_0\", \"dim_1\"], how=\"left\")             .with_columns(pl.col(\"sugar\").fill_null(0))             .rename({\"dim_0\": \"dim_0_candidate\", \"dim_1\": \"dim_1_candidate\"})         )          neighborhood_cells = neighborhood_cells.join(             current_pos,             left_on=[\"dim_0_center\", \"dim_1_center\"],             right_on=[\"dim_0_center\", \"dim_1_center\"],             how=\"left\",         )          # Final neighborhood columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 radius \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2502         # \u2502 ---      \u2506 ---    \u2506 ---              \u2506 ---              \u2506 ---    \u2502         # \u2502 u64      \u2506 i64    \u2506 i64              \u2506 i64              \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         neighborhood_cells = neighborhood_cells.drop(             [\"dim_0_center\", \"dim_1_center\"]         ).select([\"agent_id\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\", \"sugar\"])          return neighborhood_cells      def _rank_candidates(         self,         neighborhood: pl.DataFrame,         current_pos: pl.DataFrame,     ) -&gt; tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:         \"\"\"Rank candidate destination cells for each agent.          Parameters         ----------         neighborhood : pl.DataFrame             Output of :meth:`_build_neighborhood_frame` with columns             ``agent_id``, ``radius``, ``dim_0_candidate``, ``dim_1_candidate``             and ``sugar``.         current_pos : pl.DataFrame             Frame with columns ``agent_id``, ``dim_0_center`` and             ``dim_1_center`` describing where each agent currently stands.          Returns         -------         choices : pl.DataFrame             Ranked candidates per agent with columns ``agent_id``,             ``dim_0_candidate``, ``dim_1_candidate``, ``sugar``, ``radius`` and             ``rank``.         origins : pl.DataFrame             Original coordinates per agent with columns ``agent_id``,             ``dim_0`` and ``dim_1``.         max_rank : pl.DataFrame             Maximum available rank per agent with columns ``agent_id`` and             ``max_rank``.         \"\"\"         # Create ranked choices per agent: sort by sugar (desc), radius         # (asc), then coordinates. Keep the first unique entry per cell.         # choices columns (after select):         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2502         # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2502         # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         choices = (             neighborhood.select(                 [                     \"agent_id\",                     \"dim_0_candidate\",                     \"dim_1_candidate\",                     \"sugar\",                     \"radius\",                 ]             )             .with_columns(pl.col(\"radius\"))             .sort(                 [\"agent_id\", \"sugar\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\"],                 descending=[False, True, False, False, False],             )             .unique(                 subset=[\"agent_id\", \"dim_0_candidate\", \"dim_1_candidate\"],                 keep=\"first\",                 maintain_order=True,             )             .with_columns(pl.col(\"agent_id\").cum_count().over(\"agent_id\").alias(\"rank\"))         )          # Precompute per\u2011agent candidate rank once so conflict resolution can         # promote losers by incrementing a cheap `current_rank` counter,         # without re-sorting after each round. Alternative: drop taken cells         # and re-rank by sugar every round; simpler conceptually but requires         # repeated sorts and deduplication, which is heavier than filtering by         # `rank &gt;= current_rank`.          # Origins for fallback (if an agent exhausts candidates it stays put).         # origins columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2502         # \u2502 ---      \u2506 ---        \u2506 ---        \u2502         # \u2502 u64      \u2506 i64        \u2506 i64        \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         origins = current_pos.select(             [                 \"agent_id\",                 pl.col(\"dim_0_center\").alias(\"dim_0\"),                 pl.col(\"dim_1_center\").alias(\"dim_1\"),             ]         )          # Track the maximum available rank per agent to clamp promotions.         # This bounds `current_rank`; once an agent reaches `max_rank` and         # cannot secure a cell, they fall back to origin cleanly instead of         # chasing nonexistent ranks.         # max_rank columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 max_rank \u2502         # \u2502 ---      \u2506 ---       \u2502         # \u2502 u64      \u2506 u32       \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         max_rank = choices.group_by(\"agent_id\").agg(             pl.col(\"rank\").max().alias(\"max_rank\")         )         return choices, origins, max_rank      def _resolve_conflicts_in_rounds(         self,         choices: pl.DataFrame,         origins: pl.DataFrame,         max_rank: pl.DataFrame,     ) -&gt; pl.DataFrame:         \"\"\"Resolve movement conflicts through iterative lottery rounds.          Parameters         ----------         choices : pl.DataFrame             Ranked candidate cells per agent with headers matching the             ``choices`` frame returned by :meth:`_rank_candidates`.         origins : pl.DataFrame             Agent origin coordinates with columns ``agent_id``, ``dim_0`` and             ``dim_1``.         max_rank : pl.DataFrame             Maximum rank offset per agent with columns ``agent_id`` and             ``max_rank``.          Returns         -------         pl.DataFrame             Allocated movements with columns ``agent_id``, ``dim_0_candidate``             and ``dim_1_candidate``; each row records the destination assigned             to an agent.         \"\"\"         # Prepare unresolved agents and working tables.         agent_ids = choices[\"agent_id\"].unique(maintain_order=True)          # unresolved columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 current_rank  \u2502         # \u2502 ---      \u2506 ---            \u2502         # \u2502 u64      \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         unresolved = pl.DataFrame(             {                 \"agent_id\": agent_ids,                 \"current_rank\": pl.Series(np.zeros(len(agent_ids), dtype=np.int64)),             }         )          # assigned columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2502         # \u2502 ---      \u2506 ---              \u2506 ---              \u2502         # \u2502 u64      \u2506 i64              \u2506 i64              \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         assigned = pl.DataFrame(             {                 \"agent_id\": pl.Series(                     name=\"agent_id\", values=[], dtype=agent_ids.dtype                 ),                 \"dim_0_candidate\": pl.Series(                     name=\"dim_0_candidate\", values=[], dtype=pl.Int64                 ),                 \"dim_1_candidate\": pl.Series(                     name=\"dim_1_candidate\", values=[], dtype=pl.Int64                 ),             }         )          # taken columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0_candidate  \u2506 dim_1_candidate  \u2502         # \u2502 ---              \u2506 ---              \u2502         # \u2502 i64              \u2506 i64              \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         taken = pl.DataFrame(             {                 \"dim_0_candidate\": pl.Series(                     name=\"dim_0_candidate\", values=[], dtype=pl.Int64                 ),                 \"dim_1_candidate\": pl.Series(                     name=\"dim_1_candidate\", values=[], dtype=pl.Int64                 ),             }         )          # Resolve in rounds: each unresolved agent proposes its current-ranked         # candidate; winners per-cell are selected at random and losers are         # promoted to their next choice.         while unresolved.height &gt; 0:             # Using precomputed `rank` lets us select candidates with             # `rank &gt;= current_rank` and avoid re-ranking after each round.             # Alternative: remove taken cells and re-sort remaining candidates             # by sugar/distance per round (heavier due to repeated sort/dedupe).             # candidate_pool columns (after join with unresolved):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             candidate_pool = choices.join(unresolved, on=\"agent_id\")             candidate_pool = candidate_pool.filter(                 pl.col(\"rank\") &gt;= pl.col(\"current_rank\")             )             if not taken.is_empty():                 candidate_pool = candidate_pool.join(                     taken,                     on=[\"dim_0_candidate\", \"dim_1_candidate\"],                     how=\"anti\",                 )              if candidate_pool.is_empty():                 # No available candidates \u2014 everyone falls back to origin.                 # Note: this covers both agents with no visible cells left and                 # the case where all remaining candidates are already taken.                 # fallback columns:                 # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2506 current_rank \u2502                 # \u2502 ---      \u2506 ---        \u2506 ---        \u2506 ---          \u2502                 # \u2502 u64      \u2506 i64        \u2506 i64        \u2506 i64          \u2502                 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561                 fallback = unresolved.join(origins, on=\"agent_id\", how=\"left\")                 assigned = pl.concat(                     [                         assigned,                         fallback.select(                             [                                 \"agent_id\",                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 break              # best_candidates columns (per agent first choice):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             best_candidates = (                 candidate_pool.sort([\"agent_id\", \"rank\"])                 .group_by(\"agent_id\", maintain_order=True)                 .first()             )              # Agents that had no candidate this round fall back to origin.             # missing columns:             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---          \u2502             # \u2502 u64      \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             missing = unresolved.join(                 best_candidates.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"             )             if not missing.is_empty():                 # fallback (missing) columns match fallback table above.                 fallback = missing.join(origins, on=\"agent_id\", how=\"left\")                 assigned = pl.concat(                     [                         assigned,                         fallback.select(                             [                                 \"agent_id\",                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 taken = pl.concat(                     [                         taken,                         fallback.select(                             [                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 unresolved = unresolved.join(                     missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"                 )                 best_candidates = best_candidates.join(                     missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"                 )                 if unresolved.is_empty() or best_candidates.is_empty():                     continue              # Add a small random lottery to break ties deterministically for             # each candidate set.             lottery = pl.Series(\"lottery\", self.random.random(best_candidates.height))             best_candidates = best_candidates.with_columns(lottery)              # winners columns:             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502 lottery \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2506 ---     \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2506 f64     \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             winners = (                 best_candidates.sort([\"dim_0_candidate\", \"dim_1_candidate\", \"lottery\"])                 .group_by([\"dim_0_candidate\", \"dim_1_candidate\"], maintain_order=True)                 .first()             )              assigned = pl.concat(                 [                     assigned,                     winners.select(                         [                             \"agent_id\",                             pl.col(\"dim_0_candidate\"),                             pl.col(\"dim_1_candidate\"),                         ]                     ),                 ],                 how=\"vertical\",             )             taken = pl.concat(                 [                     taken,                     winners.select([\"dim_0_candidate\", \"dim_1_candidate\"]),                 ],                 how=\"vertical\",             )              winner_ids = winners.select(\"agent_id\")             unresolved = unresolved.join(winner_ids, on=\"agent_id\", how=\"anti\")             if unresolved.is_empty():                 break              # loser candidates columns mirror best_candidates (minus winners).             losers = best_candidates.join(winner_ids, on=\"agent_id\", how=\"anti\")             if losers.is_empty():                 continue              # loser_updates columns (after select):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 next_rank \u2502             # \u2502 ---      \u2506 ---       \u2502             # \u2502 u64      \u2506 i64       \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             loser_updates = (                 losers.select(                     \"agent_id\",                     (pl.col(\"rank\") + 1).cast(pl.Int64).alias(\"next_rank\"),                 )                 .join(max_rank, on=\"agent_id\", how=\"left\")                 .with_columns(                     pl.min_horizontal(pl.col(\"next_rank\"), pl.col(\"max_rank\")).alias(                         \"next_rank\"                     )                 )                 .select([\"agent_id\", \"next_rank\"])             )              # Promote losers' current_rank (if any) and continue.             # unresolved (updated) retains columns agent_id/current_rank.             unresolved = (                 unresolved.join(loser_updates, on=\"agent_id\", how=\"left\")                 .with_columns(                     pl.when(pl.col(\"next_rank\").is_not_null())                     .then(pl.col(\"next_rank\"))                     .otherwise(pl.col(\"current_rank\"))                     .alias(\"current_rank\")                 )                 .drop(\"next_rank\")             )          return assigned In\u00a0[9]: Copied! <pre>GRID_WIDTH = 40\nGRID_HEIGHT = 40\nNUM_AGENTS = 400\nMODEL_STEPS = 60\nMAX_SUGAR = 4\nSEED = 42\n\n\ndef run_variant(\n    agent_cls: type[AntsBase],\n    *,\n    steps: int,\n    seed: int,\n) -&gt; tuple[Sugarscape, float]:\n    model = Sugarscape(\n        agent_type=agent_cls,\n        n_agents=NUM_AGENTS,\n        width=GRID_WIDTH,\n        height=GRID_HEIGHT,\n        max_sugar=MAX_SUGAR,\n        seed=seed,\n    )\n    start = perf_counter()\n    model.run(steps)\n    return model, perf_counter() - start\n\n\nvariant_specs: dict[str, type[AntsBase]] = {\n    \"Sequential (Python loop)\": AntsSequential,\n    \"Sequential (Numba)\": AntsNumba,\n    \"Parallel (Polars)\": AntsParallel,\n}\n\nmodels: dict[str, Sugarscape] = {}\nframes: dict[str, pl.DataFrame] = {}\nruntimes: dict[str, float] = {}\n\nfor variant_name, agent_cls in variant_specs.items():\n    model, runtime = run_variant(agent_cls, steps=MODEL_STEPS, seed=SEED)\n    models[variant_name] = model\n    frames[variant_name] = model.datacollector.data[\"model\"]\n    runtimes[variant_name] = runtime\n\n    print(f\"{variant_name} aggregate trajectory (last 5 steps):\")\n    print(\n        frames[variant_name]\n        .select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"])\n        .tail(5)\n    )\n    print(f\"{variant_name} runtime: {runtime:.3f} s\")\n    print()\n\nruntime_table = (\n    pl.DataFrame(\n        [\n            {\n                \"update_rule\": variant_name,\n                \"runtime_seconds\": runtimes.get(variant_name, float(\"nan\")),\n            }\n            for variant_name in variant_specs.keys()\n        ]\n    )\n    .with_columns(pl.col(\"runtime_seconds\").round(4))\n    .sort(\"runtime_seconds\", descending=False, nulls_last=True)\n)\n\nprint(\"Runtime comparison (fastest first):\")\nprint(runtime_table)\n\n# Access models/frames on demand; keep namespace minimal.\nnumba_model_frame = frames.get(\"Sequential (Numba)\", pl.DataFrame())\npar_model_frame = frames.get(\"Parallel (Polars)\", pl.DataFrame())\n</pre>  GRID_WIDTH = 40 GRID_HEIGHT = 40 NUM_AGENTS = 400 MODEL_STEPS = 60 MAX_SUGAR = 4 SEED = 42   def run_variant(     agent_cls: type[AntsBase],     *,     steps: int,     seed: int, ) -&gt; tuple[Sugarscape, float]:     model = Sugarscape(         agent_type=agent_cls,         n_agents=NUM_AGENTS,         width=GRID_WIDTH,         height=GRID_HEIGHT,         max_sugar=MAX_SUGAR,         seed=seed,     )     start = perf_counter()     model.run(steps)     return model, perf_counter() - start   variant_specs: dict[str, type[AntsBase]] = {     \"Sequential (Python loop)\": AntsSequential,     \"Sequential (Numba)\": AntsNumba,     \"Parallel (Polars)\": AntsParallel, }  models: dict[str, Sugarscape] = {} frames: dict[str, pl.DataFrame] = {} runtimes: dict[str, float] = {}  for variant_name, agent_cls in variant_specs.items():     model, runtime = run_variant(agent_cls, steps=MODEL_STEPS, seed=SEED)     models[variant_name] = model     frames[variant_name] = model.datacollector.data[\"model\"]     runtimes[variant_name] = runtime      print(f\"{variant_name} aggregate trajectory (last 5 steps):\")     print(         frames[variant_name]         .select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"])         .tail(5)     )     print(f\"{variant_name} runtime: {runtime:.3f} s\")     print()  runtime_table = (     pl.DataFrame(         [             {                 \"update_rule\": variant_name,                 \"runtime_seconds\": runtimes.get(variant_name, float(\"nan\")),             }             for variant_name in variant_specs.keys()         ]     )     .with_columns(pl.col(\"runtime_seconds\").round(4))     .sort(\"runtime_seconds\", descending=False, nulls_last=True) )  print(\"Runtime comparison (fastest first):\") print(runtime_table)  # Access models/frames on demand; keep namespace minimal. numba_model_frame = frames.get(\"Sequential (Numba)\", pl.DataFrame()) par_model_frame = frames.get(\"Parallel (Polars)\", pl.DataFrame()) <pre>Sequential (Python loop) aggregate trajectory (last 5 steps):\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_sugar \u2506 total_sugar \u2506 agents_alive \u2502\n\u2502 ---  \u2506 ---        \u2506 ---         \u2506 ---          \u2502\n\u2502 i64  \u2506 f64        \u2506 f64         \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 56   \u2506 63.613169  \u2506 15458.0     \u2506 243.0        \u2502\n\u2502 57   \u2506 64.563786  \u2506 15689.0     \u2506 243.0        \u2502\n\u2502 58   \u2506 65.493827  \u2506 15915.0     \u2506 243.0        \u2502\n\u2502 59   \u2506 66.826446  \u2506 16172.0     \u2506 242.0        \u2502\n\u2502 60   \u2506 68.06639   \u2506 16404.0     \u2506 241.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nSequential (Python loop) runtime: 52.226 s\n\n</pre> <pre>Sequential (Numba) aggregate trajectory (last 5 steps):\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_sugar \u2506 total_sugar \u2506 agents_alive \u2502\n\u2502 ---  \u2506 ---        \u2506 ---         \u2506 ---          \u2502\n\u2502 i64  \u2506 f64        \u2506 f64         \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 56   \u2506 63.613169  \u2506 15458.0     \u2506 243.0        \u2502\n\u2502 57   \u2506 64.563786  \u2506 15689.0     \u2506 243.0        \u2502\n\u2502 58   \u2506 65.493827  \u2506 15915.0     \u2506 243.0        \u2502\n\u2502 59   \u2506 66.826446  \u2506 16172.0     \u2506 242.0        \u2502\n\u2502 60   \u2506 68.06639   \u2506 16404.0     \u2506 241.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nSequential (Numba) runtime: 2.396 s\n\n</pre> <pre>Parallel (Polars) aggregate trajectory (last 5 steps):\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_sugar \u2506 total_sugar \u2506 agents_alive \u2502\n\u2502 ---  \u2506 ---        \u2506 ---         \u2506 ---          \u2502\n\u2502 i64  \u2506 f64        \u2506 f64         \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 56   \u2506 60.059055  \u2506 15255.0     \u2506 254.0        \u2502\n\u2502 57   \u2506 60.976378  \u2506 15488.0     \u2506 254.0        \u2502\n\u2502 58   \u2506 61.866142  \u2506 15714.0     \u2506 254.0        \u2502\n\u2502 59   \u2506 63.007905  \u2506 15941.0     \u2506 253.0        \u2502\n\u2502 60   \u2506 63.881423  \u2506 16162.0     \u2506 253.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nParallel (Polars) runtime: 1.961 s\n\nRuntime comparison (fastest first):\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 update_rule              \u2506 runtime_seconds \u2502\n\u2502 ---                      \u2506 ---             \u2502\n\u2502 str                      \u2506 f64             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Parallel (Polars)        \u2506 1.9613          \u2502\n\u2502 Sequential (Numba)       \u2506 2.3955          \u2502\n\u2502 Sequential (Python loop) \u2506 52.2257         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[10]: Copied! <pre>comparison = numba_model_frame.select(\n    [\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]\n).join(\n    par_model_frame.select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]),\n    on=\"step\",\n    how=\"inner\",\n    suffix=\"_parallel\",\n)\ncomparison = comparison.with_columns(\n    (pl.col(\"mean_sugar\") - pl.col(\"mean_sugar_parallel\")).abs().alias(\"mean_diff\"),\n    (pl.col(\"total_sugar\") - pl.col(\"total_sugar_parallel\")).abs().alias(\"total_diff\"),\n    (pl.col(\"agents_alive\") - pl.col(\"agents_alive_parallel\"))\n    .abs()\n    .alias(\"count_diff\"),\n)\nprint(\"Step-level absolute differences (first 10 steps):\")\nprint(comparison.select([\"step\", \"mean_diff\", \"total_diff\", \"count_diff\"]).head(10))\n\n\n# Build the steady\u2011state metrics table from the DataCollector output rather than\n# recomputing reporters directly on the model objects. The collector already\n# stored the model\u2011level reporters (gini, correlations, etc.) every step.\ndef _last_row(df: pl.DataFrame) -&gt; pl.DataFrame:\n    if df.is_empty():\n        return df\n    # Ensure we take the final time step in case steps &lt; MODEL_STEPS due to extinction.\n    return df.sort(\"step\").tail(1)\n\n\nnumba_last = _last_row(frames.get(\"Sequential (Numba)\", pl.DataFrame()))\nparallel_last = _last_row(frames.get(\"Parallel (Polars)\", pl.DataFrame()))\n\nmetrics_pieces: list[pl.DataFrame] = []\nif not numba_last.is_empty():\n    metrics_pieces.append(\n        numba_last.select(\n            [\n                pl.lit(\"Sequential (Numba)\").alias(\"update_rule\"),\n                \"gini\",\n                \"corr_sugar_metabolism\",\n                \"corr_sugar_vision\",\n                pl.col(\"agents_alive\"),\n            ]\n        )\n    )\nif not parallel_last.is_empty():\n    metrics_pieces.append(\n        parallel_last.select(\n            [\n                pl.lit(\"Parallel (random tie-break)\").alias(\"update_rule\"),\n                \"gini\",\n                \"corr_sugar_metabolism\",\n                \"corr_sugar_vision\",\n                pl.col(\"agents_alive\"),\n            ]\n        )\n    )\n\nmetrics_table = (\n    pl.concat(metrics_pieces, how=\"vertical\") if metrics_pieces else pl.DataFrame()\n)\n\nprint(\"\\nSteady-state inequality metrics:\")\nprint(\n    metrics_table.select(\n        [\n            \"update_rule\",\n            pl.col(\"gini\").round(4),\n            pl.col(\"corr_sugar_metabolism\").round(4),\n            pl.col(\"corr_sugar_vision\").round(4),\n            pl.col(\"agents_alive\"),\n        ]\n    )\n)\n\nif metrics_table.height &gt;= 2:\n    numba_gini = metrics_table.filter(pl.col(\"update_rule\") == \"Sequential (Numba)\")[\n        \"gini\"\n    ][0]\n    par_gini = metrics_table.filter(\n        pl.col(\"update_rule\") == \"Parallel (random tie-break)\"\n    )[\"gini\"][0]\n    print(f\"Absolute Gini gap (numba vs parallel): {abs(numba_gini - par_gini):.4f}\")\n</pre> comparison = numba_model_frame.select(     [\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"] ).join(     par_model_frame.select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]),     on=\"step\",     how=\"inner\",     suffix=\"_parallel\", ) comparison = comparison.with_columns(     (pl.col(\"mean_sugar\") - pl.col(\"mean_sugar_parallel\")).abs().alias(\"mean_diff\"),     (pl.col(\"total_sugar\") - pl.col(\"total_sugar_parallel\")).abs().alias(\"total_diff\"),     (pl.col(\"agents_alive\") - pl.col(\"agents_alive_parallel\"))     .abs()     .alias(\"count_diff\"), ) print(\"Step-level absolute differences (first 10 steps):\") print(comparison.select([\"step\", \"mean_diff\", \"total_diff\", \"count_diff\"]).head(10))   # Build the steady\u2011state metrics table from the DataCollector output rather than # recomputing reporters directly on the model objects. The collector already # stored the model\u2011level reporters (gini, correlations, etc.) every step. def _last_row(df: pl.DataFrame) -&gt; pl.DataFrame:     if df.is_empty():         return df     # Ensure we take the final time step in case steps &lt; MODEL_STEPS due to extinction.     return df.sort(\"step\").tail(1)   numba_last = _last_row(frames.get(\"Sequential (Numba)\", pl.DataFrame())) parallel_last = _last_row(frames.get(\"Parallel (Polars)\", pl.DataFrame()))  metrics_pieces: list[pl.DataFrame] = [] if not numba_last.is_empty():     metrics_pieces.append(         numba_last.select(             [                 pl.lit(\"Sequential (Numba)\").alias(\"update_rule\"),                 \"gini\",                 \"corr_sugar_metabolism\",                 \"corr_sugar_vision\",                 pl.col(\"agents_alive\"),             ]         )     ) if not parallel_last.is_empty():     metrics_pieces.append(         parallel_last.select(             [                 pl.lit(\"Parallel (random tie-break)\").alias(\"update_rule\"),                 \"gini\",                 \"corr_sugar_metabolism\",                 \"corr_sugar_vision\",                 pl.col(\"agents_alive\"),             ]         )     )  metrics_table = (     pl.concat(metrics_pieces, how=\"vertical\") if metrics_pieces else pl.DataFrame() )  print(\"\\nSteady-state inequality metrics:\") print(     metrics_table.select(         [             \"update_rule\",             pl.col(\"gini\").round(4),             pl.col(\"corr_sugar_metabolism\").round(4),             pl.col(\"corr_sugar_vision\").round(4),             pl.col(\"agents_alive\"),         ]     ) )  if metrics_table.height &gt;= 2:     numba_gini = metrics_table.filter(pl.col(\"update_rule\") == \"Sequential (Numba)\")[         \"gini\"     ][0]     par_gini = metrics_table.filter(         pl.col(\"update_rule\") == \"Parallel (random tie-break)\"     )[\"gini\"][0]     print(f\"Absolute Gini gap (numba vs parallel): {abs(numba_gini - par_gini):.4f}\") <pre>Step-level absolute differences (first 10 steps):\nshape: (10, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_diff \u2506 total_diff \u2506 count_diff \u2502\n\u2502 ---  \u2506 ---       \u2506 ---        \u2506 ---        \u2502\n\u2502 i64  \u2506 f64       \u2506 f64        \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0    \u2506 0.0       \u2506 0.0        \u2506 0.0        \u2502\n\u2502 1    \u2506 0.0125    \u2506 5.0        \u2506 0.0        \u2502\n\u2502 2    \u2506 0.02      \u2506 8.0        \u2506 0.0        \u2502\n\u2502 3    \u2506 0.0075    \u2506 3.0        \u2506 0.0        \u2502\n\u2502 4    \u2506 0.071014  \u2506 13.0       \u2506 1.0        \u2502\n\u2502 5    \u2506 0.091603  \u2506 36.0       \u2506 0.0        \u2502\n\u2502 6    \u2506 0.038603  \u2506 62.0       \u2506 3.0        \u2502\n\u2502 7    \u2506 0.005146  \u2506 63.0       \u2506 4.0        \u2502\n\u2502 8    \u2506 0.020046  \u2506 73.0       \u2506 4.0        \u2502\n\u2502 9    \u2506 0.0096    \u2506 72.0       \u2506 4.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nSteady-state inequality metrics:\nshape: (2, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 update_rule                 \u2506 gini   \u2506 corr_sugar_metabolism \u2506 corr_sugar_vision \u2506 agents_alive \u2502\n\u2502 ---                         \u2506 ---    \u2506 ---                   \u2506 ---               \u2506 ---          \u2502\n\u2502 str                         \u2506 f64    \u2506 f64                   \u2506 f64               \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Sequential (Numba)          \u2506 0.3098 \u2506 -0.7981               \u2506 0.2852            \u2506 241.0        \u2502\n\u2502 Parallel (random tie-break) \u2506 0.3287 \u2506 -0.8211               \u2506 0.2199            \u2506 253.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nAbsolute Gini gap (numba vs parallel): 0.0189\n</pre>"},{"location":"user-guide/3_advanced_tutorial/#advanced-tutorial-rebuilding-sugarscape-with-mesa-frames","title":"Advanced Tutorial \u2014 Rebuilding Sugarscape with mesa-frames\u00b6","text":"<p>We revisit the classic Sugarscape instant-growback model described in chapter 2 of Growing Artificial Societies (Epstein &amp; Axtell, 1996) and rebuild it step by step using <code>mesa-frames</code>. Along the way we highlight why the traditional definition is not ideal for high-performance with mesa-frames and how a simple relaxation can unlock vectorisation and lead to similar macro behaviour.</p>"},{"location":"user-guide/3_advanced_tutorial/#sugarscape-in-plain-terms","title":"Sugarscape in Plain Terms\u00b6","text":"<p>We model a population of ants living on a rectangular grid rich in sugar. Each cell can host at most one ant and holds a fixed amount of sugar. Every time step unfolds as follows:</p> <ul> <li>Sense: each ant looks outward along the four cardinal directions up to its <code>vision</code> radius and spots open cells.</li> <li>Move: the ant chooses the cell with highest sugar (breaking ties by distance and coordinates). The sugar on cells that are already occupied (including its own) is 0.</li> <li>Eat &amp; survive: ants harvest the sugar on the cell they occupy. If their sugar stock falls below their <code>metabolism</code> cost, they die.</li> <li>Regrow: sugar instantly regrows to its maximum level on empty cells. The landscape is drawn from a uniform distribution, so resources are homogeneous on average and the interesting dynamics come from agent heterogeneity and congestion.</li> </ul> <p>The update schedule matters for micro-behaviour, so we study three variants:</p> <ol> <li>Sequential loop (asynchronous): This is the traditional definition. Ants move one at a time in random order. This cannot be vectorised easily as the best move for an ant might depend on the moves of earlier ants (for example, if they target the same cell).</li> <li>Sequential with Numba: matches the first variant but relies on a compiled helper for speed.</li> <li>Parallel (synchronous): all ants propose moves; conflicts are resolved at random before applying the winners simultaneously (and the losers get to their second-best cell, etc).</li> </ol> <p>The first variant (pure Python loops) is a natural starting point, but it is not the mesa-frames philosophy. The latter two are: we aim to write rules declaratively and let the dataframe engine worry about performance. Our guiding principle is to focus on modelling first and performance second. Only when a rule is truly inherently sequential do we fall back to a compiled kernel (Numba or JAX).</p> <p>Our goal is to show that, under instantaneous growback and uniform resources, the model converges to the same macroscopic inequality pattern regardless of whether agents act sequentially or in parallel and that As long as the random draws do not push the system into extinction, the long-run Gini coefficient of wealth and the wealth\u2013trait correlations line up within sampling error \u2014 a classic example of emergent macro regularities in agent-based models.</p>"},{"location":"user-guide/3_advanced_tutorial/#1-imports","title":"1. Imports\u00b6","text":""},{"location":"user-guide/3_advanced_tutorial/#2-model-definition","title":"2. Model definition\u00b6","text":"<p>In this section we define some helpers and the model class that wires together the grid and the agents. The <code>agent_type</code> parameter stays flexible so we can plug in different movement policies later, but the model now owns the logic that generates the sugar field and the initial agent frame. Because both helpers use <code>self.random</code>, instantiating each variant with the same seed keeps the initial conditions identical across the sequential, Numba, and parallel implementations.</p> <p>The space is a von Neumann grid (which means agents can only move up, down, left, or right) with capacity 1, meaning each cell can host at most one agent. The sugar field is stored as part of the cell data frame, with columns for current sugar and maximum sugar (for regrowth). The model also sets up a data collector to track aggregate statistics and agent traits over time.</p> <p>The <code>step</code> method advances the sugar field, triggers the agent set's step.</p> <p>We also define some useful functions to compute metrics like the Gini coefficient and correlations.</p>"},{"location":"user-guide/3_advanced_tutorial/#3-agent-definition","title":"3. Agent definition\u00b6","text":""},{"location":"user-guide/3_advanced_tutorial/#31-base-agent-class","title":"3.1 Base agent class\u00b6","text":"<p>Now let's define the agent class (the ant class). We start with a base class which implements the common logic for eating and starvation, while leaving the <code>move</code> method abstract. The base class also provides helper methods for sensing visible cells and choosing the best cell based on sugar, distance, and coordinates. This will allow us to define different movement policies (sequential, Numba-accelerated, and parallel) as subclasses that only need to implement the <code>move</code> method.</p>"},{"location":"user-guide/3_advanced_tutorial/#32-sequential-movement","title":"3.2 Sequential movement\u00b6","text":"<p>We now implement the simplest movement policy: sequential (asynchronous). Each agent moves one at a time in the current ordering, choosing the best visible cell according to the rules.</p> <p>This implementation uses plain Python loops as the logic cannot be easily vectorised. As a result, it is slow for large populations and grids. We will later show how to speed it up with Numba.</p>"},{"location":"user-guide/3_advanced_tutorial/#33-speeding-up-the-loop-with-numba","title":"3.3 Speeding Up the Loop with Numba\u00b6","text":"<p>As we will see later, the previous sequential implementation is slow for large populations and grids because it relies on plain Python loops. We can speed it up significantly by using Numba to compile the movement logic.</p> <p>Numba compiles numerical Python code to fast machine code at runtime. To use Numba, we need to rewrite the movement logic in a way that is compatible with Numba's restrictions (using tightly typed numpy arrays and accessing data indexes directly).</p>"},{"location":"user-guide/3_advanced_tutorial/#35-simultaneous-movement-with-conflict-resolution-the-polars-mesa-frames-idiomatic-way","title":"3.5 Simultaneous Movement with Conflict Resolution (the Polars mesa-frames idiomatic way)\u00b6","text":"<p>The previous implementation is optimal speed-wise but it's a bit low-level. It requires maintaining an occupancy grid and imperative loops and it might become tricky to extend with more complex movement rules or models. To stay in mesa-frames idiom, we can implement a parallel movement policy that uses Polars DataFrame operations to resolve conflicts when multiple agents target the same cell. These conflicts are resolved in rounds: in each round, each agent proposes its current best candidate cell; winners per cell are chosen at random, and losers are promoted to their next-ranked choice. This continues until all agents have moved. This implementation is a tad slower but still efficient and easier to read (for a Polars user).</p>"},{"location":"user-guide/3_advanced_tutorial/#4-run-the-model-variants","title":"4. Run the Model Variants\u00b6","text":"<p>We iterate over each movement policy with a shared helper so all runs reuse the same seed. The tutorial runs all three variants (Python sequential, Numba sequential, and parallel) by default; edit the script if you want to skip the slow pure-Python baseline.</p>"},{"location":"user-guide/3_advanced_tutorial/#5-comparing-the-update-rules","title":"5. Comparing the Update Rules\u00b6","text":"<p>Even though micro rules differ, aggregate trajectories remain qualitatively similar (sugar trends up while population gradually declines). When we join the traces step-by-step, we see small but noticeable deviations introduced by synchronous conflict resolution (e.g., a few more retirements when conflicts cluster). In our run (seed=42), the final-step Gini differs by \u22480.005, and wealth\u2013trait correlations match within ~1e-3. These gaps vary by seed and grid size, but they consistently stay modest, supporting the relaxed parallel update as a faithful macro-level approximation.</p>"},{"location":"user-guide/3_advanced_tutorial/#6-takeaways-and-next-steps","title":"6. Takeaways and Next Steps\u00b6","text":"<p>Some final notes:</p> <ul> <li>mesa-frames should preferably be used when you have many agents and operations can be vectorized.</li> <li>If your model is not easily vectorizable, consider using Numba or reducing your microscopic rule to a vectorizable form. As we saw, the macroscopic behavior can remain consistent (and be more similar to real-world systems).</li> </ul> <p>Currently, the Polars implementation spends most of the time in join operations.</p> <p>Polars + LazyFrames roadmap \u2013 future mesa-frames releases will expose LazyFrame-powered sets and spaces (which can also use a GPU cuda accelerated backend which greatly accelerates joins), so the same Polars code you wrote here will scale even further without touching Numba.</p>"},{"location":"user-guide/3_advanced_tutorial/","title":"Advanced Tutorial \u2014 Rebuilding Sugarscape with mesa-frames","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations <p>First, let's install and import the necessary packages.</p> <p>If you're running this tutorial on Google Colab or another fresh environment, uncomment the cell below to install the required dependencies.</p> In\u00a0[2]: Copied! <pre>!pip install git+https://github.com/projectmesa/mesa-frames polars numba numpy\n</pre> !pip install git+https://github.com/projectmesa/mesa-frames polars numba numpy <pre>Collecting git+https://github.com/projectmesa/mesa-frames\r\n  Cloning https://github.com/projectmesa/mesa-frames to /tmp/pip-req-build-c6okujw3\r\n  Running command git clone --filter=blob:none --quiet https://github.com/projectmesa/mesa-frames /tmp/pip-req-build-c6okujw3\r\n</pre> <pre>  Resolved https://github.com/projectmesa/mesa-frames to commit 33555b4b4cb6b95c69120b04bccf948a6da808eb\r\n</pre> <pre>  Installing build dependencies ... -</pre> <pre>\b \b\\</pre> <pre>\b \bdone\r\n</pre> <pre>  Getting requirements to build wheel ... done\r\n</pre> <pre>  Preparing metadata (pyproject.toml) ... done\r\nRequirement already satisfied: polars in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (1.34.0)\r\nRequirement already satisfied: numba in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (0.62.1)\r\nRequirement already satisfied: numpy in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (2.3.3)\r\nRequirement already satisfied: boto3&gt;=1.35.91 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: psycopg2-binary==2.9.10 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.9.10)\r\nRequirement already satisfied: pyarrow&gt;=20.0.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (21.0.0)\r\nRequirement already satisfied: polars-runtime-32==1.34.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from polars) (1.34.0)\r\nRequirement already satisfied: llvmlite&lt;0.46,&gt;=0.45.0dev0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from numba) (0.45.1)\r\nRequirement already satisfied: botocore&lt;1.41.0,&gt;=1.40.51 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.0.1)\r\nRequirement already satisfied: s3transfer&lt;0.15.0,&gt;=0.14.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (0.14.0)\r\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.5.0)\r\nRequirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.17.0)\r\n</pre> In\u00a0[3]: Copied! <pre>from time import perf_counter\n\nimport numpy as np\nimport polars as pl\nfrom numba import njit\n\nfrom mesa_frames import AgentSet, DataCollector, Grid, Model\n</pre> from time import perf_counter  import numpy as np import polars as pl from numba import njit  from mesa_frames import AgentSet, DataCollector, Grid, Model In\u00a0[4]: Copied! <pre># Model-level reporters\n\n\ndef gini(model: Model) -&gt; float:\n    \"\"\"Compute the Gini coefficient of agent sugar holdings.\n\n    The function reads the primary agent set from ``model.sets[0]`` and\n    computes the population Gini coefficient on the ``sugar`` column. The\n    implementation is robust to empty sets and zero-total sugar.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and to expose a Polars DataFrame\n        under ``.df`` with a ``sugar`` column.\n\n    Returns\n    -------\n    float\n        Gini coefficient in the range [0, 1] if defined, ``0.0`` when the\n        total sugar is zero, and ``nan`` when the agent set is empty or too\n        small to measure.\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    sugar = primary_set.df[\"sugar\"].to_numpy().astype(np.float64)\n\n    if sugar.size == 0:\n        return float(\"nan\")\n    sorted_vals = np.sort(sugar.astype(np.float64))\n    n = sorted_vals.size\n    if n == 0:\n        return float(\"nan\")\n    cumulative = np.cumsum(sorted_vals)\n    total = cumulative[-1]\n    if total == 0:\n        return 0.0\n    index = np.arange(1, n + 1, dtype=np.float64)\n    return float((2.0 * np.dot(index, sorted_vals) / (n * total)) - (n + 1) / n)\n\n\ndef corr_sugar_metabolism(model: Model) -&gt; float:\n    \"\"\"Pearson correlation between agent sugar and metabolism.\n\n    This reporter extracts the ``sugar`` and ``metabolism`` columns from the\n    primary agent set and returns their Pearson correlation coefficient. When\n    the agent set is empty or contains insufficient variation the function\n    returns ``nan``.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and provide a Polars DataFrame\n        with ``sugar`` and ``metabolism`` columns.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient between sugar and metabolism, or\n        ``nan`` when the correlation is undefined (empty set or constant\n        values).\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    agent_df = primary_set.df\n    sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)\n    metabolism = agent_df[\"metabolism\"].to_numpy().astype(np.float64)\n    return _safe_corr(sugar, metabolism)\n\n\ndef corr_sugar_vision(model: Model) -&gt; float:\n    \"\"\"Pearson correlation between agent sugar and vision.\n\n    Extracts the ``sugar`` and ``vision`` columns from the primary agent set\n    and returns their Pearson correlation coefficient. If the reporter cannot\n    compute a meaningful correlation (for example, when the agent set is\n    empty or values are constant) it returns ``nan``.\n\n    Parameters\n    ----------\n    model : Model\n        The simulation model that contains agent sets. The primary agent set\n        is expected to be at ``model.sets[0]`` and provide a Polars DataFrame\n        with ``sugar`` and ``vision`` columns.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient between sugar and vision, or ``nan``\n        when the correlation is undefined.\n    \"\"\"\n    if len(model.sets) == 0:\n        return float(\"nan\")\n\n    primary_set = model.sets[0]\n    if len(primary_set) == 0:\n        return float(\"nan\")\n\n    agent_df = primary_set.df\n    sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)\n    vision = agent_df[\"vision\"].to_numpy().astype(np.float64)\n    return _safe_corr(sugar, vision)\n\n\ndef _safe_corr(x: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Safely compute Pearson correlation between two 1-D arrays.\n\n    This helper guards against degenerate inputs (too few observations or\n    constant arrays) which would make the Pearson correlation undefined or\n    numerically unstable. When a valid correlation can be computed the\n    function returns a Python float.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        One-dimensional numeric array containing the first variable to\n        correlate.\n    y : np.ndarray\n        One-dimensional numeric array containing the second variable to\n        correlate.\n\n    Returns\n    -------\n    float\n        Pearson correlation coefficient as a Python float, or ``nan`` if the\n        correlation is undefined (fewer than 2 observations or constant\n        inputs).\n    \"\"\"\n    if x.size &lt; 2 or y.size &lt; 2:\n        return float(\"nan\")\n    if np.allclose(x, x[0]) or np.allclose(y, y[0]):\n        return float(\"nan\")\n    return float(np.corrcoef(x, y)[0, 1])\n\n\nclass Sugarscape(Model):\n    \"\"\"Minimal Sugarscape model used throughout the tutorial.\n\n    This class wires together a grid that stores ``sugar`` per cell, an\n    agent set implementation (passed in as ``agent_type``), and a\n    data collector that records model- and agent-level statistics.\n\n    The model's responsibilities are to:\n    - create the sugar landscape (cells with current and maximum sugar)\n    - create and place agents on the grid\n    - advance the sugar regrowth rule each step\n    - run the model for a fixed number of steps and collect data\n\n    Parameters\n    ----------\n    agent_type : type[AntsBase]\n        The :class:`AgentSet` subclass implementing the movement rules\n        (sequential, numba-accelerated, or parallel).\n    n_agents : int\n        Number of agents to create and place on the grid.\n    width : int\n        Grid width (number of columns).\n    height : int\n        Grid height (number of rows).\n    max_sugar : int, optional\n        Upper bound for the randomly initialised sugar values on the grid,\n        by default 4.\n    seed : int | None, optional\n        RNG seed to make runs reproducible across variants, by default None.\n\n    Notes\n    -----\n    The grid uses a von Neumann neighbourhood and capacity 1 (at most one\n    agent per cell). Both the sugar landscape and initial agent traits are\n    drawn from ``self.random`` so different movement variants can be\n    instantiated with identical initial conditions by passing the same seed.\n    \"\"\"\n\n    def __init__(\n        self,\n        agent_type: type[AntsBase],\n        n_agents: int,\n        *,\n        width: int,\n        height: int,\n        max_sugar: int = 4,\n        seed: int | None = None,\n    ) -&gt; None:\n        if n_agents &gt; width * height:\n            raise ValueError(\n                \"Cannot place more agents than grid cells when capacity is 1.\"\n            )\n        super().__init__(seed)\n\n        # 1. Let's create the sugar grid and set up the space\n\n        sugar_grid_df = self._generate_sugar_grid(width, height, max_sugar)\n        self.space = Grid(\n            self, [width, height], neighborhood_type=\"von_neumann\", capacity=1\n        )\n        self.space.set_cells(sugar_grid_df)\n        self._max_sugar = sugar_grid_df.select([\"dim_0\", \"dim_1\", \"max_sugar\"])\n\n        # 2. Now we create the agents and place them on the grid\n\n        agent_frame = self._generate_agent_frame(n_agents)\n        main_set = agent_type(self, agent_frame)\n        self.sets += main_set\n        self.space.place_to_empty(self.sets)\n\n        # 3. Finally we set up the data collector\n        self.datacollector = DataCollector(\n            model=self,\n            model_reporters={\n                \"mean_sugar\": lambda m: 0.0\n                if len(m.sets[0]) == 0\n                else float(m.sets[0].df[\"sugar\"].mean()),\n                \"total_sugar\": lambda m: float(m.sets[0].df[\"sugar\"].sum())\n                if len(m.sets[0])\n                else 0.0,\n                \"agents_alive\": lambda m: float(len(m.sets[0])) if len(m.sets) else 0.0,\n                \"gini\": gini,\n                \"corr_sugar_metabolism\": corr_sugar_metabolism,\n                \"corr_sugar_vision\": corr_sugar_vision,\n            },\n            agent_reporters={\"traits\": [\"sugar\", \"metabolism\", \"vision\"]},\n        )\n        self.datacollector.collect()\n\n    def _generate_sugar_grid(\n        self, width: int, height: int, max_sugar: int\n    ) -&gt; pl.DataFrame:\n        \"\"\"Generate a random sugar grid.\n\n        Parameters\n        ----------\n        width : int\n            Grid width (number of columns).\n        height : int\n            Grid height (number of rows).\n        max_sugar : int\n            Maximum sugar value (inclusive) for each cell.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``dim_0``, ``dim_1``, ``sugar`` (current\n            amount) and ``max_sugar`` (regrowth target).\n        \"\"\"\n        sugar_vals = self.random.integers(\n            0, max_sugar + 1, size=(width, height), dtype=np.int64\n        )\n        dim_0 = pl.Series(\"dim_0\", pl.arange(width, eager=True)).to_frame()\n        dim_1 = pl.Series(\"dim_1\", pl.arange(height, eager=True)).to_frame()\n        return dim_0.join(dim_1, how=\"cross\").with_columns(\n            sugar=sugar_vals.flatten(), max_sugar=sugar_vals.flatten()\n        )\n\n    def _generate_agent_frame(self, n_agents: int) -&gt; pl.DataFrame:\n        \"\"\"Create the initial agent frame populated with agent traits.\n\n        Parameters\n        ----------\n        n_agents : int\n            Number of agents to create.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``sugar``, ``metabolism`` and ``vision``\n            (integer values) for each agent.\n        \"\"\"\n        rng = self.random\n        return pl.DataFrame(\n            {\n                \"sugar\": rng.integers(6, 25, size=n_agents, dtype=np.int64),\n                \"metabolism\": rng.integers(2, 5, size=n_agents, dtype=np.int64),\n                \"vision\": rng.integers(1, 6, size=n_agents, dtype=np.int64),\n            }\n        )\n\n    def step(self) -&gt; None:\n        \"\"\"Advance the model by one step.\n\n        Notes\n        -----\n        The per-step ordering is important and this tutorial implements the\n        classic Sugarscape \"instant growback\": agents move and eat first,\n        and then empty cells are refilled immediately (move -&gt; eat -&gt; regrow\n        -&gt; collect).\n        \"\"\"\n        if len(self.sets[0]) == 0:\n            self.running = False\n            return\n        self.sets[0].step()\n        self._advance_sugar_field()\n        self.datacollector.collect()\n        if len(self.sets[0]) == 0:\n            self.running = False\n\n    def run(self, steps: int) -&gt; None:\n        \"\"\"Run the model for a fixed number of steps.\n\n        Parameters\n        ----------\n        steps : int\n            Maximum number of steps to run. The model may terminate earlier if\n            ``self.running`` is set to ``False`` (for example, when all agents\n            have died).\n        \"\"\"\n        for _ in range(steps):\n            if not self.running:\n                break\n            self.step()\n\n    def _advance_sugar_field(self) -&gt; None:\n        \"\"\"Apply the instant-growback sugar regrowth rule.\n\n        Empty cells (no agent present) are refilled to their ``max_sugar``\n        value. Cells that are occupied are set to zero because agents harvest\n        the sugar when they eat. The method uses vectorised DataFrame joins\n        and writes to keep the operation efficient.\n        \"\"\"\n        empty_cells = self.space.empty_cells\n        if not empty_cells.is_empty():\n            # Look up the maximum sugar for each empty cell and restore it.\n            refresh = empty_cells.join(\n                self._max_sugar, on=[\"dim_0\", \"dim_1\"], how=\"left\"\n            )\n            self.space.set_cells(empty_cells, {\"sugar\": refresh[\"max_sugar\"]})\n        full_cells = self.space.full_cells\n        if not full_cells.is_empty():\n            # Occupied cells have just been harvested; set their sugar to 0.\n            zeros = pl.Series(np.zeros(len(full_cells), dtype=np.int64))\n            self.space.set_cells(full_cells, {\"sugar\": zeros})\n</pre>  # Model-level reporters   def gini(model: Model) -&gt; float:     \"\"\"Compute the Gini coefficient of agent sugar holdings.      The function reads the primary agent set from ``model.sets[0]`` and     computes the population Gini coefficient on the ``sugar`` column. The     implementation is robust to empty sets and zero-total sugar.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and to expose a Polars DataFrame         under ``.df`` with a ``sugar`` column.      Returns     -------     float         Gini coefficient in the range [0, 1] if defined, ``0.0`` when the         total sugar is zero, and ``nan`` when the agent set is empty or too         small to measure.     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      sugar = primary_set.df[\"sugar\"].to_numpy().astype(np.float64)      if sugar.size == 0:         return float(\"nan\")     sorted_vals = np.sort(sugar.astype(np.float64))     n = sorted_vals.size     if n == 0:         return float(\"nan\")     cumulative = np.cumsum(sorted_vals)     total = cumulative[-1]     if total == 0:         return 0.0     index = np.arange(1, n + 1, dtype=np.float64)     return float((2.0 * np.dot(index, sorted_vals) / (n * total)) - (n + 1) / n)   def corr_sugar_metabolism(model: Model) -&gt; float:     \"\"\"Pearson correlation between agent sugar and metabolism.      This reporter extracts the ``sugar`` and ``metabolism`` columns from the     primary agent set and returns their Pearson correlation coefficient. When     the agent set is empty or contains insufficient variation the function     returns ``nan``.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and provide a Polars DataFrame         with ``sugar`` and ``metabolism`` columns.      Returns     -------     float         Pearson correlation coefficient between sugar and metabolism, or         ``nan`` when the correlation is undefined (empty set or constant         values).     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      agent_df = primary_set.df     sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)     metabolism = agent_df[\"metabolism\"].to_numpy().astype(np.float64)     return _safe_corr(sugar, metabolism)   def corr_sugar_vision(model: Model) -&gt; float:     \"\"\"Pearson correlation between agent sugar and vision.      Extracts the ``sugar`` and ``vision`` columns from the primary agent set     and returns their Pearson correlation coefficient. If the reporter cannot     compute a meaningful correlation (for example, when the agent set is     empty or values are constant) it returns ``nan``.      Parameters     ----------     model : Model         The simulation model that contains agent sets. The primary agent set         is expected to be at ``model.sets[0]`` and provide a Polars DataFrame         with ``sugar`` and ``vision`` columns.      Returns     -------     float         Pearson correlation coefficient between sugar and vision, or ``nan``         when the correlation is undefined.     \"\"\"     if len(model.sets) == 0:         return float(\"nan\")      primary_set = model.sets[0]     if len(primary_set) == 0:         return float(\"nan\")      agent_df = primary_set.df     sugar = agent_df[\"sugar\"].to_numpy().astype(np.float64)     vision = agent_df[\"vision\"].to_numpy().astype(np.float64)     return _safe_corr(sugar, vision)   def _safe_corr(x: np.ndarray, y: np.ndarray) -&gt; float:     \"\"\"Safely compute Pearson correlation between two 1-D arrays.      This helper guards against degenerate inputs (too few observations or     constant arrays) which would make the Pearson correlation undefined or     numerically unstable. When a valid correlation can be computed the     function returns a Python float.      Parameters     ----------     x : np.ndarray         One-dimensional numeric array containing the first variable to         correlate.     y : np.ndarray         One-dimensional numeric array containing the second variable to         correlate.      Returns     -------     float         Pearson correlation coefficient as a Python float, or ``nan`` if the         correlation is undefined (fewer than 2 observations or constant         inputs).     \"\"\"     if x.size &lt; 2 or y.size &lt; 2:         return float(\"nan\")     if np.allclose(x, x[0]) or np.allclose(y, y[0]):         return float(\"nan\")     return float(np.corrcoef(x, y)[0, 1])   class Sugarscape(Model):     \"\"\"Minimal Sugarscape model used throughout the tutorial.      This class wires together a grid that stores ``sugar`` per cell, an     agent set implementation (passed in as ``agent_type``), and a     data collector that records model- and agent-level statistics.      The model's responsibilities are to:     - create the sugar landscape (cells with current and maximum sugar)     - create and place agents on the grid     - advance the sugar regrowth rule each step     - run the model for a fixed number of steps and collect data      Parameters     ----------     agent_type : type[AntsBase]         The :class:`AgentSet` subclass implementing the movement rules         (sequential, numba-accelerated, or parallel).     n_agents : int         Number of agents to create and place on the grid.     width : int         Grid width (number of columns).     height : int         Grid height (number of rows).     max_sugar : int, optional         Upper bound for the randomly initialised sugar values on the grid,         by default 4.     seed : int | None, optional         RNG seed to make runs reproducible across variants, by default None.      Notes     -----     The grid uses a von Neumann neighbourhood and capacity 1 (at most one     agent per cell). Both the sugar landscape and initial agent traits are     drawn from ``self.random`` so different movement variants can be     instantiated with identical initial conditions by passing the same seed.     \"\"\"      def __init__(         self,         agent_type: type[AntsBase],         n_agents: int,         *,         width: int,         height: int,         max_sugar: int = 4,         seed: int | None = None,     ) -&gt; None:         if n_agents &gt; width * height:             raise ValueError(                 \"Cannot place more agents than grid cells when capacity is 1.\"             )         super().__init__(seed)          # 1. Let's create the sugar grid and set up the space          sugar_grid_df = self._generate_sugar_grid(width, height, max_sugar)         self.space = Grid(             self, [width, height], neighborhood_type=\"von_neumann\", capacity=1         )         self.space.set_cells(sugar_grid_df)         self._max_sugar = sugar_grid_df.select([\"dim_0\", \"dim_1\", \"max_sugar\"])          # 2. Now we create the agents and place them on the grid          agent_frame = self._generate_agent_frame(n_agents)         main_set = agent_type(self, agent_frame)         self.sets += main_set         self.space.place_to_empty(self.sets)          # 3. Finally we set up the data collector         self.datacollector = DataCollector(             model=self,             model_reporters={                 \"mean_sugar\": lambda m: 0.0                 if len(m.sets[0]) == 0                 else float(m.sets[0].df[\"sugar\"].mean()),                 \"total_sugar\": lambda m: float(m.sets[0].df[\"sugar\"].sum())                 if len(m.sets[0])                 else 0.0,                 \"agents_alive\": lambda m: float(len(m.sets[0])) if len(m.sets) else 0.0,                 \"gini\": gini,                 \"corr_sugar_metabolism\": corr_sugar_metabolism,                 \"corr_sugar_vision\": corr_sugar_vision,             },             agent_reporters={\"traits\": [\"sugar\", \"metabolism\", \"vision\"]},         )         self.datacollector.collect()      def _generate_sugar_grid(         self, width: int, height: int, max_sugar: int     ) -&gt; pl.DataFrame:         \"\"\"Generate a random sugar grid.          Parameters         ----------         width : int             Grid width (number of columns).         height : int             Grid height (number of rows).         max_sugar : int             Maximum sugar value (inclusive) for each cell.          Returns         -------         pl.DataFrame             DataFrame with columns ``dim_0``, ``dim_1``, ``sugar`` (current             amount) and ``max_sugar`` (regrowth target).         \"\"\"         sugar_vals = self.random.integers(             0, max_sugar + 1, size=(width, height), dtype=np.int64         )         dim_0 = pl.Series(\"dim_0\", pl.arange(width, eager=True)).to_frame()         dim_1 = pl.Series(\"dim_1\", pl.arange(height, eager=True)).to_frame()         return dim_0.join(dim_1, how=\"cross\").with_columns(             sugar=sugar_vals.flatten(), max_sugar=sugar_vals.flatten()         )      def _generate_agent_frame(self, n_agents: int) -&gt; pl.DataFrame:         \"\"\"Create the initial agent frame populated with agent traits.          Parameters         ----------         n_agents : int             Number of agents to create.          Returns         -------         pl.DataFrame             DataFrame with columns ``sugar``, ``metabolism`` and ``vision``             (integer values) for each agent.         \"\"\"         rng = self.random         return pl.DataFrame(             {                 \"sugar\": rng.integers(6, 25, size=n_agents, dtype=np.int64),                 \"metabolism\": rng.integers(2, 5, size=n_agents, dtype=np.int64),                 \"vision\": rng.integers(1, 6, size=n_agents, dtype=np.int64),             }         )      def step(self) -&gt; None:         \"\"\"Advance the model by one step.          Notes         -----         The per-step ordering is important and this tutorial implements the         classic Sugarscape \"instant growback\": agents move and eat first,         and then empty cells are refilled immediately (move -&gt; eat -&gt; regrow         -&gt; collect).         \"\"\"         if len(self.sets[0]) == 0:             self.running = False             return         self.sets[0].step()         self._advance_sugar_field()         self.datacollector.collect()         if len(self.sets[0]) == 0:             self.running = False      def run(self, steps: int) -&gt; None:         \"\"\"Run the model for a fixed number of steps.          Parameters         ----------         steps : int             Maximum number of steps to run. The model may terminate earlier if             ``self.running`` is set to ``False`` (for example, when all agents             have died).         \"\"\"         for _ in range(steps):             if not self.running:                 break             self.step()      def _advance_sugar_field(self) -&gt; None:         \"\"\"Apply the instant-growback sugar regrowth rule.          Empty cells (no agent present) are refilled to their ``max_sugar``         value. Cells that are occupied are set to zero because agents harvest         the sugar when they eat. The method uses vectorised DataFrame joins         and writes to keep the operation efficient.         \"\"\"         empty_cells = self.space.empty_cells         if not empty_cells.is_empty():             # Look up the maximum sugar for each empty cell and restore it.             refresh = empty_cells.join(                 self._max_sugar, on=[\"dim_0\", \"dim_1\"], how=\"left\"             )             self.space.set_cells(empty_cells, {\"sugar\": refresh[\"max_sugar\"]})         full_cells = self.space.full_cells         if not full_cells.is_empty():             # Occupied cells have just been harvested; set their sugar to 0.             zeros = pl.Series(np.zeros(len(full_cells), dtype=np.int64))             self.space.set_cells(full_cells, {\"sugar\": zeros}) In\u00a0[5]: Copied! <pre>class AntsBase(AgentSet):\n    \"\"\"Base agent set for the Sugarscape tutorial.\n\n    This class implements the common behaviour shared by all agent\n    movement variants (sequential, numba-accelerated and parallel).\n\n    Notes\n    -----\n    - Agents are expected to have integer traits: ``sugar``, ``metabolism``\n      and ``vision``. These are validated in :meth:`__init__`.\n    - Subclasses must implement :meth:`move` which changes agent positions\n      on the grid (via :meth:`mesa_frames.Grid` helpers).\n    \"\"\"\n\n    def __init__(self, model: Model, agent_frame: pl.DataFrame) -&gt; None:\n        \"\"\"Initialise the agent set and validate required trait columns.\n\n        Parameters\n        ----------\n        model : Model\n            The parent model which provides RNG and space.\n        agent_frame : pl.DataFrame\n            A Polars DataFrame with at least the columns ``sugar``,\n            ``metabolism`` and ``vision`` for each agent.\n\n        Raises\n        ------\n        ValueError\n            If required trait columns are missing from ``agent_frame``.\n        \"\"\"\n        super().__init__(model)\n        required = {\"sugar\", \"metabolism\", \"vision\"}\n        missing = required.difference(agent_frame.columns)\n        if missing:\n            raise ValueError(\n                f\"Initial agent frame must include columns {sorted(required)}; missing {sorted(missing)}.\"\n            )\n        self.add(agent_frame.clone())\n\n    def step(self) -&gt; None:\n        \"\"\"Advance the agent set by one time step.\n\n        The update order is important: agents are first shuffled to randomise\n        move order (this is important only for sequential variants), then they move, harvest sugar\n        from their occupied cells, and finally any agents whose sugar falls\n        to zero or below are removed.\n        \"\"\"\n        # Randomise ordering for movement decisions when required by the\n        # implementation (e.g. sequential update uses this shuffle).\n        self.shuffle(inplace=True)\n        # Movement policy implemented by subclasses.\n        self.move()\n        # Agents harvest sugar on their occupied cells.\n        self.eat()\n        # Remove agents that starved after eating.\n        self._remove_starved()\n\n    def move(self) -&gt; None:  # pragma: no cover\n        \"\"\"Abstract movement method.\n\n        Subclasses must override this method to update agent positions on the\n        grid. Implementations should use :meth:`mesa_frames.Grid.move_agents`\n        or similar helpers provided by the space API.\n        \"\"\"\n        raise NotImplementedError\n\n    def eat(self) -&gt; None:\n        \"\"\"Agents harvest sugar from the cells they currently occupy.\n\n        Behaviour:\n        - Look up the set of occupied cells (cells that reference an agent\n          id).\n        - For each occupied cell, add the cell sugar to the agent's sugar\n          stock and subtract the agent's metabolism cost.\n        - After agents harvest, set the sugar on those cells to zero (they\n          were consumed).\n        \"\"\"\n        # Map of currently occupied agent ids on the grid.\n        occupied_ids = self.index\n        # `occupied_ids` is a Polars Series; calling `is_in` with a Series\n        # of the same datatype is ambiguous in newer Polars. Use `implode`\n        # to collapse the Series into a list-like value for membership checks.\n        occupied_cells = self.space.cells.filter(\n            pl.col(\"agent_id\").is_in(occupied_ids.implode())\n        )\n        if occupied_cells.is_empty():\n            return\n        # The agent ordering here uses the agent_id values stored in the\n        # occupied cells frame; indexing the agent set with that vector updates\n        # the matching agents' sugar values in one vectorised write.\n        agent_ids = occupied_cells[\"agent_id\"]\n        self[agent_ids, \"sugar\"] = (\n            self[agent_ids, \"sugar\"]\n            + occupied_cells[\"sugar\"]\n            - self[agent_ids, \"metabolism\"]\n        )\n        # After harvesting, occupied cells have zero sugar.\n        self.space.set_cells(\n            occupied_cells.select([\"dim_0\", \"dim_1\"]),\n            {\"sugar\": pl.Series(np.zeros(len(occupied_cells), dtype=np.int64))},\n        )\n\n    def _remove_starved(self) -&gt; None:\n        \"\"\"Discard agents whose sugar stock has fallen to zero or below.\n\n        This method performs a vectorised filter on the agent frame and\n        removes any matching rows from the set.\n        \"\"\"\n        starved = self.df.filter(pl.col(\"sugar\") &lt;= 0)\n        if not starved.is_empty():\n            # ``discard`` accepts a DataFrame of agents to remove.\n            self.discard(starved)\n</pre>   class AntsBase(AgentSet):     \"\"\"Base agent set for the Sugarscape tutorial.      This class implements the common behaviour shared by all agent     movement variants (sequential, numba-accelerated and parallel).      Notes     -----     - Agents are expected to have integer traits: ``sugar``, ``metabolism``       and ``vision``. These are validated in :meth:`__init__`.     - Subclasses must implement :meth:`move` which changes agent positions       on the grid (via :meth:`mesa_frames.Grid` helpers).     \"\"\"      def __init__(self, model: Model, agent_frame: pl.DataFrame) -&gt; None:         \"\"\"Initialise the agent set and validate required trait columns.          Parameters         ----------         model : Model             The parent model which provides RNG and space.         agent_frame : pl.DataFrame             A Polars DataFrame with at least the columns ``sugar``,             ``metabolism`` and ``vision`` for each agent.          Raises         ------         ValueError             If required trait columns are missing from ``agent_frame``.         \"\"\"         super().__init__(model)         required = {\"sugar\", \"metabolism\", \"vision\"}         missing = required.difference(agent_frame.columns)         if missing:             raise ValueError(                 f\"Initial agent frame must include columns {sorted(required)}; missing {sorted(missing)}.\"             )         self.add(agent_frame.clone())      def step(self) -&gt; None:         \"\"\"Advance the agent set by one time step.          The update order is important: agents are first shuffled to randomise         move order (this is important only for sequential variants), then they move, harvest sugar         from their occupied cells, and finally any agents whose sugar falls         to zero or below are removed.         \"\"\"         # Randomise ordering for movement decisions when required by the         # implementation (e.g. sequential update uses this shuffle).         self.shuffle(inplace=True)         # Movement policy implemented by subclasses.         self.move()         # Agents harvest sugar on their occupied cells.         self.eat()         # Remove agents that starved after eating.         self._remove_starved()      def move(self) -&gt; None:  # pragma: no cover         \"\"\"Abstract movement method.          Subclasses must override this method to update agent positions on the         grid. Implementations should use :meth:`mesa_frames.Grid.move_agents`         or similar helpers provided by the space API.         \"\"\"         raise NotImplementedError      def eat(self) -&gt; None:         \"\"\"Agents harvest sugar from the cells they currently occupy.          Behaviour:         - Look up the set of occupied cells (cells that reference an agent           id).         - For each occupied cell, add the cell sugar to the agent's sugar           stock and subtract the agent's metabolism cost.         - After agents harvest, set the sugar on those cells to zero (they           were consumed).         \"\"\"         # Map of currently occupied agent ids on the grid.         occupied_ids = self.index         # `occupied_ids` is a Polars Series; calling `is_in` with a Series         # of the same datatype is ambiguous in newer Polars. Use `implode`         # to collapse the Series into a list-like value for membership checks.         occupied_cells = self.space.cells.filter(             pl.col(\"agent_id\").is_in(occupied_ids.implode())         )         if occupied_cells.is_empty():             return         # The agent ordering here uses the agent_id values stored in the         # occupied cells frame; indexing the agent set with that vector updates         # the matching agents' sugar values in one vectorised write.         agent_ids = occupied_cells[\"agent_id\"]         self[agent_ids, \"sugar\"] = (             self[agent_ids, \"sugar\"]             + occupied_cells[\"sugar\"]             - self[agent_ids, \"metabolism\"]         )         # After harvesting, occupied cells have zero sugar.         self.space.set_cells(             occupied_cells.select([\"dim_0\", \"dim_1\"]),             {\"sugar\": pl.Series(np.zeros(len(occupied_cells), dtype=np.int64))},         )      def _remove_starved(self) -&gt; None:         \"\"\"Discard agents whose sugar stock has fallen to zero or below.          This method performs a vectorised filter on the agent frame and         removes any matching rows from the set.         \"\"\"         starved = self.df.filter(pl.col(\"sugar\") &lt;= 0)         if not starved.is_empty():             # ``discard`` accepts a DataFrame of agents to remove.             self.discard(starved) In\u00a0[6]: Copied! <pre>class AntsSequential(AntsBase):\n    def _visible_cells(\n        self, origin: tuple[int, int], vision: int\n    ) -&gt; list[tuple[int, int]]:\n        \"\"\"List cells visible from an origin along the four cardinal axes.\n\n        The visibility set includes the origin cell itself and cells at\n        Manhattan distances 1..vision along the four cardinal directions\n        (up, down, left, right), clipped to the grid bounds.\n\n        Parameters\n        ----------\n        origin : tuple[int, int]\n            The agent's current coordinate ``(x, y)``.\n        vision : int\n            Maximum Manhattan radius to consider along each axis.\n\n        Returns\n        -------\n        list[tuple[int, int]]\n            Ordered list of visible cells (origin first, then increasing\n            step distance along each axis).\n        \"\"\"\n        x0, y0 = origin\n        width, height = self.space.dimensions\n        cells: list[tuple[int, int]] = [origin]\n        # Look outward one step at a time in the four cardinal directions.\n        for step in range(1, vision + 1):\n            if x0 + step &lt; width:\n                cells.append((x0 + step, y0))\n            if x0 - step &gt;= 0:\n                cells.append((x0 - step, y0))\n            if y0 + step &lt; height:\n                cells.append((x0, y0 + step))\n            if y0 - step &gt;= 0:\n                cells.append((x0, y0 - step))\n        return cells\n\n    def _choose_best_cell(\n        self,\n        origin: tuple[int, int],\n        vision: int,\n        sugar_map: dict[tuple[int, int], int],\n        blocked: set[tuple[int, int]] | None,\n    ) -&gt; tuple[int, int]:\n        \"\"\"Select the best visible cell according to the movement rules.\n\n        Tie-break rules (in order):\n        1. Prefer cells with strictly greater sugar.\n        2. If equal sugar, prefer the cell with smaller distance from the\n           origin (measured with the Frobenius norm returned by\n           ``space.get_distances``).\n        3. If still tied, prefer the cell with smaller coordinates (lexicographic\n           ordering of the ``(x, y)`` tuple).\n\n        Parameters\n        ----------\n        origin : tuple[int, int]\n            Agent's current coordinate.\n        vision : int\n            Maximum vision radius along cardinal axes.\n        sugar_map : dict[tuple[int, int], int]\n            Mapping from ``(x, y)`` to sugar amount.\n        blocked : set[tuple[int, int]] | None\n            Optional set of coordinates that should be considered occupied and\n            therefore skipped (except the origin which is always allowed).\n\n        Returns\n        -------\n        tuple[int, int]\n            Chosen target coordinate (may be the origin if no better cell is\n            available).\n        \"\"\"\n        best_cell = origin\n        best_sugar = sugar_map.get(origin, 0)\n        best_distance = 0\n        ox, oy = origin\n        for candidate in self._visible_cells(origin, vision):\n            # Skip blocked cells (occupied by other agents) unless it's the\n            # agent's current cell which we always consider.\n            if blocked and candidate != origin and candidate in blocked:\n                continue\n            sugar_here = sugar_map.get(candidate, 0)\n            # Use step-based Manhattan distance (number of steps along cardinal\n            # axes) which is the same metric used by the Numba path. This avoids\n            # calling the heavier `space.get_distances` per candidate.\n            cx, cy = candidate\n            distance = abs(cx - ox) + abs(cy - oy)\n            better = False\n            # Primary criterion: strictly more sugar.\n            if sugar_here &gt; best_sugar:\n                better = True\n            elif sugar_here == best_sugar:\n                # Secondary: closer distance.\n                if distance &lt; best_distance:\n                    better = True\n                # Tertiary: lexicographic tie-break on coordinates.\n                elif distance == best_distance and candidate &lt; best_cell:\n                    better = True\n            if better:\n                best_cell = candidate\n                best_sugar = sugar_here\n                best_distance = distance\n        return best_cell\n\n    def _current_sugar_map(self) -&gt; dict[tuple[int, int], int]:\n        \"\"\"Return a mapping from grid coordinates to the current sugar value.\n\n        Returns\n        -------\n        dict[tuple[int, int], int]\n            Keys are ``(x, y)`` tuples and values are the integer sugar amount\n            on that cell (zero if missing/None).\n        \"\"\"\n        cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])\n        # Build a plain Python dict for fast lookups in the movement code.\n        return {\n            (int(x), int(y)): 0 if sugar is None else int(sugar)\n            for x, y, sugar in cells.iter_rows()\n        }\n\n    def move(self) -&gt; None:\n        sugar_map = self._current_sugar_map()\n        state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")\n        positions = {\n            int(row[\"unique_id\"]): (int(row[\"dim_0\"]), int(row[\"dim_1\"]))\n            for row in state.iter_rows(named=True)\n        }\n        taken: set[tuple[int, int]] = set(positions.values())\n\n        for row in state.iter_rows(named=True):\n            agent_id = int(row[\"unique_id\"])\n            vision = int(row[\"vision\"])\n            current = positions[agent_id]\n            taken.discard(current)\n            target = self._choose_best_cell(current, vision, sugar_map, taken)\n            taken.add(target)\n            positions[agent_id] = target\n            if target != current:\n                self.space.move_agents(agent_id, target)\n</pre>   class AntsSequential(AntsBase):     def _visible_cells(         self, origin: tuple[int, int], vision: int     ) -&gt; list[tuple[int, int]]:         \"\"\"List cells visible from an origin along the four cardinal axes.          The visibility set includes the origin cell itself and cells at         Manhattan distances 1..vision along the four cardinal directions         (up, down, left, right), clipped to the grid bounds.          Parameters         ----------         origin : tuple[int, int]             The agent's current coordinate ``(x, y)``.         vision : int             Maximum Manhattan radius to consider along each axis.          Returns         -------         list[tuple[int, int]]             Ordered list of visible cells (origin first, then increasing             step distance along each axis).         \"\"\"         x0, y0 = origin         width, height = self.space.dimensions         cells: list[tuple[int, int]] = [origin]         # Look outward one step at a time in the four cardinal directions.         for step in range(1, vision + 1):             if x0 + step &lt; width:                 cells.append((x0 + step, y0))             if x0 - step &gt;= 0:                 cells.append((x0 - step, y0))             if y0 + step &lt; height:                 cells.append((x0, y0 + step))             if y0 - step &gt;= 0:                 cells.append((x0, y0 - step))         return cells      def _choose_best_cell(         self,         origin: tuple[int, int],         vision: int,         sugar_map: dict[tuple[int, int], int],         blocked: set[tuple[int, int]] | None,     ) -&gt; tuple[int, int]:         \"\"\"Select the best visible cell according to the movement rules.          Tie-break rules (in order):         1. Prefer cells with strictly greater sugar.         2. If equal sugar, prefer the cell with smaller distance from the            origin (measured with the Frobenius norm returned by            ``space.get_distances``).         3. If still tied, prefer the cell with smaller coordinates (lexicographic            ordering of the ``(x, y)`` tuple).          Parameters         ----------         origin : tuple[int, int]             Agent's current coordinate.         vision : int             Maximum vision radius along cardinal axes.         sugar_map : dict[tuple[int, int], int]             Mapping from ``(x, y)`` to sugar amount.         blocked : set[tuple[int, int]] | None             Optional set of coordinates that should be considered occupied and             therefore skipped (except the origin which is always allowed).          Returns         -------         tuple[int, int]             Chosen target coordinate (may be the origin if no better cell is             available).         \"\"\"         best_cell = origin         best_sugar = sugar_map.get(origin, 0)         best_distance = 0         ox, oy = origin         for candidate in self._visible_cells(origin, vision):             # Skip blocked cells (occupied by other agents) unless it's the             # agent's current cell which we always consider.             if blocked and candidate != origin and candidate in blocked:                 continue             sugar_here = sugar_map.get(candidate, 0)             # Use step-based Manhattan distance (number of steps along cardinal             # axes) which is the same metric used by the Numba path. This avoids             # calling the heavier `space.get_distances` per candidate.             cx, cy = candidate             distance = abs(cx - ox) + abs(cy - oy)             better = False             # Primary criterion: strictly more sugar.             if sugar_here &gt; best_sugar:                 better = True             elif sugar_here == best_sugar:                 # Secondary: closer distance.                 if distance &lt; best_distance:                     better = True                 # Tertiary: lexicographic tie-break on coordinates.                 elif distance == best_distance and candidate &lt; best_cell:                     better = True             if better:                 best_cell = candidate                 best_sugar = sugar_here                 best_distance = distance         return best_cell      def _current_sugar_map(self) -&gt; dict[tuple[int, int], int]:         \"\"\"Return a mapping from grid coordinates to the current sugar value.          Returns         -------         dict[tuple[int, int], int]             Keys are ``(x, y)`` tuples and values are the integer sugar amount             on that cell (zero if missing/None).         \"\"\"         cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])         # Build a plain Python dict for fast lookups in the movement code.         return {             (int(x), int(y)): 0 if sugar is None else int(sugar)             for x, y, sugar in cells.iter_rows()         }      def move(self) -&gt; None:         sugar_map = self._current_sugar_map()         state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")         positions = {             int(row[\"unique_id\"]): (int(row[\"dim_0\"]), int(row[\"dim_1\"]))             for row in state.iter_rows(named=True)         }         taken: set[tuple[int, int]] = set(positions.values())          for row in state.iter_rows(named=True):             agent_id = int(row[\"unique_id\"])             vision = int(row[\"vision\"])             current = positions[agent_id]             taken.discard(current)             target = self._choose_best_cell(current, vision, sugar_map, taken)             taken.add(target)             positions[agent_id] = target             if target != current:                 self.space.move_agents(agent_id, target) In\u00a0[7]: Copied! <pre>@njit(cache=True)\ndef _numba_should_replace(\n    best_sugar: int,\n    best_distance: int,\n    best_x: int,\n    best_y: int,\n    candidate_sugar: int,\n    candidate_distance: int,\n    candidate_x: int,\n    candidate_y: int,\n) -&gt; bool:\n    \"\"\"Numba helper: decide whether a candidate cell should replace the\n    current best cell according to the movement tie-break rules.\n\n    This implements the same ordering used in :meth:`_choose_best_cell` but\n    in a tightly-typed, compiled form suitable for Numba loops.\n\n    Parameters\n    ----------\n    best_sugar : int\n        Sugar at the current best cell.\n    best_distance : int\n        Manhattan distance from the origin to the current best cell.\n    best_x : int\n        X coordinate of the current best cell.\n    best_y : int\n        Y coordinate of the current best cell.\n    candidate_sugar : int\n        Sugar at the candidate cell.\n    candidate_distance : int\n        Manhattan distance from the origin to the candidate cell.\n    candidate_x : int\n        X coordinate of the candidate cell.\n    candidate_y : int\n        Y coordinate of the candidate cell.\n\n    Returns\n    -------\n    bool\n        True if the candidate should replace the current best cell.\n    \"\"\"\n    # Primary criterion: prefer strictly greater sugar.\n    if candidate_sugar &gt; best_sugar:\n        return True\n    # If sugar ties, prefer the closer cell.\n    if candidate_sugar == best_sugar:\n        if candidate_distance &lt; best_distance:\n            return True\n        # If distance ties as well, compare coordinates lexicographically.\n        if candidate_distance == best_distance:\n            if candidate_x &lt; best_x:\n                return True\n            if candidate_x == best_x and candidate_y &lt; best_y:\n                return True\n    return False\n\n\n@njit(cache=True)\ndef _numba_find_best_cell(\n    x0: int,\n    y0: int,\n    vision: int,\n    sugar_array: np.ndarray,\n    occupied: np.ndarray,\n) -&gt; tuple[int, int]:\n    width, height = sugar_array.shape\n    best_x = x0\n    best_y = y0\n    best_sugar = sugar_array[x0, y0]\n    best_distance = 0\n\n    # Examine visible cells along the four cardinal directions, increasing\n    # step by step. The 'occupied' array marks cells that are currently\n    # unavailable (True = occupied). The origin cell is allowed as the\n    # default; callers typically clear the origin before searching.\n    for step in range(1, vision + 1):\n        nx = x0 + step\n        if nx &lt; width and not occupied[nx, y0]:\n            sugar_here = sugar_array[nx, y0]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0\n            ):\n                best_x = nx\n                best_y = y0\n                best_sugar = sugar_here\n                best_distance = step\n\n        nx = x0 - step\n        if nx &gt;= 0 and not occupied[nx, y0]:\n            sugar_here = sugar_array[nx, y0]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0\n            ):\n                best_x = nx\n                best_y = y0\n                best_sugar = sugar_here\n                best_distance = step\n\n        ny = y0 + step\n        if ny &lt; height and not occupied[x0, ny]:\n            sugar_here = sugar_array[x0, ny]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny\n            ):\n                best_x = x0\n                best_y = ny\n                best_sugar = sugar_here\n                best_distance = step\n\n        ny = y0 - step\n        if ny &gt;= 0 and not occupied[x0, ny]:\n            sugar_here = sugar_array[x0, ny]\n            if _numba_should_replace(\n                best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny\n            ):\n                best_x = x0\n                best_y = ny\n                best_sugar = sugar_here\n                best_distance = step\n\n    return best_x, best_y\n\n\n@njit(cache=True)\ndef sequential_move_numba(\n    dim0: np.ndarray,\n    dim1: np.ndarray,\n    vision: np.ndarray,\n    sugar_array: np.ndarray,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Numba-accelerated sequential movement helper.\n\n    This function emulates the traditional asynchronous (sequential) update\n    where agents move one at a time in the current ordering. It accepts\n    numpy arrays describing agent positions and vision ranges, and a 2D\n    sugar array for lookup.\n\n    Parameters\n    ----------\n    dim0 : np.ndarray\n        1D integer array of length n_agents containing the x coordinates\n        for each agent.\n    dim1 : np.ndarray\n        1D integer array of length n_agents containing the y coordinates\n        for each agent.\n    vision : np.ndarray\n        1D integer array of vision radii for each agent.\n    sugar_array : np.ndarray\n        2D array shaped (width, height) containing per-cell sugar values.\n\n    Returns\n    -------\n    tuple[np.ndarray, np.ndarray]\n        Updated arrays of x and y coordinates after sequential movement.\n    \"\"\"\n    n_agents = dim0.shape[0]\n    width, height = sugar_array.shape\n    # Copy inputs to avoid mutating caller arrays in-place.\n    new_dim0 = dim0.copy()\n    new_dim1 = dim1.copy()\n    # Occupancy grid: True when a cell is currently occupied by an agent.\n    occupied = np.zeros((width, height), dtype=np.bool_)\n\n    # Mark initial occupancy.\n    for i in range(n_agents):\n        occupied[new_dim0[i], new_dim1[i]] = True\n\n    # Process agents in order. For each agent we clear its current cell in\n    # the occupancy grid (so it can consider moving into it), search for the\n    # best unoccupied visible cell, and mark the chosen destination as\n    # occupied. This models agents moving one-by-one.\n    for i in range(n_agents):\n        x0 = new_dim0[i]\n        y0 = new_dim1[i]\n        # Free the agent's current cell so it is considered available during\n        # the search (agents may choose to stay, in which case we'll re-mark\n        # it below).\n        occupied[x0, y0] = False\n        best_x, best_y = _numba_find_best_cell(\n            x0, y0, int(vision[i]), sugar_array, occupied\n        )\n        # Claim the chosen destination.\n        occupied[best_x, best_y] = True\n        new_dim0[i] = best_x\n        new_dim1[i] = best_y\n\n    return new_dim0, new_dim1\n\n\nclass AntsNumba(AntsBase):\n    def move(self) -&gt; None:\n        state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")\n        if state.is_empty():\n            return\n        agent_ids = state[\"unique_id\"]\n        dim0 = state[\"dim_0\"].to_numpy().astype(np.int64)\n        dim1 = state[\"dim_1\"].to_numpy().astype(np.int64)\n        vision = state[\"vision\"].to_numpy().astype(np.int64)\n\n        sugar_array = (\n            self.space.cells.sort([\"dim_0\", \"dim_1\"])\n            .with_columns(pl.col(\"sugar\").fill_null(0))[\"sugar\"]\n            .to_numpy()\n            .reshape(self.space.dimensions)\n        )\n\n        new_dim0, new_dim1 = sequential_move_numba(dim0, dim1, vision, sugar_array)\n        coords = pl.DataFrame({\"dim_0\": new_dim0.tolist(), \"dim_1\": new_dim1.tolist()})\n        self.space.move_agents(agent_ids, coords)\n</pre> @njit(cache=True) def _numba_should_replace(     best_sugar: int,     best_distance: int,     best_x: int,     best_y: int,     candidate_sugar: int,     candidate_distance: int,     candidate_x: int,     candidate_y: int, ) -&gt; bool:     \"\"\"Numba helper: decide whether a candidate cell should replace the     current best cell according to the movement tie-break rules.      This implements the same ordering used in :meth:`_choose_best_cell` but     in a tightly-typed, compiled form suitable for Numba loops.      Parameters     ----------     best_sugar : int         Sugar at the current best cell.     best_distance : int         Manhattan distance from the origin to the current best cell.     best_x : int         X coordinate of the current best cell.     best_y : int         Y coordinate of the current best cell.     candidate_sugar : int         Sugar at the candidate cell.     candidate_distance : int         Manhattan distance from the origin to the candidate cell.     candidate_x : int         X coordinate of the candidate cell.     candidate_y : int         Y coordinate of the candidate cell.      Returns     -------     bool         True if the candidate should replace the current best cell.     \"\"\"     # Primary criterion: prefer strictly greater sugar.     if candidate_sugar &gt; best_sugar:         return True     # If sugar ties, prefer the closer cell.     if candidate_sugar == best_sugar:         if candidate_distance &lt; best_distance:             return True         # If distance ties as well, compare coordinates lexicographically.         if candidate_distance == best_distance:             if candidate_x &lt; best_x:                 return True             if candidate_x == best_x and candidate_y &lt; best_y:                 return True     return False   @njit(cache=True) def _numba_find_best_cell(     x0: int,     y0: int,     vision: int,     sugar_array: np.ndarray,     occupied: np.ndarray, ) -&gt; tuple[int, int]:     width, height = sugar_array.shape     best_x = x0     best_y = y0     best_sugar = sugar_array[x0, y0]     best_distance = 0      # Examine visible cells along the four cardinal directions, increasing     # step by step. The 'occupied' array marks cells that are currently     # unavailable (True = occupied). The origin cell is allowed as the     # default; callers typically clear the origin before searching.     for step in range(1, vision + 1):         nx = x0 + step         if nx &lt; width and not occupied[nx, y0]:             sugar_here = sugar_array[nx, y0]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0             ):                 best_x = nx                 best_y = y0                 best_sugar = sugar_here                 best_distance = step          nx = x0 - step         if nx &gt;= 0 and not occupied[nx, y0]:             sugar_here = sugar_array[nx, y0]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, nx, y0             ):                 best_x = nx                 best_y = y0                 best_sugar = sugar_here                 best_distance = step          ny = y0 + step         if ny &lt; height and not occupied[x0, ny]:             sugar_here = sugar_array[x0, ny]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny             ):                 best_x = x0                 best_y = ny                 best_sugar = sugar_here                 best_distance = step          ny = y0 - step         if ny &gt;= 0 and not occupied[x0, ny]:             sugar_here = sugar_array[x0, ny]             if _numba_should_replace(                 best_sugar, best_distance, best_x, best_y, sugar_here, step, x0, ny             ):                 best_x = x0                 best_y = ny                 best_sugar = sugar_here                 best_distance = step      return best_x, best_y   @njit(cache=True) def sequential_move_numba(     dim0: np.ndarray,     dim1: np.ndarray,     vision: np.ndarray,     sugar_array: np.ndarray, ) -&gt; tuple[np.ndarray, np.ndarray]:     \"\"\"Numba-accelerated sequential movement helper.      This function emulates the traditional asynchronous (sequential) update     where agents move one at a time in the current ordering. It accepts     numpy arrays describing agent positions and vision ranges, and a 2D     sugar array for lookup.      Parameters     ----------     dim0 : np.ndarray         1D integer array of length n_agents containing the x coordinates         for each agent.     dim1 : np.ndarray         1D integer array of length n_agents containing the y coordinates         for each agent.     vision : np.ndarray         1D integer array of vision radii for each agent.     sugar_array : np.ndarray         2D array shaped (width, height) containing per-cell sugar values.      Returns     -------     tuple[np.ndarray, np.ndarray]         Updated arrays of x and y coordinates after sequential movement.     \"\"\"     n_agents = dim0.shape[0]     width, height = sugar_array.shape     # Copy inputs to avoid mutating caller arrays in-place.     new_dim0 = dim0.copy()     new_dim1 = dim1.copy()     # Occupancy grid: True when a cell is currently occupied by an agent.     occupied = np.zeros((width, height), dtype=np.bool_)      # Mark initial occupancy.     for i in range(n_agents):         occupied[new_dim0[i], new_dim1[i]] = True      # Process agents in order. For each agent we clear its current cell in     # the occupancy grid (so it can consider moving into it), search for the     # best unoccupied visible cell, and mark the chosen destination as     # occupied. This models agents moving one-by-one.     for i in range(n_agents):         x0 = new_dim0[i]         y0 = new_dim1[i]         # Free the agent's current cell so it is considered available during         # the search (agents may choose to stay, in which case we'll re-mark         # it below).         occupied[x0, y0] = False         best_x, best_y = _numba_find_best_cell(             x0, y0, int(vision[i]), sugar_array, occupied         )         # Claim the chosen destination.         occupied[best_x, best_y] = True         new_dim0[i] = best_x         new_dim1[i] = best_y      return new_dim0, new_dim1   class AntsNumba(AntsBase):     def move(self) -&gt; None:         state = self.df.join(self.pos, on=\"unique_id\", how=\"left\")         if state.is_empty():             return         agent_ids = state[\"unique_id\"]         dim0 = state[\"dim_0\"].to_numpy().astype(np.int64)         dim1 = state[\"dim_1\"].to_numpy().astype(np.int64)         vision = state[\"vision\"].to_numpy().astype(np.int64)          sugar_array = (             self.space.cells.sort([\"dim_0\", \"dim_1\"])             .with_columns(pl.col(\"sugar\").fill_null(0))[\"sugar\"]             .to_numpy()             .reshape(self.space.dimensions)         )          new_dim0, new_dim1 = sequential_move_numba(dim0, dim1, vision, sugar_array)         coords = pl.DataFrame({\"dim_0\": new_dim0.tolist(), \"dim_1\": new_dim1.tolist()})         self.space.move_agents(agent_ids, coords) In\u00a0[8]: Copied! <pre>class AntsParallel(AntsBase):\n    def move(self) -&gt; None:\n        \"\"\"Move agents in parallel by ranking visible cells and resolving conflicts.\n\n        Declarative mental model: express *what* each agent wants (ranked candidates),\n        then use dataframe ops to *allocate* (joins, group_by with a lottery).\n        Performance is handled by Polars/LazyFrames; avoid premature micro-optimisations.\n\n        Returns\n        -------\n        None\n            Movement updates happen in-place on the underlying space.\n        \"\"\"\n        # Early exit if there are no agents.\n        if len(self.df) == 0:\n            return\n\n        # current_pos columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_center   \u2506 dim_1_center   \u2502\n        # \u2502 ---      \u2506 ---            \u2506 ---            \u2502\n        # \u2502 u64      \u2506 i64            \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        current_pos = self.pos.select(\n            [\n                pl.col(\"unique_id\").alias(\"agent_id\"),\n                pl.col(\"dim_0\").alias(\"dim_0_center\"),\n                pl.col(\"dim_1\").alias(\"dim_1_center\"),\n            ]\n        )\n\n        neighborhood = self._build_neighborhood_frame(current_pos)\n        choices, origins, max_rank = self._rank_candidates(neighborhood, current_pos)\n        if choices.is_empty():\n            return\n\n        assigned = self._resolve_conflicts_in_rounds(choices, origins, max_rank)\n        if assigned.is_empty():\n            return\n\n        # move_df columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 unique_id  \u2506 dim_0      \u2506 dim_1      \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---        \u2502\n        # \u2502 u64        \u2506 i64        \u2506 i64        \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        move_df = pl.DataFrame(\n            {\n                \"unique_id\": assigned[\"agent_id\"],\n                \"dim_0\": assigned[\"dim_0_candidate\"],\n                \"dim_1\": assigned[\"dim_1_candidate\"],\n            }\n        )\n        # `move_agents` accepts IdsLike and SpaceCoordinates (Polars Series/DataFrame),\n        # so pass Series/DataFrame directly rather than converting to Python lists.\n        self.space.move_agents(move_df[\"unique_id\"], move_df.select([\"dim_0\", \"dim_1\"]))\n\n    def _build_neighborhood_frame(self, current_pos: pl.DataFrame) -&gt; pl.DataFrame:\n        \"\"\"Assemble the sugar-weighted neighbourhood for each sensing agent.\n\n        Parameters\n        ----------\n        current_pos : pl.DataFrame\n            DataFrame with columns ``agent_id``, ``dim_0_center`` and\n            ``dim_1_center`` describing the current position of each agent.\n\n        Returns\n        -------\n        pl.DataFrame\n            DataFrame with columns ``agent_id``, ``radius``, ``dim_0_candidate``,\n            ``dim_1_candidate`` and ``sugar`` describing the visible cells for\n            each agent.\n        \"\"\"\n        # Build a neighbourhood frame: for each agent and visible cell we\n        # attach the cell sugar. The raw offsets contain the candidate\n        # cell coordinates and the center coordinates for the sensing agent.\n        # Raw neighborhood columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0      \u2506 dim_1      \u2506 radius \u2506 dim_0_center   \u2506 dim_1_center   \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---    \u2506 ---            \u2506 ---            \u2502\n        # \u2502 i64        \u2506 i64        \u2506 i64    \u2506 i64            \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        neighborhood_cells = self.space.get_neighborhood(\n            radius=self[\"vision\"], agents=self, include_center=True\n        )\n\n        # sugar_cells columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0      \u2506 dim_1      \u2506 sugar  \u2502\n        # \u2502 ---        \u2506 ---        \u2506 ---    \u2502\n        # \u2502 i64        \u2506 i64        \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\n        sugar_cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])\n\n        neighborhood_cells = (\n            neighborhood_cells.join(sugar_cells, on=[\"dim_0\", \"dim_1\"], how=\"left\")\n            .with_columns(pl.col(\"sugar\").fill_null(0))\n            .rename({\"dim_0\": \"dim_0_candidate\", \"dim_1\": \"dim_1_candidate\"})\n        )\n\n        neighborhood_cells = neighborhood_cells.join(\n            current_pos,\n            left_on=[\"dim_0_center\", \"dim_1_center\"],\n            right_on=[\"dim_0_center\", \"dim_1_center\"],\n            how=\"left\",\n        )\n\n        # Final neighborhood columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 radius \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2502\n        # \u2502 ---      \u2506 ---    \u2506 ---              \u2506 ---              \u2506 ---    \u2502\n        # \u2502 u64      \u2506 i64    \u2506 i64              \u2506 i64              \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        neighborhood_cells = neighborhood_cells.drop(\n            [\"dim_0_center\", \"dim_1_center\"]\n        ).select([\"agent_id\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\", \"sugar\"])\n\n        return neighborhood_cells\n\n    def _rank_candidates(\n        self,\n        neighborhood: pl.DataFrame,\n        current_pos: pl.DataFrame,\n    ) -&gt; tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n        \"\"\"Rank candidate destination cells for each agent.\n\n        Parameters\n        ----------\n        neighborhood : pl.DataFrame\n            Output of :meth:`_build_neighborhood_frame` with columns\n            ``agent_id``, ``radius``, ``dim_0_candidate``, ``dim_1_candidate``\n            and ``sugar``.\n        current_pos : pl.DataFrame\n            Frame with columns ``agent_id``, ``dim_0_center`` and\n            ``dim_1_center`` describing where each agent currently stands.\n\n        Returns\n        -------\n        choices : pl.DataFrame\n            Ranked candidates per agent with columns ``agent_id``,\n            ``dim_0_candidate``, ``dim_1_candidate``, ``sugar``, ``radius`` and\n            ``rank``.\n        origins : pl.DataFrame\n            Original coordinates per agent with columns ``agent_id``,\n            ``dim_0`` and ``dim_1``.\n        max_rank : pl.DataFrame\n            Maximum available rank per agent with columns ``agent_id`` and\n            ``max_rank``.\n        \"\"\"\n        # Create ranked choices per agent: sort by sugar (desc), radius\n        # (asc), then coordinates. Keep the first unique entry per cell.\n        # choices columns (after select):\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2502\n        # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2502\n        # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        choices = (\n            neighborhood.select(\n                [\n                    \"agent_id\",\n                    \"dim_0_candidate\",\n                    \"dim_1_candidate\",\n                    \"sugar\",\n                    \"radius\",\n                ]\n            )\n            .with_columns(pl.col(\"radius\"))\n            .sort(\n                [\"agent_id\", \"sugar\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\"],\n                descending=[False, True, False, False, False],\n            )\n            .unique(\n                subset=[\"agent_id\", \"dim_0_candidate\", \"dim_1_candidate\"],\n                keep=\"first\",\n                maintain_order=True,\n            )\n            .with_columns(pl.col(\"agent_id\").cum_count().over(\"agent_id\").alias(\"rank\"))\n        )\n\n        # Precompute per\u2011agent candidate rank once so conflict resolution can\n        # promote losers by incrementing a cheap `current_rank` counter,\n        # without re-sorting after each round. Alternative: drop taken cells\n        # and re-rank by sugar every round; simpler conceptually but requires\n        # repeated sorts and deduplication, which is heavier than filtering by\n        # `rank &gt;= current_rank`.\n\n        # Origins for fallback (if an agent exhausts candidates it stays put).\n        # origins columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2502\n        # \u2502 ---      \u2506 ---        \u2506 ---        \u2502\n        # \u2502 u64      \u2506 i64        \u2506 i64        \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        origins = current_pos.select(\n            [\n                \"agent_id\",\n                pl.col(\"dim_0_center\").alias(\"dim_0\"),\n                pl.col(\"dim_1_center\").alias(\"dim_1\"),\n            ]\n        )\n\n        # Track the maximum available rank per agent to clamp promotions.\n        # This bounds `current_rank`; once an agent reaches `max_rank` and\n        # cannot secure a cell, they fall back to origin cleanly instead of\n        # chasing nonexistent ranks.\n        # max_rank columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 max_rank \u2502\n        # \u2502 ---      \u2506 ---       \u2502\n        # \u2502 u64      \u2506 u32       \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        max_rank = choices.group_by(\"agent_id\").agg(\n            pl.col(\"rank\").max().alias(\"max_rank\")\n        )\n        return choices, origins, max_rank\n\n    def _resolve_conflicts_in_rounds(\n        self,\n        choices: pl.DataFrame,\n        origins: pl.DataFrame,\n        max_rank: pl.DataFrame,\n    ) -&gt; pl.DataFrame:\n        \"\"\"Resolve movement conflicts through iterative lottery rounds.\n\n        Parameters\n        ----------\n        choices : pl.DataFrame\n            Ranked candidate cells per agent with headers matching the\n            ``choices`` frame returned by :meth:`_rank_candidates`.\n        origins : pl.DataFrame\n            Agent origin coordinates with columns ``agent_id``, ``dim_0`` and\n            ``dim_1``.\n        max_rank : pl.DataFrame\n            Maximum rank offset per agent with columns ``agent_id`` and\n            ``max_rank``.\n\n        Returns\n        -------\n        pl.DataFrame\n            Allocated movements with columns ``agent_id``, ``dim_0_candidate``\n            and ``dim_1_candidate``; each row records the destination assigned\n            to an agent.\n        \"\"\"\n        # Prepare unresolved agents and working tables.\n        agent_ids = choices[\"agent_id\"].unique(maintain_order=True)\n\n        # unresolved columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 current_rank  \u2502\n        # \u2502 ---      \u2506 ---            \u2502\n        # \u2502 u64      \u2506 i64            \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        unresolved = pl.DataFrame(\n            {\n                \"agent_id\": agent_ids,\n                \"current_rank\": pl.Series(np.zeros(len(agent_ids), dtype=np.int64)),\n            }\n        )\n\n        # assigned columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2502\n        # \u2502 ---      \u2506 ---              \u2506 ---              \u2502\n        # \u2502 u64      \u2506 i64              \u2506 i64              \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        assigned = pl.DataFrame(\n            {\n                \"agent_id\": pl.Series(\n                    name=\"agent_id\", values=[], dtype=agent_ids.dtype\n                ),\n                \"dim_0_candidate\": pl.Series(\n                    name=\"dim_0_candidate\", values=[], dtype=pl.Int64\n                ),\n                \"dim_1_candidate\": pl.Series(\n                    name=\"dim_1_candidate\", values=[], dtype=pl.Int64\n                ),\n            }\n        )\n\n        # taken columns:\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 dim_0_candidate  \u2506 dim_1_candidate  \u2502\n        # \u2502 ---              \u2506 ---              \u2502\n        # \u2502 i64              \u2506 i64              \u2502\n        # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        taken = pl.DataFrame(\n            {\n                \"dim_0_candidate\": pl.Series(\n                    name=\"dim_0_candidate\", values=[], dtype=pl.Int64\n                ),\n                \"dim_1_candidate\": pl.Series(\n                    name=\"dim_1_candidate\", values=[], dtype=pl.Int64\n                ),\n            }\n        )\n\n        # Resolve in rounds: each unresolved agent proposes its current-ranked\n        # candidate; winners per-cell are selected at random and losers are\n        # promoted to their next choice.\n        while unresolved.height &gt; 0:\n            # Using precomputed `rank` lets us select candidates with\n            # `rank &gt;= current_rank` and avoid re-ranking after each round.\n            # Alternative: remove taken cells and re-sort remaining candidates\n            # by sugar/distance per round (heavier due to repeated sort/dedupe).\n            # candidate_pool columns (after join with unresolved):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            candidate_pool = choices.join(unresolved, on=\"agent_id\")\n            candidate_pool = candidate_pool.filter(\n                pl.col(\"rank\") &gt;= pl.col(\"current_rank\")\n            )\n            if not taken.is_empty():\n                candidate_pool = candidate_pool.join(\n                    taken,\n                    on=[\"dim_0_candidate\", \"dim_1_candidate\"],\n                    how=\"anti\",\n                )\n\n            if candidate_pool.is_empty():\n                # No available candidates \u2014 everyone falls back to origin.\n                # Note: this covers both agents with no visible cells left and\n                # the case where all remaining candidates are already taken.\n                # fallback columns:\n                # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2506 current_rank \u2502\n                # \u2502 ---      \u2506 ---        \u2506 ---        \u2506 ---          \u2502\n                # \u2502 u64      \u2506 i64        \u2506 i64        \u2506 i64          \u2502\n                # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n                fallback = unresolved.join(origins, on=\"agent_id\", how=\"left\")\n                assigned = pl.concat(\n                    [\n                        assigned,\n                        fallback.select(\n                            [\n                                \"agent_id\",\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                break\n\n            # best_candidates columns (per agent first choice):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            best_candidates = (\n                candidate_pool.sort([\"agent_id\", \"rank\"])\n                .group_by(\"agent_id\", maintain_order=True)\n                .first()\n            )\n\n            # Agents that had no candidate this round fall back to origin.\n            # missing columns:\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 current_rank \u2502\n            # \u2502 ---      \u2506 ---          \u2502\n            # \u2502 u64      \u2506 i64          \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            missing = unresolved.join(\n                best_candidates.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n            )\n            if not missing.is_empty():\n                # fallback (missing) columns match fallback table above.\n                fallback = missing.join(origins, on=\"agent_id\", how=\"left\")\n                assigned = pl.concat(\n                    [\n                        assigned,\n                        fallback.select(\n                            [\n                                \"agent_id\",\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                taken = pl.concat(\n                    [\n                        taken,\n                        fallback.select(\n                            [\n                                pl.col(\"dim_0\").alias(\"dim_0_candidate\"),\n                                pl.col(\"dim_1\").alias(\"dim_1_candidate\"),\n                            ]\n                        ),\n                    ],\n                    how=\"vertical\",\n                )\n                unresolved = unresolved.join(\n                    missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n                )\n                best_candidates = best_candidates.join(\n                    missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"\n                )\n                if unresolved.is_empty() or best_candidates.is_empty():\n                    continue\n\n            # Add a small random lottery to break ties deterministically for\n            # each candidate set.\n            lottery = pl.Series(\"lottery\", self.random.random(best_candidates.height))\n            best_candidates = best_candidates.with_columns(lottery)\n\n            # winners columns:\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502 lottery \u2502\n            # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2506 ---     \u2502\n            # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2506 f64     \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            winners = (\n                best_candidates.sort([\"dim_0_candidate\", \"dim_1_candidate\", \"lottery\"])\n                .group_by([\"dim_0_candidate\", \"dim_1_candidate\"], maintain_order=True)\n                .first()\n            )\n\n            assigned = pl.concat(\n                [\n                    assigned,\n                    winners.select(\n                        [\n                            \"agent_id\",\n                            pl.col(\"dim_0_candidate\"),\n                            pl.col(\"dim_1_candidate\"),\n                        ]\n                    ),\n                ],\n                how=\"vertical\",\n            )\n            taken = pl.concat(\n                [\n                    taken,\n                    winners.select([\"dim_0_candidate\", \"dim_1_candidate\"]),\n                ],\n                how=\"vertical\",\n            )\n\n            winner_ids = winners.select(\"agent_id\")\n            unresolved = unresolved.join(winner_ids, on=\"agent_id\", how=\"anti\")\n            if unresolved.is_empty():\n                break\n\n            # loser candidates columns mirror best_candidates (minus winners).\n            losers = best_candidates.join(winner_ids, on=\"agent_id\", how=\"anti\")\n            if losers.is_empty():\n                continue\n\n            # loser_updates columns (after select):\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 agent_id \u2506 next_rank \u2502\n            # \u2502 ---      \u2506 ---       \u2502\n            # \u2502 u64      \u2506 i64       \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            loser_updates = (\n                losers.select(\n                    \"agent_id\",\n                    (pl.col(\"rank\") + 1).cast(pl.Int64).alias(\"next_rank\"),\n                )\n                .join(max_rank, on=\"agent_id\", how=\"left\")\n                .with_columns(\n                    pl.min_horizontal(pl.col(\"next_rank\"), pl.col(\"max_rank\")).alias(\n                        \"next_rank\"\n                    )\n                )\n                .select([\"agent_id\", \"next_rank\"])\n            )\n\n            # Promote losers' current_rank (if any) and continue.\n            # unresolved (updated) retains columns agent_id/current_rank.\n            unresolved = (\n                unresolved.join(loser_updates, on=\"agent_id\", how=\"left\")\n                .with_columns(\n                    pl.when(pl.col(\"next_rank\").is_not_null())\n                    .then(pl.col(\"next_rank\"))\n                    .otherwise(pl.col(\"current_rank\"))\n                    .alias(\"current_rank\")\n                )\n                .drop(\"next_rank\")\n            )\n\n        return assigned\n</pre>   class AntsParallel(AntsBase):     def move(self) -&gt; None:         \"\"\"Move agents in parallel by ranking visible cells and resolving conflicts.          Declarative mental model: express *what* each agent wants (ranked candidates),         then use dataframe ops to *allocate* (joins, group_by with a lottery).         Performance is handled by Polars/LazyFrames; avoid premature micro-optimisations.          Returns         -------         None             Movement updates happen in-place on the underlying space.         \"\"\"         # Early exit if there are no agents.         if len(self.df) == 0:             return          # current_pos columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_center   \u2506 dim_1_center   \u2502         # \u2502 ---      \u2506 ---            \u2506 ---            \u2502         # \u2502 u64      \u2506 i64            \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         current_pos = self.pos.select(             [                 pl.col(\"unique_id\").alias(\"agent_id\"),                 pl.col(\"dim_0\").alias(\"dim_0_center\"),                 pl.col(\"dim_1\").alias(\"dim_1_center\"),             ]         )          neighborhood = self._build_neighborhood_frame(current_pos)         choices, origins, max_rank = self._rank_candidates(neighborhood, current_pos)         if choices.is_empty():             return          assigned = self._resolve_conflicts_in_rounds(choices, origins, max_rank)         if assigned.is_empty():             return          # move_df columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 unique_id  \u2506 dim_0      \u2506 dim_1      \u2502         # \u2502 ---        \u2506 ---        \u2506 ---        \u2502         # \u2502 u64        \u2506 i64        \u2506 i64        \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         move_df = pl.DataFrame(             {                 \"unique_id\": assigned[\"agent_id\"],                 \"dim_0\": assigned[\"dim_0_candidate\"],                 \"dim_1\": assigned[\"dim_1_candidate\"],             }         )         # `move_agents` accepts IdsLike and SpaceCoordinates (Polars Series/DataFrame),         # so pass Series/DataFrame directly rather than converting to Python lists.         self.space.move_agents(move_df[\"unique_id\"], move_df.select([\"dim_0\", \"dim_1\"]))      def _build_neighborhood_frame(self, current_pos: pl.DataFrame) -&gt; pl.DataFrame:         \"\"\"Assemble the sugar-weighted neighbourhood for each sensing agent.          Parameters         ----------         current_pos : pl.DataFrame             DataFrame with columns ``agent_id``, ``dim_0_center`` and             ``dim_1_center`` describing the current position of each agent.          Returns         -------         pl.DataFrame             DataFrame with columns ``agent_id``, ``radius``, ``dim_0_candidate``,             ``dim_1_candidate`` and ``sugar`` describing the visible cells for             each agent.         \"\"\"         # Build a neighbourhood frame: for each agent and visible cell we         # attach the cell sugar. The raw offsets contain the candidate         # cell coordinates and the center coordinates for the sensing agent.         # Raw neighborhood columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0      \u2506 dim_1      \u2506 radius \u2506 dim_0_center   \u2506 dim_1_center   \u2502         # \u2502 ---        \u2506 ---        \u2506 ---    \u2506 ---            \u2506 ---            \u2502         # \u2502 i64        \u2506 i64        \u2506 i64    \u2506 i64            \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         neighborhood_cells = self.space.get_neighborhood(             radius=self[\"vision\"], agents=self, include_center=True         )          # sugar_cells columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0      \u2506 dim_1      \u2506 sugar  \u2502         # \u2502 ---        \u2506 ---        \u2506 ---    \u2502         # \u2502 i64        \u2506 i64        \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561          sugar_cells = self.space.cells.select([\"dim_0\", \"dim_1\", \"sugar\"])          neighborhood_cells = (             neighborhood_cells.join(sugar_cells, on=[\"dim_0\", \"dim_1\"], how=\"left\")             .with_columns(pl.col(\"sugar\").fill_null(0))             .rename({\"dim_0\": \"dim_0_candidate\", \"dim_1\": \"dim_1_candidate\"})         )          neighborhood_cells = neighborhood_cells.join(             current_pos,             left_on=[\"dim_0_center\", \"dim_1_center\"],             right_on=[\"dim_0_center\", \"dim_1_center\"],             how=\"left\",         )          # Final neighborhood columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 radius \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2502         # \u2502 ---      \u2506 ---    \u2506 ---              \u2506 ---              \u2506 ---    \u2502         # \u2502 u64      \u2506 i64    \u2506 i64              \u2506 i64              \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         neighborhood_cells = neighborhood_cells.drop(             [\"dim_0_center\", \"dim_1_center\"]         ).select([\"agent_id\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\", \"sugar\"])          return neighborhood_cells      def _rank_candidates(         self,         neighborhood: pl.DataFrame,         current_pos: pl.DataFrame,     ) -&gt; tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:         \"\"\"Rank candidate destination cells for each agent.          Parameters         ----------         neighborhood : pl.DataFrame             Output of :meth:`_build_neighborhood_frame` with columns             ``agent_id``, ``radius``, ``dim_0_candidate``, ``dim_1_candidate``             and ``sugar``.         current_pos : pl.DataFrame             Frame with columns ``agent_id``, ``dim_0_center`` and             ``dim_1_center`` describing where each agent currently stands.          Returns         -------         choices : pl.DataFrame             Ranked candidates per agent with columns ``agent_id``,             ``dim_0_candidate``, ``dim_1_candidate``, ``sugar``, ``radius`` and             ``rank``.         origins : pl.DataFrame             Original coordinates per agent with columns ``agent_id``,             ``dim_0`` and ``dim_1``.         max_rank : pl.DataFrame             Maximum available rank per agent with columns ``agent_id`` and             ``max_rank``.         \"\"\"         # Create ranked choices per agent: sort by sugar (desc), radius         # (asc), then coordinates. Keep the first unique entry per cell.         # choices columns (after select):         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2502         # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2502         # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         choices = (             neighborhood.select(                 [                     \"agent_id\",                     \"dim_0_candidate\",                     \"dim_1_candidate\",                     \"sugar\",                     \"radius\",                 ]             )             .with_columns(pl.col(\"radius\"))             .sort(                 [\"agent_id\", \"sugar\", \"radius\", \"dim_0_candidate\", \"dim_1_candidate\"],                 descending=[False, True, False, False, False],             )             .unique(                 subset=[\"agent_id\", \"dim_0_candidate\", \"dim_1_candidate\"],                 keep=\"first\",                 maintain_order=True,             )             .with_columns(pl.col(\"agent_id\").cum_count().over(\"agent_id\").alias(\"rank\"))         )          # Precompute per\u2011agent candidate rank once so conflict resolution can         # promote losers by incrementing a cheap `current_rank` counter,         # without re-sorting after each round. Alternative: drop taken cells         # and re-rank by sugar every round; simpler conceptually but requires         # repeated sorts and deduplication, which is heavier than filtering by         # `rank &gt;= current_rank`.          # Origins for fallback (if an agent exhausts candidates it stays put).         # origins columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2502         # \u2502 ---      \u2506 ---        \u2506 ---        \u2502         # \u2502 u64      \u2506 i64        \u2506 i64        \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         origins = current_pos.select(             [                 \"agent_id\",                 pl.col(\"dim_0_center\").alias(\"dim_0\"),                 pl.col(\"dim_1_center\").alias(\"dim_1\"),             ]         )          # Track the maximum available rank per agent to clamp promotions.         # This bounds `current_rank`; once an agent reaches `max_rank` and         # cannot secure a cell, they fall back to origin cleanly instead of         # chasing nonexistent ranks.         # max_rank columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 max_rank \u2502         # \u2502 ---      \u2506 ---       \u2502         # \u2502 u64      \u2506 u32       \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         max_rank = choices.group_by(\"agent_id\").agg(             pl.col(\"rank\").max().alias(\"max_rank\")         )         return choices, origins, max_rank      def _resolve_conflicts_in_rounds(         self,         choices: pl.DataFrame,         origins: pl.DataFrame,         max_rank: pl.DataFrame,     ) -&gt; pl.DataFrame:         \"\"\"Resolve movement conflicts through iterative lottery rounds.          Parameters         ----------         choices : pl.DataFrame             Ranked candidate cells per agent with headers matching the             ``choices`` frame returned by :meth:`_rank_candidates`.         origins : pl.DataFrame             Agent origin coordinates with columns ``agent_id``, ``dim_0`` and             ``dim_1``.         max_rank : pl.DataFrame             Maximum rank offset per agent with columns ``agent_id`` and             ``max_rank``.          Returns         -------         pl.DataFrame             Allocated movements with columns ``agent_id``, ``dim_0_candidate``             and ``dim_1_candidate``; each row records the destination assigned             to an agent.         \"\"\"         # Prepare unresolved agents and working tables.         agent_ids = choices[\"agent_id\"].unique(maintain_order=True)          # unresolved columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 current_rank  \u2502         # \u2502 ---      \u2506 ---            \u2502         # \u2502 u64      \u2506 i64            \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         unresolved = pl.DataFrame(             {                 \"agent_id\": agent_ids,                 \"current_rank\": pl.Series(np.zeros(len(agent_ids), dtype=np.int64)),             }         )          # assigned columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2502         # \u2502 ---      \u2506 ---              \u2506 ---              \u2502         # \u2502 u64      \u2506 i64              \u2506 i64              \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         assigned = pl.DataFrame(             {                 \"agent_id\": pl.Series(                     name=\"agent_id\", values=[], dtype=agent_ids.dtype                 ),                 \"dim_0_candidate\": pl.Series(                     name=\"dim_0_candidate\", values=[], dtype=pl.Int64                 ),                 \"dim_1_candidate\": pl.Series(                     name=\"dim_1_candidate\", values=[], dtype=pl.Int64                 ),             }         )          # taken columns:         # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         # \u2502 dim_0_candidate  \u2506 dim_1_candidate  \u2502         # \u2502 ---              \u2506 ---              \u2502         # \u2502 i64              \u2506 i64              \u2502         # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561         taken = pl.DataFrame(             {                 \"dim_0_candidate\": pl.Series(                     name=\"dim_0_candidate\", values=[], dtype=pl.Int64                 ),                 \"dim_1_candidate\": pl.Series(                     name=\"dim_1_candidate\", values=[], dtype=pl.Int64                 ),             }         )          # Resolve in rounds: each unresolved agent proposes its current-ranked         # candidate; winners per-cell are selected at random and losers are         # promoted to their next choice.         while unresolved.height &gt; 0:             # Using precomputed `rank` lets us select candidates with             # `rank &gt;= current_rank` and avoid re-ranking after each round.             # Alternative: remove taken cells and re-sort remaining candidates             # by sugar/distance per round (heavier due to repeated sort/dedupe).             # candidate_pool columns (after join with unresolved):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             candidate_pool = choices.join(unresolved, on=\"agent_id\")             candidate_pool = candidate_pool.filter(                 pl.col(\"rank\") &gt;= pl.col(\"current_rank\")             )             if not taken.is_empty():                 candidate_pool = candidate_pool.join(                     taken,                     on=[\"dim_0_candidate\", \"dim_1_candidate\"],                     how=\"anti\",                 )              if candidate_pool.is_empty():                 # No available candidates \u2014 everyone falls back to origin.                 # Note: this covers both agents with no visible cells left and                 # the case where all remaining candidates are already taken.                 # fallback columns:                 # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 # \u2502 agent_id \u2506 dim_0      \u2506 dim_1      \u2506 current_rank \u2502                 # \u2502 ---      \u2506 ---        \u2506 ---        \u2506 ---          \u2502                 # \u2502 u64      \u2506 i64        \u2506 i64        \u2506 i64          \u2502                 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561                 fallback = unresolved.join(origins, on=\"agent_id\", how=\"left\")                 assigned = pl.concat(                     [                         assigned,                         fallback.select(                             [                                 \"agent_id\",                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 break              # best_candidates columns (per agent first choice):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             best_candidates = (                 candidate_pool.sort([\"agent_id\", \"rank\"])                 .group_by(\"agent_id\", maintain_order=True)                 .first()             )              # Agents that had no candidate this round fall back to origin.             # missing columns:             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 current_rank \u2502             # \u2502 ---      \u2506 ---          \u2502             # \u2502 u64      \u2506 i64          \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             missing = unresolved.join(                 best_candidates.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"             )             if not missing.is_empty():                 # fallback (missing) columns match fallback table above.                 fallback = missing.join(origins, on=\"agent_id\", how=\"left\")                 assigned = pl.concat(                     [                         assigned,                         fallback.select(                             [                                 \"agent_id\",                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 taken = pl.concat(                     [                         taken,                         fallback.select(                             [                                 pl.col(\"dim_0\").alias(\"dim_0_candidate\"),                                 pl.col(\"dim_1\").alias(\"dim_1_candidate\"),                             ]                         ),                     ],                     how=\"vertical\",                 )                 unresolved = unresolved.join(                     missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"                 )                 best_candidates = best_candidates.join(                     missing.select(\"agent_id\"), on=\"agent_id\", how=\"anti\"                 )                 if unresolved.is_empty() or best_candidates.is_empty():                     continue              # Add a small random lottery to break ties deterministically for             # each candidate set.             lottery = pl.Series(\"lottery\", self.random.random(best_candidates.height))             best_candidates = best_candidates.with_columns(lottery)              # winners columns:             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 dim_0_candidate  \u2506 dim_1_candidate  \u2506 sugar  \u2506 radius \u2506 rank \u2506 current_rank \u2502 lottery \u2502             # \u2502 ---      \u2506 ---              \u2506 ---              \u2506 ---    \u2506 ---    \u2506 ---  \u2506 ---          \u2506 ---     \u2502             # \u2502 u64      \u2506 i64              \u2506 i64              \u2506 i64    \u2506 i64    \u2506 u32  \u2506 i64          \u2506 f64     \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             winners = (                 best_candidates.sort([\"dim_0_candidate\", \"dim_1_candidate\", \"lottery\"])                 .group_by([\"dim_0_candidate\", \"dim_1_candidate\"], maintain_order=True)                 .first()             )              assigned = pl.concat(                 [                     assigned,                     winners.select(                         [                             \"agent_id\",                             pl.col(\"dim_0_candidate\"),                             pl.col(\"dim_1_candidate\"),                         ]                     ),                 ],                 how=\"vertical\",             )             taken = pl.concat(                 [                     taken,                     winners.select([\"dim_0_candidate\", \"dim_1_candidate\"]),                 ],                 how=\"vertical\",             )              winner_ids = winners.select(\"agent_id\")             unresolved = unresolved.join(winner_ids, on=\"agent_id\", how=\"anti\")             if unresolved.is_empty():                 break              # loser candidates columns mirror best_candidates (minus winners).             losers = best_candidates.join(winner_ids, on=\"agent_id\", how=\"anti\")             if losers.is_empty():                 continue              # loser_updates columns (after select):             # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             # \u2502 agent_id \u2506 next_rank \u2502             # \u2502 ---      \u2506 ---       \u2502             # \u2502 u64      \u2506 i64       \u2502             # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561             loser_updates = (                 losers.select(                     \"agent_id\",                     (pl.col(\"rank\") + 1).cast(pl.Int64).alias(\"next_rank\"),                 )                 .join(max_rank, on=\"agent_id\", how=\"left\")                 .with_columns(                     pl.min_horizontal(pl.col(\"next_rank\"), pl.col(\"max_rank\")).alias(                         \"next_rank\"                     )                 )                 .select([\"agent_id\", \"next_rank\"])             )              # Promote losers' current_rank (if any) and continue.             # unresolved (updated) retains columns agent_id/current_rank.             unresolved = (                 unresolved.join(loser_updates, on=\"agent_id\", how=\"left\")                 .with_columns(                     pl.when(pl.col(\"next_rank\").is_not_null())                     .then(pl.col(\"next_rank\"))                     .otherwise(pl.col(\"current_rank\"))                     .alias(\"current_rank\")                 )                 .drop(\"next_rank\")             )          return assigned In\u00a0[9]: Copied! <pre>GRID_WIDTH = 40\nGRID_HEIGHT = 40\nNUM_AGENTS = 400\nMODEL_STEPS = 60\nMAX_SUGAR = 4\nSEED = 42\n\n\ndef run_variant(\n    agent_cls: type[AntsBase],\n    *,\n    steps: int,\n    seed: int,\n) -&gt; tuple[Sugarscape, float]:\n    model = Sugarscape(\n        agent_type=agent_cls,\n        n_agents=NUM_AGENTS,\n        width=GRID_WIDTH,\n        height=GRID_HEIGHT,\n        max_sugar=MAX_SUGAR,\n        seed=seed,\n    )\n    start = perf_counter()\n    model.run(steps)\n    return model, perf_counter() - start\n\n\nvariant_specs: dict[str, type[AntsBase]] = {\n    \"Sequential (Python loop)\": AntsSequential,\n    \"Sequential (Numba)\": AntsNumba,\n    \"Parallel (Polars)\": AntsParallel,\n}\n\nmodels: dict[str, Sugarscape] = {}\nframes: dict[str, pl.DataFrame] = {}\nruntimes: dict[str, float] = {}\n\nfor variant_name, agent_cls in variant_specs.items():\n    model, runtime = run_variant(agent_cls, steps=MODEL_STEPS, seed=SEED)\n    models[variant_name] = model\n    frames[variant_name] = model.datacollector.data[\"model\"]\n    runtimes[variant_name] = runtime\n\n    print(f\"{variant_name} aggregate trajectory (last 5 steps):\")\n    print(\n        frames[variant_name]\n        .select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"])\n        .tail(5)\n    )\n    print(f\"{variant_name} runtime: {runtime:.3f} s\")\n    print()\n\nruntime_table = (\n    pl.DataFrame(\n        [\n            {\n                \"update_rule\": variant_name,\n                \"runtime_seconds\": runtimes.get(variant_name, float(\"nan\")),\n            }\n            for variant_name in variant_specs.keys()\n        ]\n    )\n    .with_columns(pl.col(\"runtime_seconds\").round(4))\n    .sort(\"runtime_seconds\", descending=False, nulls_last=True)\n)\n\nprint(\"Runtime comparison (fastest first):\")\nprint(runtime_table)\n\n# Access models/frames on demand; keep namespace minimal.\nnumba_model_frame = frames.get(\"Sequential (Numba)\", pl.DataFrame())\npar_model_frame = frames.get(\"Parallel (Polars)\", pl.DataFrame())\n</pre>  GRID_WIDTH = 40 GRID_HEIGHT = 40 NUM_AGENTS = 400 MODEL_STEPS = 60 MAX_SUGAR = 4 SEED = 42   def run_variant(     agent_cls: type[AntsBase],     *,     steps: int,     seed: int, ) -&gt; tuple[Sugarscape, float]:     model = Sugarscape(         agent_type=agent_cls,         n_agents=NUM_AGENTS,         width=GRID_WIDTH,         height=GRID_HEIGHT,         max_sugar=MAX_SUGAR,         seed=seed,     )     start = perf_counter()     model.run(steps)     return model, perf_counter() - start   variant_specs: dict[str, type[AntsBase]] = {     \"Sequential (Python loop)\": AntsSequential,     \"Sequential (Numba)\": AntsNumba,     \"Parallel (Polars)\": AntsParallel, }  models: dict[str, Sugarscape] = {} frames: dict[str, pl.DataFrame] = {} runtimes: dict[str, float] = {}  for variant_name, agent_cls in variant_specs.items():     model, runtime = run_variant(agent_cls, steps=MODEL_STEPS, seed=SEED)     models[variant_name] = model     frames[variant_name] = model.datacollector.data[\"model\"]     runtimes[variant_name] = runtime      print(f\"{variant_name} aggregate trajectory (last 5 steps):\")     print(         frames[variant_name]         .select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"])         .tail(5)     )     print(f\"{variant_name} runtime: {runtime:.3f} s\")     print()  runtime_table = (     pl.DataFrame(         [             {                 \"update_rule\": variant_name,                 \"runtime_seconds\": runtimes.get(variant_name, float(\"nan\")),             }             for variant_name in variant_specs.keys()         ]     )     .with_columns(pl.col(\"runtime_seconds\").round(4))     .sort(\"runtime_seconds\", descending=False, nulls_last=True) )  print(\"Runtime comparison (fastest first):\") print(runtime_table)  # Access models/frames on demand; keep namespace minimal. numba_model_frame = frames.get(\"Sequential (Numba)\", pl.DataFrame()) par_model_frame = frames.get(\"Parallel (Polars)\", pl.DataFrame()) <pre>Sequential (Python loop) aggregate trajectory (last 5 steps):\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_sugar \u2506 total_sugar \u2506 agents_alive \u2502\n\u2502 ---  \u2506 ---        \u2506 ---         \u2506 ---          \u2502\n\u2502 i64  \u2506 f64        \u2506 f64         \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 56   \u2506 63.613169  \u2506 15458.0     \u2506 243.0        \u2502\n\u2502 57   \u2506 64.563786  \u2506 15689.0     \u2506 243.0        \u2502\n\u2502 58   \u2506 65.493827  \u2506 15915.0     \u2506 243.0        \u2502\n\u2502 59   \u2506 66.826446  \u2506 16172.0     \u2506 242.0        \u2502\n\u2502 60   \u2506 68.06639   \u2506 16404.0     \u2506 241.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nSequential (Python loop) runtime: 51.904 s\n\n</pre> <pre>Sequential (Numba) aggregate trajectory (last 5 steps):\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_sugar \u2506 total_sugar \u2506 agents_alive \u2502\n\u2502 ---  \u2506 ---        \u2506 ---         \u2506 ---          \u2502\n\u2502 i64  \u2506 f64        \u2506 f64         \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 56   \u2506 63.613169  \u2506 15458.0     \u2506 243.0        \u2502\n\u2502 57   \u2506 64.563786  \u2506 15689.0     \u2506 243.0        \u2502\n\u2502 58   \u2506 65.493827  \u2506 15915.0     \u2506 243.0        \u2502\n\u2502 59   \u2506 66.826446  \u2506 16172.0     \u2506 242.0        \u2502\n\u2502 60   \u2506 68.06639   \u2506 16404.0     \u2506 241.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nSequential (Numba) runtime: 1.164 s\n\n</pre> <pre>Parallel (Polars) aggregate trajectory (last 5 steps):\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_sugar \u2506 total_sugar \u2506 agents_alive \u2502\n\u2502 ---  \u2506 ---        \u2506 ---         \u2506 ---          \u2502\n\u2502 i64  \u2506 f64        \u2506 f64         \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 56   \u2506 60.059055  \u2506 15255.0     \u2506 254.0        \u2502\n\u2502 57   \u2506 60.976378  \u2506 15488.0     \u2506 254.0        \u2502\n\u2502 58   \u2506 61.866142  \u2506 15714.0     \u2506 254.0        \u2502\n\u2502 59   \u2506 63.007905  \u2506 15941.0     \u2506 253.0        \u2502\n\u2502 60   \u2506 63.881423  \u2506 16162.0     \u2506 253.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nParallel (Polars) runtime: 1.950 s\n\nRuntime comparison (fastest first):\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 update_rule              \u2506 runtime_seconds \u2502\n\u2502 ---                      \u2506 ---             \u2502\n\u2502 str                      \u2506 f64             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Sequential (Numba)       \u2506 1.1637          \u2502\n\u2502 Parallel (Polars)        \u2506 1.9501          \u2502\n\u2502 Sequential (Python loop) \u2506 51.9035         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[10]: Copied! <pre>comparison = numba_model_frame.select(\n    [\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]\n).join(\n    par_model_frame.select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]),\n    on=\"step\",\n    how=\"inner\",\n    suffix=\"_parallel\",\n)\ncomparison = comparison.with_columns(\n    (pl.col(\"mean_sugar\") - pl.col(\"mean_sugar_parallel\")).abs().alias(\"mean_diff\"),\n    (pl.col(\"total_sugar\") - pl.col(\"total_sugar_parallel\")).abs().alias(\"total_diff\"),\n    (pl.col(\"agents_alive\") - pl.col(\"agents_alive_parallel\"))\n    .abs()\n    .alias(\"count_diff\"),\n)\nprint(\"Step-level absolute differences (first 10 steps):\")\nprint(comparison.select([\"step\", \"mean_diff\", \"total_diff\", \"count_diff\"]).head(10))\n\n\n# Build the steady\u2011state metrics table from the DataCollector output rather than\n# recomputing reporters directly on the model objects. The collector already\n# stored the model\u2011level reporters (gini, correlations, etc.) every step.\ndef _last_row(df: pl.DataFrame) -&gt; pl.DataFrame:\n    if df.is_empty():\n        return df\n    # Ensure we take the final time step in case steps &lt; MODEL_STEPS due to extinction.\n    return df.sort(\"step\").tail(1)\n\n\nnumba_last = _last_row(frames.get(\"Sequential (Numba)\", pl.DataFrame()))\nparallel_last = _last_row(frames.get(\"Parallel (Polars)\", pl.DataFrame()))\n\nmetrics_pieces: list[pl.DataFrame] = []\nif not numba_last.is_empty():\n    metrics_pieces.append(\n        numba_last.select(\n            [\n                pl.lit(\"Sequential (Numba)\").alias(\"update_rule\"),\n                \"gini\",\n                \"corr_sugar_metabolism\",\n                \"corr_sugar_vision\",\n                pl.col(\"agents_alive\"),\n            ]\n        )\n    )\nif not parallel_last.is_empty():\n    metrics_pieces.append(\n        parallel_last.select(\n            [\n                pl.lit(\"Parallel (random tie-break)\").alias(\"update_rule\"),\n                \"gini\",\n                \"corr_sugar_metabolism\",\n                \"corr_sugar_vision\",\n                pl.col(\"agents_alive\"),\n            ]\n        )\n    )\n\nmetrics_table = (\n    pl.concat(metrics_pieces, how=\"vertical\") if metrics_pieces else pl.DataFrame()\n)\n\nprint(\"\\nSteady-state inequality metrics:\")\nprint(\n    metrics_table.select(\n        [\n            \"update_rule\",\n            pl.col(\"gini\").round(4),\n            pl.col(\"corr_sugar_metabolism\").round(4),\n            pl.col(\"corr_sugar_vision\").round(4),\n            pl.col(\"agents_alive\"),\n        ]\n    )\n)\n\nif metrics_table.height &gt;= 2:\n    numba_gini = metrics_table.filter(pl.col(\"update_rule\") == \"Sequential (Numba)\")[\n        \"gini\"\n    ][0]\n    par_gini = metrics_table.filter(\n        pl.col(\"update_rule\") == \"Parallel (random tie-break)\"\n    )[\"gini\"][0]\n    print(f\"Absolute Gini gap (numba vs parallel): {abs(numba_gini - par_gini):.4f}\")\n</pre> comparison = numba_model_frame.select(     [\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"] ).join(     par_model_frame.select([\"step\", \"mean_sugar\", \"total_sugar\", \"agents_alive\"]),     on=\"step\",     how=\"inner\",     suffix=\"_parallel\", ) comparison = comparison.with_columns(     (pl.col(\"mean_sugar\") - pl.col(\"mean_sugar_parallel\")).abs().alias(\"mean_diff\"),     (pl.col(\"total_sugar\") - pl.col(\"total_sugar_parallel\")).abs().alias(\"total_diff\"),     (pl.col(\"agents_alive\") - pl.col(\"agents_alive_parallel\"))     .abs()     .alias(\"count_diff\"), ) print(\"Step-level absolute differences (first 10 steps):\") print(comparison.select([\"step\", \"mean_diff\", \"total_diff\", \"count_diff\"]).head(10))   # Build the steady\u2011state metrics table from the DataCollector output rather than # recomputing reporters directly on the model objects. The collector already # stored the model\u2011level reporters (gini, correlations, etc.) every step. def _last_row(df: pl.DataFrame) -&gt; pl.DataFrame:     if df.is_empty():         return df     # Ensure we take the final time step in case steps &lt; MODEL_STEPS due to extinction.     return df.sort(\"step\").tail(1)   numba_last = _last_row(frames.get(\"Sequential (Numba)\", pl.DataFrame())) parallel_last = _last_row(frames.get(\"Parallel (Polars)\", pl.DataFrame()))  metrics_pieces: list[pl.DataFrame] = [] if not numba_last.is_empty():     metrics_pieces.append(         numba_last.select(             [                 pl.lit(\"Sequential (Numba)\").alias(\"update_rule\"),                 \"gini\",                 \"corr_sugar_metabolism\",                 \"corr_sugar_vision\",                 pl.col(\"agents_alive\"),             ]         )     ) if not parallel_last.is_empty():     metrics_pieces.append(         parallel_last.select(             [                 pl.lit(\"Parallel (random tie-break)\").alias(\"update_rule\"),                 \"gini\",                 \"corr_sugar_metabolism\",                 \"corr_sugar_vision\",                 pl.col(\"agents_alive\"),             ]         )     )  metrics_table = (     pl.concat(metrics_pieces, how=\"vertical\") if metrics_pieces else pl.DataFrame() )  print(\"\\nSteady-state inequality metrics:\") print(     metrics_table.select(         [             \"update_rule\",             pl.col(\"gini\").round(4),             pl.col(\"corr_sugar_metabolism\").round(4),             pl.col(\"corr_sugar_vision\").round(4),             pl.col(\"agents_alive\"),         ]     ) )  if metrics_table.height &gt;= 2:     numba_gini = metrics_table.filter(pl.col(\"update_rule\") == \"Sequential (Numba)\")[         \"gini\"     ][0]     par_gini = metrics_table.filter(         pl.col(\"update_rule\") == \"Parallel (random tie-break)\"     )[\"gini\"][0]     print(f\"Absolute Gini gap (numba vs parallel): {abs(numba_gini - par_gini):.4f}\") <pre>Step-level absolute differences (first 10 steps):\nshape: (10, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 step \u2506 mean_diff \u2506 total_diff \u2506 count_diff \u2502\n\u2502 ---  \u2506 ---       \u2506 ---        \u2506 ---        \u2502\n\u2502 i64  \u2506 f64       \u2506 f64        \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0    \u2506 0.0       \u2506 0.0        \u2506 0.0        \u2502\n\u2502 1    \u2506 0.0125    \u2506 5.0        \u2506 0.0        \u2502\n\u2502 2    \u2506 0.02      \u2506 8.0        \u2506 0.0        \u2502\n\u2502 3    \u2506 0.0075    \u2506 3.0        \u2506 0.0        \u2502\n\u2502 4    \u2506 0.071014  \u2506 13.0       \u2506 1.0        \u2502\n\u2502 5    \u2506 0.091603  \u2506 36.0       \u2506 0.0        \u2502\n\u2502 6    \u2506 0.038603  \u2506 62.0       \u2506 3.0        \u2502\n\u2502 7    \u2506 0.005146  \u2506 63.0       \u2506 4.0        \u2502\n\u2502 8    \u2506 0.020046  \u2506 73.0       \u2506 4.0        \u2502\n\u2502 9    \u2506 0.0096    \u2506 72.0       \u2506 4.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nSteady-state inequality metrics:\nshape: (2, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 update_rule                 \u2506 gini   \u2506 corr_sugar_metabolism \u2506 corr_sugar_vision \u2506 agents_alive \u2502\n\u2502 ---                         \u2506 ---    \u2506 ---                   \u2506 ---               \u2506 ---          \u2502\n\u2502 str                         \u2506 f64    \u2506 f64                   \u2506 f64               \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Sequential (Numba)          \u2506 0.3098 \u2506 -0.7981               \u2506 0.2852            \u2506 241.0        \u2502\n\u2502 Parallel (random tie-break) \u2506 0.3287 \u2506 -0.8211               \u2506 0.2199            \u2506 253.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nAbsolute Gini gap (numba vs parallel): 0.0189\n</pre>"},{"location":"user-guide/3_advanced_tutorial/#advanced-tutorial-rebuilding-sugarscape-with-mesa-frames","title":"Advanced Tutorial \u2014 Rebuilding Sugarscape with mesa-frames\u00b6","text":"<p>We revisit the classic Sugarscape instant-growback model described in chapter 2 of Growing Artificial Societies (Epstein &amp; Axtell, 1996) and rebuild it step by step using <code>mesa-frames</code>. Along the way we highlight why the traditional definition is not ideal for high-performance with mesa-frames and how a simple relaxation can unlock vectorisation and lead to similar macro behaviour.</p>"},{"location":"user-guide/3_advanced_tutorial/#sugarscape-in-plain-terms","title":"Sugarscape in Plain Terms\u00b6","text":"<p>We model a population of ants living on a rectangular grid rich in sugar. Each cell can host at most one ant and holds a fixed amount of sugar. Every time step unfolds as follows:</p> <ul> <li>Sense: each ant looks outward along the four cardinal directions up to its <code>vision</code> radius and spots open cells.</li> <li>Move: the ant chooses the cell with highest sugar (breaking ties by distance and coordinates). The sugar on cells that are already occupied (including its own) is 0.</li> <li>Eat &amp; survive: ants harvest the sugar on the cell they occupy. If their sugar stock falls below their <code>metabolism</code> cost, they die.</li> <li>Regrow: sugar instantly regrows to its maximum level on empty cells. The landscape is drawn from a uniform distribution, so resources are homogeneous on average and the interesting dynamics come from agent heterogeneity and congestion.</li> </ul> <p>The update schedule matters for micro-behaviour, so we study three variants:</p> <ol> <li>Sequential loop (asynchronous): This is the traditional definition. Ants move one at a time in random order. This cannot be vectorised easily as the best move for an ant might depend on the moves of earlier ants (for example, if they target the same cell).</li> <li>Sequential with Numba: matches the first variant but relies on a compiled helper for speed.</li> <li>Parallel (synchronous): all ants propose moves; conflicts are resolved at random before applying the winners simultaneously (and the losers get to their second-best cell, etc).</li> </ol> <p>The first variant (pure Python loops) is a natural starting point, but it is not the mesa-frames philosophy. The latter two are: we aim to write rules declaratively and let the dataframe engine worry about performance. Our guiding principle is to focus on modelling first and performance second. Only when a rule is truly inherently sequential do we fall back to a compiled kernel (Numba or JAX).</p> <p>Our goal is to show that, under instantaneous growback and uniform resources, the model converges to the same macroscopic inequality pattern regardless of whether agents act sequentially or in parallel and that As long as the random draws do not push the system into extinction, the long-run Gini coefficient of wealth and the wealth\u2013trait correlations line up within sampling error \u2014 a classic example of emergent macro regularities in agent-based models.</p>"},{"location":"user-guide/3_advanced_tutorial/#1-imports","title":"1. Imports\u00b6","text":""},{"location":"user-guide/3_advanced_tutorial/#2-model-definition","title":"2. Model definition\u00b6","text":"<p>In this section we define some helpers and the model class that wires together the grid and the agents. The <code>agent_type</code> parameter stays flexible so we can plug in different movement policies later, but the model now owns the logic that generates the sugar field and the initial agent frame. Because both helpers use <code>self.random</code>, instantiating each variant with the same seed keeps the initial conditions identical across the sequential, Numba, and parallel implementations.</p> <p>The space is a von Neumann grid (which means agents can only move up, down, left, or right) with capacity 1, meaning each cell can host at most one agent. The sugar field is stored as part of the cell data frame, with columns for current sugar and maximum sugar (for regrowth). The model also sets up a data collector to track aggregate statistics and agent traits over time.</p> <p>The <code>step</code> method advances the sugar field, triggers the agent set's step.</p> <p>We also define some useful functions to compute metrics like the Gini coefficient and correlations.</p>"},{"location":"user-guide/3_advanced_tutorial/#3-agent-definition","title":"3. Agent definition\u00b6","text":""},{"location":"user-guide/3_advanced_tutorial/#31-base-agent-class","title":"3.1 Base agent class\u00b6","text":"<p>Now let's define the agent class (the ant class). We start with a base class which implements the common logic for eating and starvation, while leaving the <code>move</code> method abstract. The base class also provides helper methods for sensing visible cells and choosing the best cell based on sugar, distance, and coordinates. This will allow us to define different movement policies (sequential, Numba-accelerated, and parallel) as subclasses that only need to implement the <code>move</code> method.</p>"},{"location":"user-guide/3_advanced_tutorial/#32-sequential-movement","title":"3.2 Sequential movement\u00b6","text":"<p>We now implement the simplest movement policy: sequential (asynchronous). Each agent moves one at a time in the current ordering, choosing the best visible cell according to the rules.</p> <p>This implementation uses plain Python loops as the logic cannot be easily vectorised. As a result, it is slow for large populations and grids. We will later show how to speed it up with Numba.</p>"},{"location":"user-guide/3_advanced_tutorial/#33-speeding-up-the-loop-with-numba","title":"3.3 Speeding Up the Loop with Numba\u00b6","text":"<p>As we will see later, the previous sequential implementation is slow for large populations and grids because it relies on plain Python loops. We can speed it up significantly by using Numba to compile the movement logic.</p> <p>Numba compiles numerical Python code to fast machine code at runtime. To use Numba, we need to rewrite the movement logic in a way that is compatible with Numba's restrictions (using tightly typed numpy arrays and accessing data indexes directly).</p>"},{"location":"user-guide/3_advanced_tutorial/#35-simultaneous-movement-with-conflict-resolution-the-polars-mesa-frames-idiomatic-way","title":"3.5 Simultaneous Movement with Conflict Resolution (the Polars mesa-frames idiomatic way)\u00b6","text":"<p>The previous implementation is optimal speed-wise but it's a bit low-level. It requires maintaining an occupancy grid and imperative loops and it might become tricky to extend with more complex movement rules or models. To stay in mesa-frames idiom, we can implement a parallel movement policy that uses Polars DataFrame operations to resolve conflicts when multiple agents target the same cell. These conflicts are resolved in rounds: in each round, each agent proposes its current best candidate cell; winners per cell are chosen at random, and losers are promoted to their next-ranked choice. This continues until all agents have moved. This implementation is a tad slower but still efficient and easier to read (for a Polars user).</p>"},{"location":"user-guide/3_advanced_tutorial/#4-run-the-model-variants","title":"4. Run the Model Variants\u00b6","text":"<p>We iterate over each movement policy with a shared helper so all runs reuse the same seed. The tutorial runs all three variants (Python sequential, Numba sequential, and parallel) by default; edit the script if you want to skip the slow pure-Python baseline.</p>"},{"location":"user-guide/3_advanced_tutorial/#5-comparing-the-update-rules","title":"5. Comparing the Update Rules\u00b6","text":"<p>Even though micro rules differ, aggregate trajectories remain qualitatively similar (sugar trends up while population gradually declines). When we join the traces step-by-step, we see small but noticeable deviations introduced by synchronous conflict resolution (e.g., a few more retirements when conflicts cluster). In our run (seed=42), the final-step Gini differs by \u22480.005, and wealth\u2013trait correlations match within ~1e-3. These gaps vary by seed and grid size, but they consistently stay modest, supporting the relaxed parallel update as a faithful macro-level approximation.</p>"},{"location":"user-guide/3_advanced_tutorial/#6-takeaways-and-next-steps","title":"6. Takeaways and Next Steps\u00b6","text":"<p>Some final notes:</p> <ul> <li>mesa-frames should preferably be used when you have many agents and operations can be vectorized.</li> <li>If your model is not easily vectorizable, consider using Numba or reducing your microscopic rule to a vectorizable form. As we saw, the macroscopic behavior can remain consistent (and be more similar to real-world systems).</li> </ul> <p>Currently, the Polars implementation spends most of the time in join operations.</p> <p>Polars + LazyFrames roadmap \u2013 future mesa-frames releases will expose LazyFrame-powered sets and spaces (which can also use a GPU cuda accelerated backend which greatly accelerates joins), so the same Polars code you wrote here will scale even further without touching Numba.</p>"},{"location":"user-guide/4_datacollector/","title":"Data Collector Tutorial","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[2]: Copied! <pre>!pip install git+https://github.com/projectmesa/mesa-frames mesa\n</pre> !pip install git+https://github.com/projectmesa/mesa-frames mesa <pre>Collecting git+https://github.com/projectmesa/mesa-frames\r\n  Cloning https://github.com/projectmesa/mesa-frames to /tmp/pip-req-build-7axrremg\r\n  Running command git clone --filter=blob:none --quiet https://github.com/projectmesa/mesa-frames /tmp/pip-req-build-7axrremg\r\n</pre> <pre>  Resolved https://github.com/projectmesa/mesa-frames to commit 33555b4b4cb6b95c69120b04bccf948a6da808eb\r\n</pre> <pre>  Installing build dependencies ... -</pre> <pre>\b \b\\</pre> <pre>\b \bdone\r\n</pre> <pre>  Getting requirements to build wheel ... done\r\n</pre> <pre>  Preparing metadata (pyproject.toml) ... done\r\nRequirement already satisfied: mesa in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (3.3.0)\r\nRequirement already satisfied: boto3&gt;=1.35.91 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: numpy&gt;=2.0.2 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.3.3)\r\nRequirement already satisfied: polars&gt;=1.30.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.34.0)\r\nRequirement already satisfied: psycopg2-binary==2.9.10 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.9.10)\r\nRequirement already satisfied: pyarrow&gt;=20.0.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (21.0.0)\r\nRequirement already satisfied: pandas in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (2.3.3)\r\nRequirement already satisfied: scipy in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (1.16.2)\r\nRequirement already satisfied: tqdm in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (4.67.1)\r\nRequirement already satisfied: botocore&lt;1.41.0,&gt;=1.40.51 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.0.1)\r\nRequirement already satisfied: s3transfer&lt;0.15.0,&gt;=0.14.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (0.14.0)\r\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.5.0)\r\nRequirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.17.0)\r\nRequirement already satisfied: polars-runtime-32==1.34.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from polars&gt;=1.30.0-&gt;mesa_frames==0.1.1.dev0) (1.34.0)\r\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\n</pre> In\u00a0[3]: Copied! <pre>from mesa_frames import Model, AgentSet, DataCollector\nimport polars as pl\n\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        # one column, one unit of wealth each\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.select(self.wealth &gt; 0)\n        receivers = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        income = receivers.group_by(\"unique_id\").len()\n        self[income[\"unique_id\"], \"wealth\"] += income[\"len\"]\n\n\nclass MoneyModel(Model):\n    def __init__(self, n: int):\n        super().__init__()\n        self.sets.add(MoneyAgents(n, self))\n        self.dc = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n                \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n            },\n            agent_reporters={\n                \"wealth\": \"wealth\",  # pull existing column\n            },\n            storage=\"memory\",  # we'll switch this per example\n            storage_uri=None,\n            trigger=lambda m: m.steps % 2\n            == 0,  # collect every 2 steps via conditional_collect\n            reset_memory=True,\n        )\n\n    def step(self):\n        self.sets.do(\"step\")\n\n    def run(self, steps: int, conditional: bool = True):\n        for _ in range(steps):\n            self.step()\n            self.dc.conditional_collect()  # or .collect if you want to collect every step regardless of trigger\n\n\nmodel = MoneyModel(1000)\nmodel.run(10)\nmodel.dc.data  # peek in-memory dataframes\n</pre> from mesa_frames import Model, AgentSet, DataCollector import polars as pl   class MoneyAgents(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         # one column, one unit of wealth each         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.select(self.wealth &gt; 0)         receivers = self.df.sample(n=len(self.active_agents), with_replacement=True)         self[\"active\", \"wealth\"] -= 1         income = receivers.group_by(\"unique_id\").len()         self[income[\"unique_id\"], \"wealth\"] += income[\"len\"]   class MoneyModel(Model):     def __init__(self, n: int):         super().__init__()         self.sets.add(MoneyAgents(n, self))         self.dc = DataCollector(             model=self,             model_reporters={                 \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),                 \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),             },             agent_reporters={                 \"wealth\": \"wealth\",  # pull existing column             },             storage=\"memory\",  # we'll switch this per example             storage_uri=None,             trigger=lambda m: m.steps % 2             == 0,  # collect every 2 steps via conditional_collect             reset_memory=True,         )      def step(self):         self.sets.do(\"step\")      def run(self, steps: int, conditional: bool = True):         for _ in range(steps):             self.step()             self.dc.conditional_collect()  # or .collect if you want to collect every step regardless of trigger   model = MoneyModel(1000) model.run(10) model.dc.data  # peek in-memory dataframes Out[3]: <pre>{'model': shape: (5, 5)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 step \u2506 seed                            \u2506 batch \u2506 total_wealth \u2506 n_agents \u2502\n \u2502 ---  \u2506 ---                             \u2506 ---   \u2506 ---          \u2506 ---      \u2502\n \u2502 i64  \u2506 str                             \u2506 i64   \u2506 f64          \u2506 i64      \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 2    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 4    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 6    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 8    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 10   \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518,\n 'agent': shape: (5_000, 4)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 wealth_MoneyAgents \u2506 step \u2506 seed                            \u2506 batch \u2502\n \u2502 ---                \u2506 ---  \u2506 ---                             \u2506 ---   \u2502\n \u2502 f64                \u2506 i32  \u2506 str                             \u2506 i32   \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 1.0                \u2506 2    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 2    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 2.0                \u2506 2    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 2    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 2    \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 \u2026                  \u2506 \u2026    \u2506 \u2026                               \u2506 \u2026     \u2502\n \u2502 0.0                \u2506 10   \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 10   \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 10   \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 10   \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 10   \u2506 221763089159232129264537511218\u2026 \u2506 0     \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518}</pre> In\u00a0[4]: Copied! <pre>import os\n\nos.makedirs(\"./data_csv\", exist_ok=True)\nmodel_csv = MoneyModel(1000)\nmodel_csv.dc = DataCollector(\n    model=model_csv,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"csv\",  # saving as csv\n    storage_uri=\"./data_csv\",\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_csv.run(10)\nmodel_csv.dc.flush()\nos.listdir(\"./data_csv\")\n</pre> import os  os.makedirs(\"./data_csv\", exist_ok=True) model_csv = MoneyModel(1000) model_csv.dc = DataCollector(     model=model_csv,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"csv\",  # saving as csv     storage_uri=\"./data_csv\",     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_csv.run(10) model_csv.dc.flush() os.listdir(\"./data_csv\") Out[4]: <pre>[]</pre> In\u00a0[5]: Copied! <pre>os.makedirs(\"./data_parquet\", exist_ok=True)\nmodel_parq = MoneyModel(1000)\nmodel_parq.dc = DataCollector(\n    model=model_parq,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"parquet\",  # save as parquet\n    storage_uri=\"data_parquet\",\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_parq.run(10)\nmodel_parq.dc.flush()\nos.listdir(\"./data_parquet\")\n</pre> os.makedirs(\"./data_parquet\", exist_ok=True) model_parq = MoneyModel(1000) model_parq.dc = DataCollector(     model=model_parq,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"parquet\",  # save as parquet     storage_uri=\"data_parquet\",     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_parq.run(10) model_parq.dc.flush() os.listdir(\"./data_parquet\") Out[5]: <pre>[]</pre> In\u00a0[6]: Copied! <pre>model_s3 = MoneyModel(1000)\nmodel_s3.dc = DataCollector(\n    model=model_s3,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"S3-csv\",  # save as csv in S3\n    storage_uri=\"s3://my-bucket/experiments/run-1\",  # change it to required path\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_s3.run(10)\nmodel_s3.dc.flush()\n</pre> model_s3 = MoneyModel(1000) model_s3.dc = DataCollector(     model=model_s3,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"S3-csv\",  # save as csv in S3     storage_uri=\"s3://my-bucket/experiments/run-1\",  # change it to required path     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_s3.run(10) model_s3.dc.flush() In\u00a0[7]: Copied! <pre>DDL_MODEL = r\"\"\"\nCREATE SCHEMA IF NOT EXISTS public;\nCREATE TABLE IF NOT EXISTS public.model_data (\n  step INTEGER,\n  seed VARCHAR,\n  total_wealth BIGINT,\n  n_agents INTEGER\n);\n\"\"\"\nDDL_AGENT = r\"\"\"\nCREATE TABLE IF NOT EXISTS public.agent_data (\n  step INTEGER,\n  seed VARCHAR,\n  unique_id BIGINT,\n  wealth BIGINT\n);\n\"\"\"\nprint(DDL_MODEL)\nprint(DDL_AGENT)\n</pre> DDL_MODEL = r\"\"\" CREATE SCHEMA IF NOT EXISTS public; CREATE TABLE IF NOT EXISTS public.model_data (   step INTEGER,   seed VARCHAR,   total_wealth BIGINT,   n_agents INTEGER ); \"\"\" DDL_AGENT = r\"\"\" CREATE TABLE IF NOT EXISTS public.agent_data (   step INTEGER,   seed VARCHAR,   unique_id BIGINT,   wealth BIGINT ); \"\"\" print(DDL_MODEL) print(DDL_AGENT) <pre>\nCREATE SCHEMA IF NOT EXISTS public;\nCREATE TABLE IF NOT EXISTS public.model_data (\n  step INTEGER,\n  seed VARCHAR,\n  total_wealth BIGINT,\n  n_agents INTEGER\n);\n\n\nCREATE TABLE IF NOT EXISTS public.agent_data (\n  step INTEGER,\n  seed VARCHAR,\n  unique_id BIGINT,\n  wealth BIGINT\n);\n\n</pre> <p>After creating the tables (outside this notebook or via a DB connection cell), configure and flush:</p> In\u00a0[8]: Copied! <pre>POSTGRES_URI = \"postgresql://user:pass@localhost:5432/mydb\"\nm_pg = MoneyModel(300)\nm_pg.dc._storage = \"postgresql\"\nm_pg.dc._storage_uri = POSTGRES_URI\nm_pg.run(6)\nm_pg.dc.flush()\n</pre> POSTGRES_URI = \"postgresql://user:pass@localhost:5432/mydb\" m_pg = MoneyModel(300) m_pg.dc._storage = \"postgresql\" m_pg.dc._storage_uri = POSTGRES_URI m_pg.run(6) m_pg.dc.flush() In\u00a0[9]: Copied! <pre>m = MoneyModel(100)\nm.dc.trigger = lambda model: model._steps % 3 == 0  # every 3rd step\nm.run(10, conditional=True)\nm.dc.data[\"model\"].head()\n</pre> m = MoneyModel(100) m.dc.trigger = lambda model: model._steps % 3 == 0  # every 3rd step m.run(10, conditional=True) m.dc.data[\"model\"].head() Out[9]: shape: (5, 5)stepseedbatchtotal_wealthn_agentsi64stri64f64i642\"238872707390670715069929708812\u20260100.01004\"238872707390670715069929708812\u20260100.01006\"238872707390670715069929708812\u20260100.01008\"238872707390670715069929708812\u20260100.010010\"238872707390670715069929708812\u20260100.0100 <p>Generated on 2025-08-30.</p>"},{"location":"user-guide/4_datacollector/#data-collector-tutorial","title":"Data Collector Tutorial\u00b6","text":"<p>This notebook walks you through using the concrete <code>DataCollector</code> in <code>mesa-frames</code> to collect model- and agent-level data and write it to different storage backends: memory, CSV, Parquet, S3, and PostgreSQL.</p> <p>It also shows how to use conditional triggers and how the schema validation behaves for PostgreSQL.</p>"},{"location":"user-guide/4_datacollector/#installation-colab-or-fresh-env","title":"Installation (Colab or fresh env)\u00b6","text":"<p>Uncomment and run the next cell if you're in Colab or a clean environment.</p>"},{"location":"user-guide/4_datacollector/#minimal-example-model","title":"Minimal Example Model\u00b6","text":"<p>We create a tiny model using the <code>Model</code> and an <code>AgentSet</code>-style agent container. This is just to demonstrate collection APIs.</p>"},{"location":"user-guide/4_datacollector/#saving-the-data-for-later-use","title":"Saving the data for later use\u00b6","text":"<p><code>DataCollector</code> supports multiple storage backends. Files are saved with step number and batch number (e.g., <code>model_step10_batch2.csv</code>) so multiple collects at the same step don\u2019t overwrite.</p> <ul> <li>CSV: <code>storage=\"csv\"</code> \u2192 writes <code>model_step{n}_batch{k}.csv</code>, easy to open anywhere.</li> <li>Parquet: <code>storage=\"parquet\"</code> \u2192 compressed, efficient for large datasets.</li> <li>S3: <code>storage=\"S3-csv\"</code>/<code>storage=\"S3-parquet\"</code> \u2192 saves CSV/Parquet directly to Amazon S3.</li> <li>PostgreSQL: <code>storage=\"postgresql\"</code> \u2192 inserts results into <code>model_data</code> and <code>agent_data</code> tables for querying.</li> </ul>"},{"location":"user-guide/4_datacollector/#writing-to-local-csv","title":"Writing to Local CSV\u00b6","text":"<p>Switch the storage to <code>csv</code> and provide a folder path. Files are written as <code>model_step{n}.csv</code> and <code>agent_step{n}.csv</code>.</p>"},{"location":"user-guide/4_datacollector/#writing-to-local-parquet","title":"Writing to Local Parquet\u00b6","text":"<p>Use <code>parquet</code> for columnar output.</p>"},{"location":"user-guide/4_datacollector/#writing-to-amazon-s3-csv-or-parquet","title":"Writing to Amazon S3 (CSV or Parquet)\u00b6","text":"<p>Set AWS credentials via environment variables or your usual config. Then choose <code>S3-csv</code> or <code>S3-parquet</code> and pass an S3 URI (e.g., <code>s3://my-bucket/experiments/run-1</code>).</p> <p>Note: This cell requires network access &amp; credentials when actually run.</p>"},{"location":"user-guide/4_datacollector/#writing-to-postgresql","title":"Writing to PostgreSQL\u00b6","text":"<p>PostgreSQL requires that the target tables exist and that the expected reporter columns are present. The collector will validate tables/columns up front and raise descriptive errors if something is missing.</p> <p>Below is a minimal schema example. Adjust columns to your configured reporters.</p>"},{"location":"user-guide/4_datacollector/#triggers-conditional-collection","title":"Triggers &amp; Conditional Collection\u00b6","text":"<p>The collector accepts a <code>trigger: Callable[[Model], bool]</code>. When using <code>conditional_collect()</code>, the collector checks the trigger and collects only if it returns <code>True</code>.</p> <p>You can always call <code>collect()</code> to gather data unconditionally.</p>"},{"location":"user-guide/4_datacollector/#troubleshooting","title":"Troubleshooting\u00b6","text":"<ul> <li>ValueError: Please define a storage_uri \u2014 for non-memory backends you must set <code>_storage_uri</code>.</li> <li>Missing columns in table \u2014 check the PostgreSQL error text; create/alter the table to include the columns for your configured <code>model_reporters</code> and <code>agent_reporters</code>, plus required <code>step</code> and <code>seed</code>.</li> <li>Permissions/credentials errors (S3/PostgreSQL) \u2014 ensure correct IAM/credentials or database permissions.</li> </ul>"},{"location":"user-guide/4_datacollector/","title":"Data Collector Tutorial","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[2]: Copied! <pre>!pip install git+https://github.com/projectmesa/mesa-frames mesa\n</pre> !pip install git+https://github.com/projectmesa/mesa-frames mesa <pre>Collecting git+https://github.com/projectmesa/mesa-frames\r\n  Cloning https://github.com/projectmesa/mesa-frames to /tmp/pip-req-build-k5iodk_t\r\n  Running command git clone --filter=blob:none --quiet https://github.com/projectmesa/mesa-frames /tmp/pip-req-build-k5iodk_t\r\n</pre> <pre>  Resolved https://github.com/projectmesa/mesa-frames to commit 33555b4b4cb6b95c69120b04bccf948a6da808eb\r\n</pre> <pre>  Installing build dependencies ... -</pre> <pre>\b \b\\</pre> <pre>\b \bdone\r\n</pre> <pre>  Getting requirements to build wheel ... done\r\n</pre> <pre>  Preparing metadata (pyproject.toml) ... done\r\nRequirement already satisfied: mesa in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (3.3.0)\r\nRequirement already satisfied: boto3&gt;=1.35.91 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: numpy&gt;=2.0.2 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.3.3)\r\nRequirement already satisfied: polars&gt;=1.30.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (1.34.0)\r\nRequirement already satisfied: psycopg2-binary==2.9.10 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (2.9.10)\r\nRequirement already satisfied: pyarrow&gt;=20.0.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa_frames==0.1.1.dev0) (21.0.0)\r\nRequirement already satisfied: pandas in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (2.3.3)\r\nRequirement already satisfied: scipy in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (1.16.2)\r\nRequirement already satisfied: tqdm in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from mesa) (4.67.1)\r\n</pre> <pre>Requirement already satisfied: botocore&lt;1.41.0,&gt;=1.40.51 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.40.51)\r\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.0.1)\r\nRequirement already satisfied: s3transfer&lt;0.15.0,&gt;=0.14.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (0.14.0)\r\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.9.0.post0)\r\nRequirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (2.5.0)\r\nRequirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.41.0,&gt;=1.40.51-&gt;boto3&gt;=1.35.91-&gt;mesa_frames==0.1.1.dev0) (1.17.0)\r\nRequirement already satisfied: polars-runtime-32==1.34.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from polars&gt;=1.30.0-&gt;mesa_frames==0.1.1.dev0) (1.34.0)\r\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from pandas-&gt;mesa) (2025.2)\r\n</pre> In\u00a0[3]: Copied! <pre>from mesa_frames import Model, AgentSet, DataCollector\nimport polars as pl\n\n\nclass MoneyAgents(AgentSet):\n    def __init__(self, n: int, model: Model):\n        super().__init__(model)\n        # one column, one unit of wealth each\n        self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})\n\n    def step(self) -&gt; None:\n        self.select(self.wealth &gt; 0)\n        receivers = self.df.sample(n=len(self.active_agents), with_replacement=True)\n        self[\"active\", \"wealth\"] -= 1\n        income = receivers.group_by(\"unique_id\").len()\n        self[income[\"unique_id\"], \"wealth\"] += income[\"len\"]\n\n\nclass MoneyModel(Model):\n    def __init__(self, n: int):\n        super().__init__()\n        self.sets.add(MoneyAgents(n, self))\n        self.dc = DataCollector(\n            model=self,\n            model_reporters={\n                \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n                \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n            },\n            agent_reporters={\n                \"wealth\": \"wealth\",  # pull existing column\n            },\n            storage=\"memory\",  # we'll switch this per example\n            storage_uri=None,\n            trigger=lambda m: m.steps % 2\n            == 0,  # collect every 2 steps via conditional_collect\n            reset_memory=True,\n        )\n\n    def step(self):\n        self.sets.do(\"step\")\n\n    def run(self, steps: int, conditional: bool = True):\n        for _ in range(steps):\n            self.step()\n            self.dc.conditional_collect()  # or .collect if you want to collect every step regardless of trigger\n\n\nmodel = MoneyModel(1000)\nmodel.run(10)\nmodel.dc.data  # peek in-memory dataframes\n</pre> from mesa_frames import Model, AgentSet, DataCollector import polars as pl   class MoneyAgents(AgentSet):     def __init__(self, n: int, model: Model):         super().__init__(model)         # one column, one unit of wealth each         self += pl.DataFrame({\"wealth\": pl.ones(n, eager=True)})      def step(self) -&gt; None:         self.select(self.wealth &gt; 0)         receivers = self.df.sample(n=len(self.active_agents), with_replacement=True)         self[\"active\", \"wealth\"] -= 1         income = receivers.group_by(\"unique_id\").len()         self[income[\"unique_id\"], \"wealth\"] += income[\"len\"]   class MoneyModel(Model):     def __init__(self, n: int):         super().__init__()         self.sets.add(MoneyAgents(n, self))         self.dc = DataCollector(             model=self,             model_reporters={                 \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),                 \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),             },             agent_reporters={                 \"wealth\": \"wealth\",  # pull existing column             },             storage=\"memory\",  # we'll switch this per example             storage_uri=None,             trigger=lambda m: m.steps % 2             == 0,  # collect every 2 steps via conditional_collect             reset_memory=True,         )      def step(self):         self.sets.do(\"step\")      def run(self, steps: int, conditional: bool = True):         for _ in range(steps):             self.step()             self.dc.conditional_collect()  # or .collect if you want to collect every step regardless of trigger   model = MoneyModel(1000) model.run(10) model.dc.data  # peek in-memory dataframes Out[3]: <pre>{'model': shape: (5, 5)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 step \u2506 seed                            \u2506 batch \u2506 total_wealth \u2506 n_agents \u2502\n \u2502 ---  \u2506 ---                             \u2506 ---   \u2506 ---          \u2506 ---      \u2502\n \u2502 i64  \u2506 str                             \u2506 i64   \u2506 f64          \u2506 i64      \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 2    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 4    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 6    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 8    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2502 10   \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2506 1000.0       \u2506 1000     \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518,\n 'agent': shape: (5_000, 4)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 wealth_MoneyAgents \u2506 step \u2506 seed                            \u2506 batch \u2502\n \u2502 ---                \u2506 ---  \u2506 ---                             \u2506 ---   \u2502\n \u2502 f64                \u2506 i32  \u2506 str                             \u2506 i32   \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 1.0                \u2506 2    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 2    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 3.0                \u2506 2    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 2    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 2    \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 \u2026                  \u2506 \u2026    \u2506 \u2026                               \u2506 \u2026     \u2502\n \u2502 0.0                \u2506 10   \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 10   \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 10   \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 1.0                \u2506 10   \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2502 0.0                \u2506 10   \u2506 102038732203064625100075910262\u2026 \u2506 0     \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518}</pre> In\u00a0[4]: Copied! <pre>import os\n\nos.makedirs(\"./data_csv\", exist_ok=True)\nmodel_csv = MoneyModel(1000)\nmodel_csv.dc = DataCollector(\n    model=model_csv,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"csv\",  # saving as csv\n    storage_uri=\"./data_csv\",\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_csv.run(10)\nmodel_csv.dc.flush()\nos.listdir(\"./data_csv\")\n</pre> import os  os.makedirs(\"./data_csv\", exist_ok=True) model_csv = MoneyModel(1000) model_csv.dc = DataCollector(     model=model_csv,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"csv\",  # saving as csv     storage_uri=\"./data_csv\",     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_csv.run(10) model_csv.dc.flush() os.listdir(\"./data_csv\") Out[4]: <pre>[]</pre> In\u00a0[5]: Copied! <pre>os.makedirs(\"./data_parquet\", exist_ok=True)\nmodel_parq = MoneyModel(1000)\nmodel_parq.dc = DataCollector(\n    model=model_parq,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"parquet\",  # save as parquet\n    storage_uri=\"data_parquet\",\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_parq.run(10)\nmodel_parq.dc.flush()\nos.listdir(\"./data_parquet\")\n</pre> os.makedirs(\"./data_parquet\", exist_ok=True) model_parq = MoneyModel(1000) model_parq.dc = DataCollector(     model=model_parq,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"parquet\",  # save as parquet     storage_uri=\"data_parquet\",     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_parq.run(10) model_parq.dc.flush() os.listdir(\"./data_parquet\") Out[5]: <pre>[]</pre> In\u00a0[6]: Copied! <pre>model_s3 = MoneyModel(1000)\nmodel_s3.dc = DataCollector(\n    model=model_s3,\n    model_reporters={\n        \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),\n        \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),\n    },\n    agent_reporters={\n        \"wealth\": \"wealth\",\n    },\n    storage=\"S3-csv\",  # save as csv in S3\n    storage_uri=\"s3://my-bucket/experiments/run-1\",  # change it to required path\n    trigger=lambda m: m._steps % 2 == 0,\n    reset_memory=True,\n)\nmodel_s3.run(10)\nmodel_s3.dc.flush()\n</pre> model_s3 = MoneyModel(1000) model_s3.dc = DataCollector(     model=model_s3,     model_reporters={         \"total_wealth\": lambda m: m.sets[\"MoneyAgents\"].df[\"wealth\"].sum(),         \"n_agents\": lambda m: len(m.sets[\"MoneyAgents\"]),     },     agent_reporters={         \"wealth\": \"wealth\",     },     storage=\"S3-csv\",  # save as csv in S3     storage_uri=\"s3://my-bucket/experiments/run-1\",  # change it to required path     trigger=lambda m: m._steps % 2 == 0,     reset_memory=True, ) model_s3.run(10) model_s3.dc.flush() In\u00a0[7]: Copied! <pre>DDL_MODEL = r\"\"\"\nCREATE SCHEMA IF NOT EXISTS public;\nCREATE TABLE IF NOT EXISTS public.model_data (\n  step INTEGER,\n  seed VARCHAR,\n  total_wealth BIGINT,\n  n_agents INTEGER\n);\n\"\"\"\nDDL_AGENT = r\"\"\"\nCREATE TABLE IF NOT EXISTS public.agent_data (\n  step INTEGER,\n  seed VARCHAR,\n  unique_id BIGINT,\n  wealth BIGINT\n);\n\"\"\"\nprint(DDL_MODEL)\nprint(DDL_AGENT)\n</pre> DDL_MODEL = r\"\"\" CREATE SCHEMA IF NOT EXISTS public; CREATE TABLE IF NOT EXISTS public.model_data (   step INTEGER,   seed VARCHAR,   total_wealth BIGINT,   n_agents INTEGER ); \"\"\" DDL_AGENT = r\"\"\" CREATE TABLE IF NOT EXISTS public.agent_data (   step INTEGER,   seed VARCHAR,   unique_id BIGINT,   wealth BIGINT ); \"\"\" print(DDL_MODEL) print(DDL_AGENT) <pre>\nCREATE SCHEMA IF NOT EXISTS public;\nCREATE TABLE IF NOT EXISTS public.model_data (\n  step INTEGER,\n  seed VARCHAR,\n  total_wealth BIGINT,\n  n_agents INTEGER\n);\n\n\nCREATE TABLE IF NOT EXISTS public.agent_data (\n  step INTEGER,\n  seed VARCHAR,\n  unique_id BIGINT,\n  wealth BIGINT\n);\n\n</pre> <p>After creating the tables (outside this notebook or via a DB connection cell), configure and flush:</p> In\u00a0[8]: Copied! <pre>POSTGRES_URI = \"postgresql://user:pass@localhost:5432/mydb\"\nm_pg = MoneyModel(300)\nm_pg.dc._storage = \"postgresql\"\nm_pg.dc._storage_uri = POSTGRES_URI\nm_pg.run(6)\nm_pg.dc.flush()\n</pre> POSTGRES_URI = \"postgresql://user:pass@localhost:5432/mydb\" m_pg = MoneyModel(300) m_pg.dc._storage = \"postgresql\" m_pg.dc._storage_uri = POSTGRES_URI m_pg.run(6) m_pg.dc.flush() In\u00a0[9]: Copied! <pre>m = MoneyModel(100)\nm.dc.trigger = lambda model: model._steps % 3 == 0  # every 3rd step\nm.run(10, conditional=True)\nm.dc.data[\"model\"].head()\n</pre> m = MoneyModel(100) m.dc.trigger = lambda model: model._steps % 3 == 0  # every 3rd step m.run(10, conditional=True) m.dc.data[\"model\"].head() Out[9]: shape: (5, 5)stepseedbatchtotal_wealthn_agentsi64stri64f64i642\"128031806087411601317892823138\u20260100.01004\"128031806087411601317892823138\u20260100.01006\"128031806087411601317892823138\u20260100.01008\"128031806087411601317892823138\u20260100.010010\"128031806087411601317892823138\u20260100.0100 <p>Generated on 2025-08-30.</p>"},{"location":"user-guide/4_datacollector/#data-collector-tutorial","title":"Data Collector Tutorial\u00b6","text":"<p>This notebook walks you through using the concrete <code>DataCollector</code> in <code>mesa-frames</code> to collect model- and agent-level data and write it to different storage backends: memory, CSV, Parquet, S3, and PostgreSQL.</p> <p>It also shows how to use conditional triggers and how the schema validation behaves for PostgreSQL.</p>"},{"location":"user-guide/4_datacollector/#installation-colab-or-fresh-env","title":"Installation (Colab or fresh env)\u00b6","text":"<p>Uncomment and run the next cell if you're in Colab or a clean environment.</p>"},{"location":"user-guide/4_datacollector/#minimal-example-model","title":"Minimal Example Model\u00b6","text":"<p>We create a tiny model using the <code>Model</code> and an <code>AgentSet</code>-style agent container. This is just to demonstrate collection APIs.</p>"},{"location":"user-guide/4_datacollector/#saving-the-data-for-later-use","title":"Saving the data for later use\u00b6","text":"<p><code>DataCollector</code> supports multiple storage backends. Files are saved with step number and batch number (e.g., <code>model_step10_batch2.csv</code>) so multiple collects at the same step don\u2019t overwrite.</p> <ul> <li>CSV: <code>storage=\"csv\"</code> \u2192 writes <code>model_step{n}_batch{k}.csv</code>, easy to open anywhere.</li> <li>Parquet: <code>storage=\"parquet\"</code> \u2192 compressed, efficient for large datasets.</li> <li>S3: <code>storage=\"S3-csv\"</code>/<code>storage=\"S3-parquet\"</code> \u2192 saves CSV/Parquet directly to Amazon S3.</li> <li>PostgreSQL: <code>storage=\"postgresql\"</code> \u2192 inserts results into <code>model_data</code> and <code>agent_data</code> tables for querying.</li> </ul>"},{"location":"user-guide/4_datacollector/#writing-to-local-csv","title":"Writing to Local CSV\u00b6","text":"<p>Switch the storage to <code>csv</code> and provide a folder path. Files are written as <code>model_step{n}.csv</code> and <code>agent_step{n}.csv</code>.</p>"},{"location":"user-guide/4_datacollector/#writing-to-local-parquet","title":"Writing to Local Parquet\u00b6","text":"<p>Use <code>parquet</code> for columnar output.</p>"},{"location":"user-guide/4_datacollector/#writing-to-amazon-s3-csv-or-parquet","title":"Writing to Amazon S3 (CSV or Parquet)\u00b6","text":"<p>Set AWS credentials via environment variables or your usual config. Then choose <code>S3-csv</code> or <code>S3-parquet</code> and pass an S3 URI (e.g., <code>s3://my-bucket/experiments/run-1</code>).</p> <p>Note: This cell requires network access &amp; credentials when actually run.</p>"},{"location":"user-guide/4_datacollector/#writing-to-postgresql","title":"Writing to PostgreSQL\u00b6","text":"<p>PostgreSQL requires that the target tables exist and that the expected reporter columns are present. The collector will validate tables/columns up front and raise descriptive errors if something is missing.</p> <p>Below is a minimal schema example. Adjust columns to your configured reporters.</p>"},{"location":"user-guide/4_datacollector/#triggers-conditional-collection","title":"Triggers &amp; Conditional Collection\u00b6","text":"<p>The collector accepts a <code>trigger: Callable[[Model], bool]</code>. When using <code>conditional_collect()</code>, the collector checks the trigger and collects only if it returns <code>True</code>.</p> <p>You can always call <code>collect()</code> to gather data unconditionally.</p>"},{"location":"user-guide/4_datacollector/#troubleshooting","title":"Troubleshooting\u00b6","text":"<ul> <li>ValueError: Please define a storage_uri \u2014 for non-memory backends you must set <code>_storage_uri</code>.</li> <li>Missing columns in table \u2014 check the PostgreSQL error text; create/alter the table to include the columns for your configured <code>model_reporters</code> and <code>agent_reporters</code>, plus required <code>step</code> and <code>seed</code>.</li> <li>Permissions/credentials errors (S3/PostgreSQL) \u2014 ensure correct IAM/credentials or database permissions.</li> </ul>"},{"location":"user-guide/5_benchmarks/","title":"Performance Boost \ud83c\udfce\ufe0f\ud83d\udca8","text":"<p>mesa-frames offers significant performance improvements over the original mesa framework. Here are some benchmark results for different models:</p>"},{"location":"user-guide/5_benchmarks/#boltzmann-wealth-model","title":"Boltzmann Wealth Model \ud83d\udcb0","text":"<p>View the benchmark script</p>"},{"location":"user-guide/5_benchmarks/#comparison-with-mesa","title":"Comparison with mesa","text":""},{"location":"user-guide/5_benchmarks/#comparison-of-mesa-frames-implementations","title":"Comparison of mesa-frames implementations","text":""},{"location":"user-guide/5_benchmarks/#sugarscape-with-instantaneous-growback","title":"SugarScape with Instantaneous Growback \ud83c\udf6c","text":"<p>View the benchmark script</p> <p></p>"}]}